\documentclass[14pt, a4paper]{article}
\usepackage{minitoc}
\usepackage[left=3.00cm, right=2.5cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{thmtools}
\usepackage{mathtools}
\usepackage{graphicx}
%\usepackage{algpseudocode}
%\usepackage{algorithm}
\usepackage[ruled,vlined,linesnumbered,algosection]{algorithm2e}
\usepackage{blindtext}
\usepackage{setspace}
\usepackage[utf8]{inputenc}
\usepackage[utf8]{vietnam}
\usepackage[center]{caption}
\usepackage[shortlabels]{enumitem}
\usepackage{fancyhdr} % header, footer
\usepackage{hyperref} % loại bỏ border với mục lục và công thức
\usepackage[nonumberlist, nopostdot, nogroupskip]{glossaries}
\usepackage{glossary-superragged}
\usepackage{tikz,tkz-tab}
\setglossarystyle{superraggedheaderborder}
\pagestyle{fancy}
%\usepackage[style=numeric,sortcites]{biblatex}
%\addbibresource{ref.bib}
%\usepackage[numbers]{natbib}
\usepackage{indentfirst}
\usepackage{multirow}
\usepackage[natbib,backend=biber,style=ieee, sorting=ynt]{biblatex}
\bibliography{ref.bib}

\graphicspath{{./figures/}}


\makenoidxglossaries

% Danh mục thuật ngữ
\newglossaryentry{DPM}
{
	name={DPMs},
	description={Diffusion Probabilistic Models}
}
\newglossaryentry{DGM}
{
	name={DGMs},
	description={Deep Generative Models}
}
\newglossaryentry{GANs}
{
	name={GANs},
	description={Generative Adversarial Networks}
}
\newglossaryentry{ELBO}
{
	name={ELBO},
	description={Evidence Lower Bound}
}
\newglossaryentry{DDPM}
{
	name={DDPM},
	description={Denoising Diffusion Probabilistic Models}
}
\newglossaryentry{DDIM}
{
	name={DDIM},
	description={Denoising Diffusion Implicit Models}
}
\newglossaryentry{MSE}
{
	name={MSE},
	description={Mean Square Error}
}
\newglossaryentry{SN}
{
	name={SN},
	description={Square Noise}
}
\newglossaryentry{NPR}
{
	name={NPR},
	description={Noise Prediction Residual}
}
\newglossaryentry{SDE}
{
	name={SDE},
	description={Stochastic Differential Equation}
}
\newglossaryentry{ODE}
{
	name={ODE},
	description={Ordinary Differential Equation}
}
\newglossaryentry{LS}
{
	name={LS},
	description={Linear Scheduling}
}
\newglossaryentry{CS}
{
	name={CS},
	description={Cosine Scheduling}
}
\newglossaryentry{FID}
{
	name={FID},
	description={Frechet Inception Distance}
}

\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}


\fancyhf{}
\rhead{\textbf{Môn học: Học máy và khai phá dữ liệu}}
\lhead{\textbf{GVHD: PGS. TS. Trần Trọng Hiếu}}
\rfoot{\thepage}
\lfoot{\textbf{Học viên thực hiện: Nguyễn Chí Thanh - 21007925}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\numberwithin{equation}{section}
\numberwithin{figure}{section}

\setlength{\parindent}{0.5cm}

\setcounter{secnumdepth}{3} % Cho phép subsubsection trong report
\setcounter{tocdepth}{3} % Chèn subsubsection vào bảng mục lục

\newtheorem{dl}{Định lý}
\newtheorem{md}{Mệnh đề}
\newtheorem{bd}{Bổ đề}
\newtheorem{dn}{Định nghĩa}
\newtheorem{hq}{Hệ quả}

\numberwithin{dl}{section}
\numberwithin{md}{section}
\numberwithin{bd}{section}
\numberwithin{dn}{section}
\numberwithin{hq}{section}

\doublespacing
\AtBeginEnvironment{tabular}{\doublespacing}

\begin{document}

    \begin{titlepage}

        \newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

        \center % Center everything on the page

        %----------------------------------------------------------------------------------------
        %	HEADING SECTIONS
        %----------------------------------------------------------------------------------------
        \textsc{\LARGE Đại học Quốc Gia Hà Nội}\\[0.5cm]
        \textsc{\LARGE Trường đại học Khoa học tự nhiên}\\[0.5cm] % Name of your university/college
        \textsc{\LARGE Khoa Toán - Cơ - Tin học}\\[0.5cm]

        \includegraphics[scale=0.2]{HUS-logo.jpg}\\[0.5cm]

        \textsc{\Large Chuyên ngành: Khoa học dữ liệu}\\[0.5cm] % Major heading such as course name


        %----------------------------------------------------------------------------------------
        %	TITLE SECTION
        %----------------------------------------------------------------------------------------

        \HRule \\[0.4cm]
        { \huge \bfseries BÀI TẬP MÔN HỌC}\\[0.4cm] % Title of your document
        \HRule \\[1.5cm]

        \textsc{\Large Môn học: Học máy và khai phá dữ liệu}\\[1cm] % Minor heading such as course title


        \textsc{\Large Đề tài: Ước lượng ma trận hiệp phương sai tối ưu với \\ trung bình không hoàn hảo \\ trong mô hình khuếch toán xác suất}\\[2cm]


        %----------------------------------------------------------------------------------------
        %	AUTHOR SECTION
        %----------------------------------------------------------------------------------------
        \begin{minipage}{0.4\textwidth}
            \begin{flushleft} \large
            \emph{Giảng viên hướng dẫn:} \\
            PGS. TS. Trần Trọng Hiếu % Supervisor's Name
            \end{flushleft}
        \end{minipage}\\[0.5cm]

        \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
        \emph{Học viên thực hiện:}\\
        Nguyễn Chí Thanh \\
        MSHV: 21007925 \\ % Your name
        Lớp: Khoa học dữ liệu - K4
        \end{flushleft}
        \end{minipage}


        % If you don't want a supervisor, uncomment the two lines below and remove the section above
        %\Large \emph{Author:}\\
        %John \textsc{Smith}\\[3cm] % Your name

        %----------------------------------------------------------------------------------------
        %	DATE SECTION
        %----------------------------------------------------------------------------------------

        % I don't want day because it is English
        % {\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

        %----------------------------------------------------------------------------------------
        %	LOGO SECTION
        %----------------------------------------------------------------------------------------

        %\includegraphics{logo/rsz_3logo-khtn.png}\\[1cm] % Include a department/university logo - this will require the graphicx package

        %----------------------------------------------------------------------------------------

        \vfill % Fill the rest of the page with whitespace

    \end{titlepage}

    \cleardoublepage
    \pagenumbering{gobble}
    \tableofcontents
    \newpage
    \listoffigures
    \newpage
    \glsaddall 
    \renewcommand*{\glossaryname}{Danh mục các từ viết tắt}
    \renewcommand*{\acronymname}{Danh sách từ viết tắt}
    \renewcommand*{\entryname}{Viết tắt}
    \renewcommand*{\descriptionname}{Viết đầy đủ}
    \printnoidxglossary
    \cleardoublepage
    \pagenumbering{arabic}

    %\maketitle

    \newpage

    \nocite{*}

    \begin{center}
    \section*{LỜI MỞ ĐẦU}
    \end{center}
    \addcontentsline{toc}{section}{{\bf LỜI MỞ ĐẦU}\rm}

    Các mô hình khuếch tán xác suất (DPMs) là một lớp các mô hình sinh (DGMs) rất mạnh.
    Mặc dù rất được các nhà khoa học quan tâm nhưng quá trình sinh dữ liệu sử dụng phép lặp tốn tài nguyên và ít hiệu quả về mặt tính toán hơn nhiều các mô hình sinh khác ví dụ là mô hình sinh đối kháng (GANs).
    Vậy nên hiệu năng của quá trình sinh trên một tập con của các bước thời gian là rất quan trọng,
    điều này bị ảnh hưởng rất lớn bởi ma trận hiệp phương sai được thiết kế trong DPMs.
    Trong đề tài này, ta xem xét và so sánh sự ảnh hưởng của ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ để khải thiện đáng kể sức mạnh của DPMs.
    Ta sẽ nhận được các kết quả tối ưu cho ma trận hiệp phương sai và hiệu chỉnh khi mà các trung bình của DPMs không hoàn hảo.
    Ma trận hiệp phương sai tối ưu và ma trận hiệp phương sai tối ưu đã được hiệu chỉnh đều có thể được phân tích thành các thành phần kỳ vọng có điều kiện của các hàm của nhiễu.
    Dựa trên điều này ta sẽ đề xuất ước lượng ma trận hiệp phương sao tối ưu và ma trận hiệp phương sai tối ưu được hiệu chỉnh khi biết trung bình không hoàn hảo bằng cách học các kỳ vọng có điều kiện.
    Phương pháp này có thể được áp dụng cho cả trường hợp bước thời gian rời rạc và bước thời gian liên tục.
    Ta sẽ chỉ xem xét ma trận hiệp phương sai đường chéo để làm giảm chi phí tính toán.
    Để tiến hành thực nghiệm hiệu quả, ta sử dụng chiến lược chia sẻ tham số giữa các mô hình và quá trình huấn luyện gồm hai giai đoạn.
    Kết quả thực nghiệm cho thấy phương pháp này vượt trội hơn một lượng lớn và đa dạng các phương pháp thiết kế ma trận hiệp phương sai dựa trên ước lượng hợp lý,
    và cải thiện chất lượng các ảnh được tạo ra đặc biệt dù chỉ trên một số lượng nhỏ bước.
    

        
    \newpage

    \section{Tổng quan về mô hình khuếch tán} \label{Introduction}

    Gần đây, các mô hình khuếch tán xác suất (DPMs) \cite{sohl2015deep}, \cite{ho2020denoising}, \cite{song2020score} đã tạo ra rất nhiều hứa hẹn trong lĩnh vực các mô hình sinh.
    Những mô hình này lần lượt đưa nhiễu vào theo từng bước thời gian vào phân phối dữ liệu gốc tạo nên một quá trình khuếch tán.
    Bằng cách học để đảo ngược quá trình khuếch tán sử dụng mô hình Markov, DPMs có khả năng tạo ra các ảnh chất lượng cao \cite{ho2020denoising}, \cite{song2020score}, \cite{dhariwal2021diffusion},
    các âm thanh chất lượng cao \cite{chen2020wavegrad}, \cite{kong2020diffwave}. 
    Các mô hình này hoàn toàn có khả năng cạnh tranh với các mô hình sinh tân tiến nhất hiện tại \cite{brock2018large}, \cite{wu2019logan}, \cite{karras2020analyzing}, \cite{binkowski2019high}, \cite{kalchbrenner2018efficient}.

    Tuy nhiên, quá trình sinh phải sử dụng một vòng lặp với số bước lớn và trên toàn bộ số bước của DPMs làm cho DPMs yêu cầu chi phí tính toán lớn hơn nhiều và kém hiệu quả hơn so với mô hình sinh đối kháng (GANs) \cite{goodfellow2014generative}.
    Vì vậy khả năng và chất lượng sinh dữ liệu của DPMs trên một tập con các bước là rất quan trọng.
    Trong trường hợp này thì quá trình khuếch tán ngược trở nên rất phức tạp \cite{xiao2021tackling} và thiết kế về ma trận hiệp phương sai trong DPMs trở thành một việc rất quan trọng \cite{nichol2021improved}, \cite{bao2021analytic}.
    Hầu hết các công trình trước đây \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic} sử dụng ma trận hiệp phương sai đẳng hướng mà chỉ phụ thuộc vào bước thời gian mà không phụ thuộc vào trạng thái.
    Một bước phát triển gần đây đáng chú ý là Analytic-DPM \cite{bao2021analytic},
    công trình này ước lượng ma trận hiệp phương sai tối ưu (theo khía cạnh ước lượng hợp lý cực đại) thay vì sử dụng giá trị đặt trước \cite{ho2020denoising}, \cite{song2020denoising} và cho thấy một bước cải thiện đáng kể trên ước lượng hợp lý và hiệu quả lấy mẫu.
    Tuy nhiên ma trận hiệp phương sai đẳng hướng hy sinh sức mạnh của DPMs để mô hình đơn giản hơn.
    Hơn nữa, tính tối ưu của ước lượng ma trận hiệp phương sai trong \cite{bao2021analytic} được duy trì bởi giả định là trung bình tối ưu đã biết trước,
    nhưng điều này không phù hợp trong thực tế.

    Để khắc phục những hạn chế đã được nêu ở trên đồng thời cải thiện thêm khả năng của DPMs dựa trên ước lượng hợp lý và lấy mẫu hiệu quả,
    ta xem xét ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ để cải thiện sức mạnh sinh dữ liệu của DPMs.
    Ta thu được trung bình và ma trận hiệp phương sai tối ưu được xác định từ ước lượng hợp lý cực đại.
    Ta cũng sẽ hiệu chỉnh ma trận hiệp phương sai khi cho trước một trung bình không hoàn hảo (khi trung bình tối ưu được xấp xỉ và có sai lệch với giá trị lý tưởng) theo khía cạnh ước lượng hợp lý.
    Cả ma trận hiệp phương sai tối ưu và ma trận hiệp phương sai tối ưu được hiệu chỉnh có thể được phân tích thành các thành phần là các kỳ vọng có điều kiện là hàm của nhiễu,
    các kỳ vọng này có thể được ước lượng bằng cách hàm mục tiêu sai lệch bình phương trung bình (MSE).
    Mặc dù lý thuyết này có thể được áp dụng cho trường hợp ma trận hiệp phương sai đầy đủ, nhưng trong các thử nghiệm thì ta chỉ xem xét ma trận hiệp phương sai đường chéo để làm giảm chi phí tính toán.
    Bên cạnh đó ta sử dụng chiến lược chia sẻ tham số tạo sự hiệu quả khi chạy suy luận các mô hình và quá trình huấn luyện gồm hai giai đoạn được áp dụng từ các kết quả lý thuyết.

    Phương pháp của chúng ta được áp dụng cho cả bước thời gian rời rạc \cite{ho2020denoising} và bước thời gian liên tục \cite{song2020score}.
    Trong các thí nghiệm, ta sẽ so sánh phương pháp của chúng ta với nhiều phương pháp khác \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic}, \cite{song2020score} về chất lượng dữ liệu được tạo ra và ước lượng hợp lý trong DPMs với cả trường hợp bước thời gian rời rạc và bước thời gian liên tục.
    Với gần như cùng một chi phí tính toán, phương pháp của ta gần như luôn luôn vượt trội hơn so với các phương pháp khác trên ước lượng hợp lý.
    Bên cạnh đó phương pháp của chúng ta cũng tạo ra các dữ liệu có chất lượng tốt hơn trong hầu hết trường hợp đặc biệt là khi số bước dùng để sinh ra dữ liệu nhỏ.

    \section{Mô hình toán học của mô hình khuếch tán} \label{Background}

    \begin{table}[h!]
        \caption{Các ký hiệu được sử dụng trong đề tài}
        \begin{tabular} [c c c] {m{4cm}  m{2.5cm}  m{8cm}}
            \hline
            \multirow{5}{4cm}{Quá trình khuếch tán thuận} & $\overline{\alpha}_n, \overline{\beta}_n$ & Biểu diễn tích lũy của nhiễu Gaussian tại bước thứ $n$, $q(\boldsymbol{x}_n \vert \boldsymbol{x}_0)=\mathcal{N} \big( \boldsymbol{x}_n \vert \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0, \overline{\beta}_n \boldsymbol{I} \big)$ \\ \cline{2-3}
            & $\lambda_n^2$ & Biểu diễn phương sai của quá trình khuếch tán ngược $q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0)$ \\ \cline{2-3}
            & $\tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \boldsymbol{x}_0)$ & Biểu diễn trung bình của quá trình khuếch tán ngược $q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0)$ \\ \cline{2-3}
            & $\gamma_n$ & Biểu diễn hệ số của $\boldsymbol{x}_0$ trong $\tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \boldsymbol{x}_0)$ \\ \cline{2-3}
            & $\alpha_n, \beta_n$ & Biểu diễn lượng nhiễu Gaussian được thêm vào tại từng bước $n$ trong quá trình khuếch tán thuận, $q(\boldsymbol{x}_n \vert \boldsymbol{x}_{n-1})=\mathcal{N}\big( \boldsymbol{x}_n \vert \sqrt{\alpha_n} \boldsymbol{x}_{n-1}, \beta_n \boldsymbol{I} \big)$ \\
            \hline
            \multirow{2}{4cm}{Trung bình của quá trình khuếch tán ngược} & $\boldsymbol{\mu}_n (\boldsymbol{x}_n), \boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ & Biểu diễn trung bình của quá trình khuếch tán ngược $p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)$ và trung bình tối ưu \\ \cline{2-3}
            & $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n), \hat{\boldsymbol{\mu}}_n (\boldsymbol{x}_n)$ & Biểu diễn mạng dự đoán nhiễu và ước lượng của $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ \\
            \hline
            \multirow{4}{4cm}{Ma trận hiệp phương sai của quá trình khuếch tán ngược} & $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n), \boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2$ & Biểu diễn ma trận hiệp phương sai của quá trình khuếch tán ngược và ma trận hiệp phương sai đường chéo tối ưu \\ \cline{2-3}
            & $\boldsymbol{h}_n (\boldsymbol{x}_n), \hat{\boldsymbol{\sigma}}_n (\boldsymbol{x}_n)^2$ & Biểu diễn mạng dự đoán nhiễu bình phương SN và ước lượng của ma trận hiệp phương sai đường chéo tối ưu $\boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2$ \\ \cline{2-3}
            & $\tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2$ & Biểu diễn ma trận hiệp phương sai đường chéo tối ưu với một trung bình không hoàn hảo \\ \cline{2-3}
            & $\boldsymbol{g}_n (\boldsymbol{x}_n), \hat{\tilde{\boldsymbol{\sigma}}}_n^{\ast} (\boldsymbol{x}_n)^2$ & Biểu diễn mạng dự đoán phần dư NPR và ước lượng của $\tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2$ \\
            \hline
        \end{tabular}
    \end{table}

    Các mô hình khuếch tán xác suất (DPMs) là một quá trình Markov đặc biệt với các bước chuyển tiếp là phân phối Gaussian:

    \begin{equation} \label{eq:Reverse-Process}
        p\big(\boldsymbol{x}_{0:N}\big)=p\big(\boldsymbol{x}_N\big)\prod_{n=1}^N p\big(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n\big)
    \end{equation}
    với
    \begin{equation}
        p\big(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n \big)=\mathcal{N} \big( \boldsymbol{x}_{n-1} \vert \boldsymbol{\mu}_n \big( \boldsymbol{x}_n \big), \boldsymbol{\Sigma}_n \big( \boldsymbol{x}_n \big) \big)
    \end{equation}

    Mục tiêu của ta là đảo ngược quá trình khuếch tán thuận $q\big(\boldsymbol{x}_{1:N} \vert \boldsymbol{x}_0\big)$. 
    Quá trình khuếch tán thuận đưa nhiễu vào phân phối dữ liệu $q(\boldsymbol{x}_0)$ một cách từ từ qua từng bước.
    \cite{song2020denoising} xem xét một họ các quá trình khuếch tán thuật mà từng bước được đánh dấu bởi một vector không âm $\lambda = \big( \lambda_1, \dots, \lambda_N \big) \in \mathbb{R}_{\geq 0}^{N}$:

    \begin{equation} \label{eq:Forward-Process}
        q\big(\boldsymbol{x}_{1:N} \vert \boldsymbol{x}_0 \big)=q\big( \boldsymbol{x}_N \vert \boldsymbol{x}_0 \big) \prod_{n=2}^{N} q\big( \boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0 \big)
    \end{equation}

    \begin{equation}
        q\big( \boldsymbol{x}_N \vert \boldsymbol{x}_0 \big)=\mathcal{N} \big( \boldsymbol{x}_N \vert \sqrt{\overline{\alpha}_N} \boldsymbol{x}_0, \overline{\beta}_N \boldsymbol{I} \big)
    \end{equation}

    \begin{equation} \label{eq:Groundtruth-Reverse-Process}
        q\big( \boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0 \big)=\mathcal{N} \big( \boldsymbol{x}_{n-1} \vert \tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \boldsymbol{x}_0), \lambda_n^2 \boldsymbol{I} \big)
    \end{equation}

    \begin{equation}
        \tilde{\boldsymbol{\mu}}_n \big( \boldsymbol{x}_n, \boldsymbol{x}_0 \big)=\sqrt{\overline{\alpha}_{n-1}}\boldsymbol{x}_0 + \sqrt{\overline{\beta}_{n-1} - \lambda_n^2}.\dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n}\boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}
    \end{equation}

    với $\overline{\alpha}_1, \overline{\alpha}_2, \dots, \overline{\alpha}_N \in (0, 1)$ là một dãy giảm ngặt,
    $\overline{\beta}_n := 1 - \overline{\alpha}_n$ và $\boldsymbol{I}$ là ma trận đơn vị.
    Ta nhận thấy $q\big( \boldsymbol{x}_n \vert \boldsymbol{x}_0 \big)=\mathcal{N} \big( \boldsymbol{x}_n \vert \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0, \overline{\beta}_n \boldsymbol{I} \big)$,
    ta có thể lấy mẫu $\boldsymbol{x}_n$ một cách nhanh chóng khi biết trước $\boldsymbol{x}_0$ bằng cách:

    \begin{equation}
        \boldsymbol{x}_n = \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0 + \sqrt{\overline{\beta}_n} \boldsymbol{\epsilon}_n \text{ với } \boldsymbol{\epsilon}_n \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})
    \end{equation}

    Đặt $\alpha_n := \overline{\alpha}_n / \overline{\alpha}_{n-1}, \beta_n := 1 - \alpha_n$ và $\tilde{\beta}_n := \dfrac{\overline{\beta}_{n-1}}{\overline{\beta}_n}\beta_n$.
    Hai quá trình khuếch tán thuật hay được sử dụng là DDPM (tương ứng với $\lambda_n^2=\tilde{\beta}_n$) \cite{ho2020denoising} và DDIM (tương ứng với $\lambda_n^2 = 0$) \cite{song2020denoising}.
    Cụ thể quá trình khuếch tán thuận của DDPM là một quá trình Markov với chuyển tiếp Gaussian tuyến tính:

    \begin{equation}
        q\big( \boldsymbol{x}_n \vert \boldsymbol{x}_{n-1} \big)=\mathcal{N} \big( \boldsymbol{x}_n \vert \sqrt{\alpha}_n \boldsymbol{x}_{n-1}, \beta_n \boldsymbol{I} \big)
    \end{equation}

    Quá trình khuếch tán ngược được học bằng cách cực đại hóa cận dưới (ELBO): $L_{\mathrm{elbo}}=\mathbb{E}_q \log \dfrac{p(\bold{x}_{0:N})}{q(\bold{x}_{1:N}\vert \bold{x}_0)}$ hay tương đương với cực tiểu hóa độ phân kỳ Kullback-Leibler giữa quá trình khuếch tán thuận và quá trình khuếch tán ngược:

    \begin{equation} \label{eq:ELBO-Maximization}
        \max_{\lbrace \boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} L_{\mathrm{elbo}} \Leftrightarrow \min_{\lbrace \boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big)
    \end{equation}

    Bài toán ở công thức \ref{eq:ELBO-Maximization} tối ưu hóa cả trung bình và ma trận hiệp phương sai cùng lúc. 
    Ta gọi là bài toán tối ưu hóa chung.

    Để mô hình đơn giản, các công trình trước \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic} sử dụng ma trận hiệp phương sai đẳng hướng là $\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)=\sigma_n^2 \boldsymbol{I}$ chỉ phụ thuộc vào bước thời gian thứ $n$, $\sigma_n^2$ là phương sai cho từng bước.
    Với giả định này, \cite{bao2021analytic} đã chỉ ra cả trung bình tối ưu $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ và phương sai tối ưu có dạng giải tích tương ứng với kỳ vọng có điều kiện của nhiễu $\mathbb{E}_{q( \boldsymbol{x}_0 \vert \bold{x}_n )} \lbrack \boldsymbol{\epsilon}_n \rbrack$:

    \begin{equation} \label{eq:Optimal-Mean}
        \boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)=\tilde{\boldsymbol{\mu}}_n \Bigg( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \Big( \boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \Big) \Bigg)
    \end{equation}

    \begin{equation} \label{eq:Optimal-Isotropic-Variance}
        \sigma_n^{\ast 2}=\lambda_n^2 + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \Bigg( 1 - \mathbb{E}_{q(\boldsymbol{x}_n)} \dfrac{\lVert \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack\rVert_2^2}{d} \Bigg)
    \end{equation}

    Với $\boldsymbol{\epsilon}_n = \dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}$ là nhiễu được dùng để tạo ra $\boldsymbol{x}_n$ từ $\boldsymbol{x}_0$, $d$ là số chiều của dữ liệu $\boldsymbol{x}_0$ và $\gamma_n = \sqrt{\overline{\alpha}_{n-1}} - \sqrt{\overline{\beta}_{n-1} - \lambda_n^2}\sqrt{\dfrac{\overline{\alpha}_n}{\overline{\beta}_n}}$.
    \cite{ho2020denoising} ước lượng $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ sử dụng một mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$:

    \begin{equation} \label{eq:Estimated-Optimal-Mean}
        \hat{\boldsymbol{\mu}}_n(\boldsymbol{x}_n)=\tilde{\boldsymbol{\mu}}_n \Bigg( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \Big( \bold{x}_n - \sqrt{\overline{\beta}_n} \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n) \Big) \Bigg)
    \end{equation}

    Mạng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ cần phải học được kỳ vọng $\mathbb{E}_{q( \boldsymbol{x}_0 \vert \bold{x}_n )} \lbrack \boldsymbol{\epsilon}_n \rbrack$ bằng cách cực tiểu hóa hàm mục tiêu MSE:

    \begin{equation} \label{eq:Noise-Prediction}
        \min_{\lbrace \hat{\boldsymbol{\epsilon}}_n  \rbrace_{n=1}^N} \mathbb{E}_n  \mathbb{E}_{q(\boldsymbol{x}_0, \boldsymbol{x}_n)} \lVert \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \rVert_2^2
    \end{equation}

    Với $n$ được lấy mẫu theo phân phối đều từ $\lbrace 1, 2, \dots, N \rbrace$.
    Công thức \ref{eq:Noise-Prediction} chỉ ra rằng nghiệm tối ưu khi $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ cần phải học được kỳ vọng $\mathbb{E}_{q( \boldsymbol{x}_0 \vert \bold{x}_n )} \lbrack \boldsymbol{\epsilon}_n \rbrack = \mathbb{E}_{q( \boldsymbol{x}_0 \vert \bold{x}_n )} \lbrack \boldsymbol{\epsilon}_n \rbrack$ với mọi $n \in \lbrace 1, 2, \dots, N \rbrace$.

    Phương sai tối ưu ở công thức \ref{eq:Optimal-Isotropic-Variance} có thể được ước lượng sử dụng mạng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ cần phải học được kỳ vọng $\mathbb{E}_{q( \boldsymbol{x}_0 \vert \bold{x}_n )} \lbrack \boldsymbol{\epsilon}_n \rbrack$ theo \cite{bao2021analytic}:

    \begin{equation}
        \hat{\sigma}_n^{2}=\lambda_n^2 + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \Bigg( 1 - \mathbb{E}_{q(\boldsymbol{x}_n)} \dfrac{\lVert \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)\rVert_2^2}{d} \Bigg)
    \end{equation}

    \section{Phương pháp đề xuất}

    Ta có thể cải thiện ước lượng của ma trận hiệp phương sai của DPMs dựa trên công trình gần đây \cite{bao2021analytic}.
    Đầu tiên ta sẽ xem xét ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ thay vì ma trận hiệp phương sai đẳng hướng để cải thiện khả năng sinh dữ liệu của DPMs và thu được biểu thức của nghiệm tối ưu,
    sẽ được trình bày ở mục \ref{Optimal-Solution-Covariance-Beyond-Isotropic-Covariance}. Tiếp theo ta sẽ hiệu chỉnh ma trận hiệp phương sai tối ưu khi cho một trung bình không hoàn hảo (có xét đến sai số xấp xỉ và tối ưu hóa), sẽ được trình bày ở mục .
    Các chứng minh sẽ được trình bày ở phụ lục \ref{Appen:Section:Proof}.

    Mặc dù các kết quả lý thuyết có thể được áp dụng cho trường ma trận hiệp phương sai đầy đủ (phụ lục \ref{Appen:Section:Results-for-Full-Covariances}), 
    nhưng thường tốn nhiều thời gian để thu được các mẫu dữ liệu từ các bước chuyển tiếp Gaussian với ma trận hiệp phương sai đầy đủ (ví dụ phân tích Cholesky).
    Để cân bằng sự linh hoạt giữa thời gian và chi phí tính toán, ta tập trung vào ma trận hiệp phương sai đường chéo trong xuyên suốt các thực nghiệm.

    \subsection{Lời giải tối ưu cho ma trận hiệp phương sai thay vì sử dụng ma trận hiệp phương sai đẳng hướng} \label{Optimal-Solution-Covariance-Beyond-Isotropic-Covariance}

    Thay vì sử dụng ma trận hiệp phương sai đẳng hướng chỉ dựa vào bước thời gian mà không xét đến trạng thái, ta sẽ xét ma trận hiệp phương sai đường chéo để cải thiện khả năng sinh dữ liệu của DPMs.
    Ta sẽ xây dựng một ví dụ mà phân phối dữ liệu là phân phối trộn của các phân phối Gaussian.
    Ngay cả trong trường hợp đơn giản, ta có thể chứng minh ELBO tối ưu trong \ref{eq:ELBO-Maximization} với một ma trận hiệp phương sai đường chéo luôn lớn hơn trong trường hợp sử dụng ma trận hiệp phương sai đẳng hướng.
    Chứng minh chi tiết được trình bày trong mệnh đề \ref{md:Mixture-Data-Distribution} .

    Về mặt hình thức, ta xét ma trận hiệp phương sai trong dạng $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n)=\mathrm{diag}\big( \boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2 \big)$,
    với $\boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2: \mathbb{R}^d \rightarrow \mathbb{R}^d$ là đường chéo của ma trận hiệp phương sai mà $\mathrm{diag} (.)$ ký hiệu là toán tử biến đổi vector thành ma trận đường chéo.
    Một cách tự nhiên, ta sẽ tối ưu hóa bài toán ở công thức \ref{eq:ELBO-Maximization} ứng với trung bình và ma trận hiệp phương sai để thu được lời giải tối ưu,
    được phát biểu trong định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}. Kết quả cho ma trận hiệp phương sai đầy đủ trong phụ lục \ref{Appen:Section:Results-for-Full-Covariances}.

    \begin{restatable}{dl}{joint} \label{dl:Optimal-Solution-To-Joint-Optimization}
        (Nghiệm tối ưu cho bài toán tối ưu hóa chung) 
        Với ma trận hiệp phương sai có dạng $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n)=\mathrm{diag}\big( \boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2 \big)$.
        Khi đó trung bình tối ưu của bài toán trong công thức \ref{eq:ELBO-Maximization} là $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ được nêu trong công thức \ref{eq:Optimal-Mean},
        và ma trận hiệp phương sai tối ưu của bài toán trong công thức \ref{eq:ELBO-Maximization} là:


        \begin{equation*}
            \boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2 = \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2 \big)
        \end{equation*}

        với $\boldsymbol{\epsilon}_n = \dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}$ là nhiễu được dùng để tạo ra $\boldsymbol{x}_n$ từ $\boldsymbol{x}_0$,
        $(.)^2$ là bình phương từng phần tử của vector, $\boldsymbol{1}$ là vector mà các phần tử đều bằng một và $\gamma_n = \sqrt{\overline{\alpha}_{n-1}} - \sqrt{\overline{\beta}_{n-1} - \lambda_n^2} \sqrt{\dfrac{\overline{\alpha}_n}{\overline{\beta}_n}}$
    \end{restatable}

    Ý tưởng chứng minh định lý \ref{dl:Optimal-Solution-To-Joint-Optimization} tương tự như trong định lý 1 trong \cite{bao2021analytic}, nhưng định lý này chỉ xem xét trong trường hợp ma trận hiệp phương sai đẳng hướng.

    Để ước lượng ma trận hiệp phương sai tối ưu $\boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2$ trong định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}, ta cần phải ước lượng cả hai đại lượng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2$ và $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack$.

    Như đã được đề cập ở mục \ref{Background}, mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ có mục đích ước lượng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack$ bằng cách cực tiểu hóa hàm mục tiêu MSE trong công thức \ref{eq:Noise-Prediction}.
    Vì vậy ta sử dụng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2$ để ước lượng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2$.
    Nhưng cần chú ý rằng sai lệch của $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2$ sẽ bị khuếch đại nhiều hơn so với $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ (chi tiết xem phụ lục \ref{Appen:Subsection:Error-Amplification}).
    Tuy nhiên ta vẫn thấy chất lượng ảnh được tạo ra vẫn khá tốt (mục ).

    Đại lượng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack$ là kỳ vọng có điều kiện của bình phương của nhiễu (SN) $\boldsymbol{\epsilon}_n^2$ điều kiện trên $\boldsymbol{x}_n$.
    Đại lượng kỳ vọng này có thể được ước lượng sử dụng mạng $\boldsymbol{h}_n (\boldsymbol{x}_n) \in \mathbb{R}^d$ được huấn luyện trên hàm mục tiêu MSE:

    \begin{equation} \label{eq:Square-Noise-Prediction-Network-MSE-Loss}
        \min_{\lbrace \boldsymbol{h}_n \rbrace_{n=1}^N} \mathbb{E}_n \mathbb{E}_{q(\boldsymbol{x}_0, \boldsymbol{x}_n)} \lVert \boldsymbol{\epsilon}_n^2 - \boldsymbol{h}_n (\boldsymbol{x}_n) \rVert_2^2
    \end{equation}

    Với $n$ được lấy mẫu theo phân phối đều từ $\lbrace 1, 2, \dots, N \rbrace$ và $\boldsymbol{h}_n (\boldsymbol{x}_n)$ cố gắng dự đoán bình phương của nhiễu $\boldsymbol{\epsilon}_n^2$ khi cho trước $\boldsymbol{x}_n$.
    Ta gọi $\boldsymbol{h}_n (\boldsymbol{x}_n)$ là mạng dự đoán nhiễu bình phương (SN).
    Công thức \ref{eq:Square-Noise-Prediction-Network-MSE-Loss} cho thấy nghiệm tối ưu xảy ra khi $\boldsymbol{h}_n (\boldsymbol{x}_n) = \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack$ với mọi $n \in \lbrace 1, 2, \dots, N \rbrace$.

    Bằng cách ước lượng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2$ với $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2$ và $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack$ với $\boldsymbol{h}_n (\boldsymbol{x}_n)$,
    ta có thể ước lượng:

    \begin{equation} \label{eq:Sigma-SN-SPM}
        \hat{\boldsymbol{\sigma}}_n (\boldsymbol{x}_n)^2 = \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \boldsymbol{h}_n (\boldsymbol{x}_n) - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2 \big)
    \end{equation}

    Trong tiểu luận này ta gọi công thức trên ước lượng trên là SN-DPM.

    \subsection{Ma trận hiệp phương sai tối ưu với trung bình không hoàn hảo}

    Ta thấy việc ước lượng $\hat{\boldsymbol{\mu}}_n (\boldsymbol{x}_n)$ và $\hat{\boldsymbol{\sigma}}_n (\boldsymbol{x}_n)^2$ là việc hoàn toàn cần thiết theo định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}.
    Tuy nhiên, định lý \ref{dl:Optimal-Solution-To-Joint-Optimization} chỉ cho ta lời giải tối ưu $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ và $\boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2$.
    Nhưng hai đại lượng này ta không thể tính toán được một cách chính xác do có thành phần kỳ vọng có điều kiện trên hàm của nhiễu $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack$.
    Đại lượng này không thể được tính chính xác do sai lệch xấp xỉ và sai lệch của quá trình tối ưu hóa,
    điều này gợi ý ta có thể cải thiện các ước lượng này khi xem xét đến sai lệch.

    Ta nhận thấy rằng trong định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}, trung bình tối ưu không phù hợp với ma trận hiệp phương sai tối ưu khi mà ma trận hiệp phương sai tối ưu được biểu diễn qua trung bình tối ưu.
    Một cách tự nhiên, ta sẽ tối ưu duy nhất trung bình để thu được ước lượng của trung bình tối ưu $\hat{\boldsymbol{\mu}}_n$ và sau đó với tối ưu ma trận hiệp phương sai khi đã biết trung bình tối ưu $\hat{\boldsymbol{\mu}}_n$.
    Cách tiếp cận hai giai đoạn này ít nhất không tệ hơn so với cách tiếp cận ở mục \ref{Optimal-Solution-Covariance-Beyond-Isotropic-Covariance} theo khía cạnh ước lượng hợp lý bởi vì:

    \begin{equation}
        L_{\mathrm{elbo}}\big( \hat{\boldsymbol{\mu}}_n, \hat{\boldsymbol{\sigma}}_n (\boldsymbol{x}_n)^2 \big) \leq \max_{\boldsymbol{\sigma}_n (.)^2 } L_{\mathrm{elbo}} \big( \hat{\boldsymbol{\mu}}_n, \boldsymbol{\sigma}_n (.)^2 \big)
    \end{equation}

    Và dấu bằng về cơ bản không xảy ra.

    Để diễn giải ý tưởng, ta thu được các lời giải tối ưu bằng cách giải hai bài toán:

    \begin{equation} \label{eq:Arbitrary-Covariance-Optimize-Mean}
        \text{Cho ma trận hiệp phương sai bất kỳ } \boldsymbol{\Sigma}_n, \max_{\lbrace \boldsymbol{\mu}_n \rbrace_{n=1}^N} L_{\mathrm{elbo}}
    \end{equation}

    \begin{equation} \label{eq:Arbitrary-Mean-Optimize-Covariance}
        \text{Cho trung bình bất kỳ } \boldsymbol{\mu}_n, \max_{\lbrace \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} L_{\mathrm{elbo}}
    \end{equation}

    \begin{restatable}{dl}{mean} \label{dl:Solely-Optimal-Mean}
        (Lời giải tối ưu của bài toán tối ưu duy nhất với trung bình)
        Với ma trận hiệp phương sai bất kỳ $\boldsymbol{\Sigma}_n$,
        trung bình tối ưu của bài toán trong công thức \ref{eq:Arbitrary-Covariance-Optimize-Mean} luôn luôn là trung bình tối ưu trong công thức \ref{eq:Optimal-Mean}:

        \begin{equation*}
            \boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)=\tilde{\boldsymbol{\mu}}_n \Bigg( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \Big( \boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \Big) \Bigg)
        \end{equation*}

        không phù hợp với $\boldsymbol{\Sigma}_n$.
    \end{restatable}

    Định lý \ref{dl:Solely-Optimal-Mean} cho thấy rằng trung bình tối ưu không phụ thuộc vào ma trận hiệp phương sai và vì vậy ta sẽ học trung bình theo công thức \ref{eq:Noise-Prediction} mà không cần biết thông tin về ma trận hiệp phương sai.

    Ngược lại với trung bình, ma trận hiệp phương sai tối ưu của bài toán \ref{eq:Arbitrary-Mean-Optimize-Covariance} phụ thuộc vào trung bình sẽ được trình bày trong định lý .
    Kết quả cho ma trận hiệp phương sai đầy đủ được trình bày chi tiết ở phụ lục \ref{Appen:Section:Results-for-Full-Covariances}.

    \begin{restatable}{dl}{covariance} \label{dl:Solely-Optimal-Covariance}
        (Lời giải tối ưu của bài toán tối ưu duy nhất với ma trận hiệp phương sai)
        Ta giả định $\boldsymbol{\Sigma}_n = \mathrm{diag} \big( \boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2 \big)$.
        Với trung bình bất kỳ $\boldsymbol{\mu}_n (\boldsymbol{x}_n)$ được tham số hóa bởi mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ như trong công thức \ref{eq:Estimated-Optimal-Mean},
        ma trận hiệp phương sai tối ưu của bài toán trong công thức \ref{eq:Arbitrary-Mean-Optimize-Covariance} là:

        \begin{equation} \label{eq:Corrected-Optimal-Covariance}
            \begin{aligned}
                \tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2 &= \boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2 + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \underbrace{\big( \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n) \lbrack \boldsymbol{\epsilon}_n \rbrack} \big)^2}_{\mathrm{error}} \\
                &= \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \Big\lbrack \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2 \Big\rbrack
            \end{aligned}
        \end{equation}

        Với $\boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2$ là ma trận hiệp phương sai tối ưu của bài toán tối ưu hóa chung ở định lý \ref{dl:Optimal-Solution-To-Joint-Optimization},
        $\boldsymbol{\epsilon}_n = \dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}$ là nhiễu được dùng để tạo ra $\boldsymbol{x}_n$ từ $\boldsymbol{x}_0$,
        $(.)^2$ là bình phương từng phần tử của vector, $\boldsymbol{1}$ là vector mà các phần tử đều bằng một và $\gamma_n = \sqrt{\overline{\alpha}_{n-1}} - \sqrt{\overline{\beta}_{n-1} - \lambda_n^2} \sqrt{\dfrac{\overline{\alpha}_n}{\overline{\beta}_n}}$.
    \end{restatable}

    Chứng minh của định lý \ref{dl:Solely-Optimal-Covariance} chủ yếu dựa trên việc cực tiểu hóa độ phân kỳ Kullback-Leibler giữa mật độ xác suất mục tiêu và một hàm mật độ Gaussian có điều kiện trên trung bình cố định tương đương với đầu tiên thu được moment bậc hai của hàm mật độ xác suất mục tiêu,
    sau đó hiệu chỉnh bằng sai lệch giữa momen bậc nhất của hai hàm mật độ xác suất.
    Ta gọi là hàm hiệu chỉnh momen có điều kiện.

    Định lý \ref{dl:Solely-Optimal-Covariance} cho ta thấy rằng ma trận hiệp phương sai tối ưu của bài toán tối ưu hóa chung trong định lý \ref{dl:Optimal-Solution-To-Joint-Optimization} cần được hiệu chỉnh vì sai lệch của mạng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ hay $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \neq \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon} \rbrack$ là không thể tránh khỏi do sai số của quá trình tối ưu hóa của các phương pháp tối ưu hóa dựa trên đạo hàm riêng.

    Công thức \ref{eq:Corrected-Optimal-Covariance}, ma trận hiệp phương sai tối ưu đã được hiệu chỉnh $\tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2$ được xác định qua $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \Big\lbrack \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2 \Big\rbrack$.
    Ta học đại lượng này bằng cách huấn luyện một mạng $\boldsymbol{g}_n (\boldsymbol{x}_n) \in \mathbb{R}^d$ dự đoán $\big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2$ khi biết $\boldsymbol{x}_n$ bằng cách cực tiểu hóa hàm mục tiêu MSE:

    \begin{equation} \label{eq:Square-Noise-Residual-Prediction-Network-MSE-Loss}
        \min_{\lbrace \boldsymbol{g}_n \rbrace_{n=1}^N} \mathbb{E}_n \mathbb{E}_{q(\boldsymbol{x}_0, \boldsymbol{x}_n)} \lVert \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2 - \boldsymbol{g}_n (\boldsymbol{x}_n)  \rVert_2^2
    \end{equation}

    Với $n$ được lấy mẫu theo phân phối đều từ $\lbrace 1, 2, \dots, N \rbrace$.
    Thành phần $\big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2$ được gọi là phần dư nhiễu (NPR),
    hay chính là phần dư giữa nhiễu thực tế $\boldsymbol{\epsilon}_n$ và nhiễu được dự đoán bởi mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$,
    ta gọi mạng $\boldsymbol{g}_n (\boldsymbol{x}_n)$ là mạng dự đoán phần dư nhiễu.
    Công thức \ref{eq:Square-Noise-Residual-Prediction-Network-MSE-Loss} cho thấy lời giải tối ưu xảy ra khi $\boldsymbol{g}_n (\boldsymbol{x}_n) = \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \Big\lbrack \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2 \Big\rbrack$ với mọi $n \in \lbrace 1, 2, \dots, N \rbrace$.
    Một điều cần chú ý rằng, trái với $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2$ được sử dụng trong SN-DPM,
    mạng $\boldsymbol{g}_n (\boldsymbol{x}_n)$ không có vấn đề khuếch đại sai số (chi tiết được trình bày trong phụ lục \ref{Appen:Subsection:Error-Amplification}).
    Với mạng dự đoán phần dư nhiễu $\boldsymbol{g}_n (\boldsymbol{x}_n)$ trong công thức \ref{eq:Square-Noise-Residual-Prediction-Network-MSE-Loss},
    ta ước lượng $\tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2$ bằng công thức:

    \begin{equation} \label{eq:Sigma-NPR-DPM}
        \hat{\tilde{\boldsymbol{\sigma}}}_n (\boldsymbol{x}_n)^2 = \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \boldsymbol{g}_n (\boldsymbol{x}_n)
    \end{equation}

    Trong tiểu luận ta gọi ước lượng này là SNR-DPM.

    \section{Thực thi} \label{Implementation}

    Trong mục này ta sẽ trình bày chi tiết thực thi SN-DPM và NPR-DPM.
    Đặc biệt ta thiết kế chiến lược sử dụng chia sẻ tham số để tăng độ hiệu quả khi chạy suy luận trong mục \ref{Parameter-Sharing-And-Inference-Efficiency}.
    Sử dụng định lý \ref{dl:Solely-Optimal-Mean} và định lý \ref{dl:Solely-Optimal-Covariance}, ta sử dụng quá trình huấn luyện hai giai đoạn cho cả SN-DPM và NPR-DPM trong mục .

    \subsection{Chia sẻ tham số và suy luận hiệu quả} \label{Parameter-Sharing-And-Inference-Efficiency}

    Trong quá trình chạy suy luận, cả SN-DPM và NPR-DPM cần được chạy cả hai mạng.
    Để giảm chi phí tính toán, ta sử dụng phương pháp chia sẻ tham số giữa hai mạng như sau:

    \begin{equation} \label{eq:Parameter-Sharing-Scheme}
        \begin{aligned}
        \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) &= \mathrm{NN}_1 (\mathrm{UNet}(\boldsymbol{x}_n, n ; \boldsymbol{\theta}); \boldsymbol{\phi}_1) \\
        \boldsymbol{h}_n (\boldsymbol{x}_n) \text{ hoặc } \boldsymbol{g}_n (\boldsymbol{x}_n) &= \mathrm{NN}_2(\mathrm{UNet}(\boldsymbol{x}_n, n; \boldsymbol{\theta}); \boldsymbol{\phi}_2)
        \end{aligned}
    \end{equation}

    Với $\mathrm{UNet}$ là một trong những cấu trong rất phổ biến trong DPMs \cite{ho2020denoising}, \cite{song2020score} và được tham số hóa bởi tham số được chia sẻ $\boldsymbol{\theta}$,
    $\mathrm{NN}_1$ và $\mathrm{NN}_2$ là hai mạng nhỏ ví dụ mạng bao gồm một bài lớp tích chập và được tham số hóa bởi $\boldsymbol{\phi}_1$ và $\boldsymbol{\phi}_2$ tương ứng.

    So với DPMs thông thường với cùng cấu trúc $\mathrm{UNet}$, cả SN-DPM và NPR-DPM đều yêu cầu thêm chi phí bộ nhớ không lớn và thêm khoảng 10\% chi phí tính toán (chi tiết ở phụ lục \ref{Appen:Subsection:Details-of-Memory-and-Time-Cost}).

    \subsubsection{Quá trình học hai giai đoạn và tiền huấn luyện}

    Ta nhắc lại trung bình tối ưu của bài toán trong công thức \ref{eq:Arbitrary-Covariance-Optimize-Mean} không phù hợp với ma trận hiệp phương sai.
    Vì vậy, một cách tự nhiên học trung bình và phương sai có thể chia làm hai giai đoạn.
    Trong giai đoạn đầu tiên, ta học trung bình bằng cách huấn luyện mạng dự đoán nhiễu ở công thức \ref{eq:Noise-Prediction},
    hoặc chỉ cần sử dụng một mạng đã được tiền huấn luyện từ các công trình trước.
    Trong giai đoạn hai, ta sẽ cố định các tham số trong mạng dự đoán nhiễu, để mạng $\mathrm{UNet}$ là một mạng tiền huấn luyện và chỉ học ma trận hiệp phương sai bằng cách chỉnh định tham số $\boldsymbol{\phi}_2$ trong công thức \ref{eq:Parameter-Sharing-Scheme} của mạng SN-DPM hoặc NPR-DPM sử dụng đạo hàm riêng của công thức \ref{eq:Square-Noise-Prediction-Network-MSE-Loss} hoặc công thức \ref{eq:Square-Noise-Residual-Prediction-Network-MSE-Loss}:

    \begin{equation}
        \begin{aligned}
        &\nabla_{\boldsymbol{\phi}_1} \mathbb{E}_n \mathbb{E}_{q(\boldsymbol{x}_0, \boldsymbol{x}_n)} \lVert \boldsymbol{\epsilon}_n^2 - \boldsymbol{h}_n (\boldsymbol{x}_n) \rVert_2^2, \text{ hoặc} \\
        &\nabla_{\boldsymbol{\phi}_2} \mathbb{E}_n \mathbb{E}_{q(\boldsymbol{x}_0, \boldsymbol{x}_n)} \lVert \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2 - \boldsymbol{g}_n (\boldsymbol{x}_n) \rVert_2^2
        \end{aligned}
    \end{equation}

    Ta cần chú ý rằng phương pháp tiền huấn luyện cho giai đoạn hai chỉ cần chỉnh định một mạng nhỏ $\mathrm{NN}_2$ mà không cần chỉnh định $\mathrm{UNet}$.
    Thuật toán \ref{alg:Learning-of-the-SN-prediction-network} và thuật toán \ref{alg:Learning-of-the-NPR-prediction-network} trình bày thủ tục huấn luyện hai giai đoạn.
    
    \begin{algorithm}[h!]
        \DontPrintSemicolon
        \KwIn{Mạng dự đoán bình phương nhiễu (SN) $\boldsymbol{h}_n (\boldsymbol{x}_n)$ và tham số được huấn luyện $\boldsymbol{\phi}_2$}
        \Repeat{hội tụ}{
            $\boldsymbol{x}_0 \sim q(\boldsymbol{x}_0)$\;
            $n \sim \mathrm{Uniform}\big( \lbrace 1, 2, \dots, N \rbrace\big)$\;
            $\boldsymbol{\epsilon}_n \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})$\;
            $\boldsymbol{x}_n \gets \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0 + \sqrt{\overline{\beta}_n} \boldsymbol{\epsilon}_n$\;
            Chỉnh định $\boldsymbol{\phi}_2$ dựa trên đạo hàm riêng $\nabla_{\boldsymbol{\phi}_2}  \lVert \boldsymbol{\epsilon}_n^2 - \boldsymbol{h}_n (\boldsymbol{x}_n) \rVert_2^2$
        }
        \caption{Thủ tục huấn luyện mạng dự đoán nhiễu bình phương (SN)}
        \label{alg:Learning-of-the-SN-prediction-network}
    \end{algorithm}

    \begin{algorithm}[h!]
        \DontPrintSemicolon
        \KwIn{Mạng dự đoán phần dư nhiễu (NPR) $\boldsymbol{g}_n (\boldsymbol{x}_n)$ và tham số được huấn luyện $\boldsymbol{\phi}_2$;
        mạng dự đoán nhiễu đã được tiền huấn luyện $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$}
        \Repeat{hội tụ}{
            $\boldsymbol{x}_0 \sim q(\boldsymbol{x}_0)$\;
            $n \sim \mathrm{Uniform}\big( \lbrace 1, 2, \dots, N \rbrace\big)$\;
            $\boldsymbol{\epsilon}_n \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})$\;
            $\boldsymbol{x}_n \gets \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0 + \sqrt{\overline{\beta}_n} \boldsymbol{\epsilon}_n$\;
            Chỉnh định $\boldsymbol{\phi}_2$ dựa trên đạo hàm riêng $\nabla_{\boldsymbol{\phi}_2}  \lVert \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^2 - \boldsymbol{g}_n (\boldsymbol{x}_n) \rVert_2^2$
        }
        \caption{Thủ tục huấn luyện mạng dự đoán phần dư nhiễu (NPR)}
        \label{alg:Learning-of-the-NPR-prediction-network}
    \end{algorithm}

    \section{Mở rộng sang mô hình khuếch tán xác suất với bước thời gian liên tục} \label{Extension-to-DPMs-with-Continuous-Timesteps}

    \cite{song2020score} tổng quát hóa DPMs sang bước thời gian liên tục bằng cách sử dụng một phương trình vi phân ngẫu nhiên (SDE) $d \boldsymbol{x}=f(t) \boldsymbol{x} dt + g(t) d \boldsymbol{w}$,
    với $f(t), g(t)$ là hai hàm vô hướng biết trước và $\boldsymbol{w}$ là quá trình Wiener.
    Phương trình vi phân ngẫu nhiên SDE có thể được xem như là phiên bản liên tục của quá trình khuếch tán thuận ở công thức \ref{eq:Forward-Process}.
    Quá trình này xây dựng một quá trình khuếch tán $\lbrace \boldsymbol{x}_t \rbrace_{t=0}^T$ được đánh chỉ số bởi các bước thời gian liên tục $t \in \lbrack 0, T \rbrack$,
    với $\boldsymbol{x}_0$ tuân theo phân phối dữ liệu ban đầu $q(\boldsymbol{x}_0)$.
    Với 2 số $s, t$ thỏa mãn: $0 \leq s < t \leq T$, phân phối có điều kiện của $\boldsymbol{x}_t$ khi biết trước $\boldsymbol{x}_s$ là: $q(\boldsymbol{x}_t \vert \boldsymbol{x}_s)=\mathcal{N}(\boldsymbol{x}_t, \sqrt{\alpha_{t \vert s}} \boldsymbol{x}_t, \beta_{t \vert s} \boldsymbol{I})$ với $\alpha_{t \vert s}=\exp\Big(2\displaystyle\int_{s}^{t} f(\tau)d \tau \Big)$ và $\beta_{t \vert s}= \displaystyle\int_{s}^{t} g(\tau)^2 \alpha_{t \vert \tau} d \tau$.
    Theo \cite{bao2021analytic}, \cite{kingma2021variational}, ta đảo ngược quá trình khuếch tán thuận từ bước thời gian $t$ đến $s$ bằng phân phối $p(\boldsymbol{x}_s \vert \boldsymbol{x}_t) = \mathcal{N}\big( \boldsymbol{x}_s \vert \boldsymbol{\mu}_{s \vert t} (\boldsymbol{x}_t), \boldsymbol{\Sigma}_{s \vert t} (\boldsymbol{x}_t) \big) (0 \leq s < t \leq T)$, được huấn luyện bằng hàm mục tiêu:

    \begin{equation}
        \min_{\boldsymbol{\mu}_{s \vert t}, \boldsymbol{\Sigma}_{s \vert t}} \ell_{s, t} := \mathbb{E}_{q(\boldsymbol{x}_t)} D_{\mathrm{KL}} \big( q(\boldsymbol{x}_s \vert \boldsymbol{x}_t) \Vert p(\boldsymbol{x}_s \vert \boldsymbol{x}_t) \big)
    \end{equation}
    
    Với $q(\boldsymbol{x}_t)$ là phân phối xác suất cận biên của $\boldsymbol{x}_t$. Tương tự như lời giải tối ưu trong công thức \ref{eq:Optimal-Mean} và công thức \ref{eq:Optimal-Isotropic-Variance}, \cite{bao2021analytic} thu được trung bình tối ưu:

    \begin{equation} \label{eq:Continuous-Optimal-Mean}
        \boldsymbol{\mu}_{s \vert t}^{\ast} (\boldsymbol{x}_t) = \dfrac{1}{\sqrt{\alpha_{t \vert s}}}\Big( \boldsymbol{x}_t - \dfrac{\beta_{s \vert t}}{\sqrt{\beta_{t \vert 0}}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \Big)
    \end{equation}

    Với $\boldsymbol{\epsilon}_t = \dfrac{\boldsymbol{x}_t - \sqrt{\alpha_{t \vert 0}} \boldsymbol{x}_0}{\sqrt{\beta_{t \vert 0}}}$ cũng như ma trận hiệp phương sai đẳng hướng tối ưu $\sigma_{s \vert t}^{\ast 2} \boldsymbol{I}$.
    Tương tự như công thức \ref{eq:Noise-Prediction}, một mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t)$ được dùng để học $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)}  \lbrack \boldsymbol{\epsilon}_t \rbrack$,
    ta thu được một ước lượng của trung bình tối ưu:

    \begin{equation} \label{eq:Estimated-Continuous-Optimal-Mean}
        \hat{\boldsymbol{\mu}}_{s \vert t} (\boldsymbol{x}_t) = \dfrac{1}{\sqrt{\alpha_{t \vert s}}} \Big( \boldsymbol{x}_t - \dfrac{\beta_{t \vert s}}{\sqrt{\beta_{t \vert 0}}} \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) \Big)
    \end{equation}

    Ta sẽ mở rộng định lý \ref{dl:Optimal-Solution-To-Joint-Optimization} cho DPMs với bước thời gian liên tục.
    Ta thu được lời giải toán tối ưu cho bài toán \ref{eq:ELBO-Maximization} khi $\boldsymbol{\Sigma}_{s \vert t} (\boldsymbol{x}_t)=\mathrm{diag}\big(\boldsymbol{\sigma}_{s \vert t} (\boldsymbol{x}_t)^2 \big)$ được trình bày trong mệnh đề \ref{md:Continuous-Optimal-Covariance}.

    \begin{restatable}{md}{continuousoptimalcovariance} \label{md:Continuous-Optimal-Covariance}
        Với ma trận hiệp phương sai có dạng $\boldsymbol{\Sigma}_{s \vert t} (\boldsymbol{x}_t)=\mathrm{diag}\big(\boldsymbol{\sigma}_{s \vert t} (\boldsymbol{x}_t)^2 \big)$.
        Khi đó trung bình tối ưu của bài toán trong công thức \ref{eq:ELBO-Maximization} là $\boldsymbol{\mu}_{s \vert t}^{\ast} (\boldsymbol{x}_t)$ được nêu trong công thức \ref{eq:Continuous-Optimal-Mean} và ma trận hiệp phương sai tối ưu của bài toán trong công thức \ref{eq:ELBO-Maximization} là:

        \begin{equation*}
            \boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2 = \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \Big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack^2 \Big)
        \end{equation*}

        Với $\boldsymbol{\epsilon}_t = \dfrac{\boldsymbol{x}_t - \sqrt{\alpha_{t \vert 0}} \boldsymbol{x}_0}{\sqrt{\beta_{t \vert 0}}}$ là nhiễu được sử dụng để tạo ra $\boldsymbol{x}_t$ từ $\boldsymbol{x}_0$ và $\tilde{\beta}_{s \vert t} = \dfrac{\beta_{s \vert 0}}{\beta_{t \vert 0}} \beta_{t \vert s}$.
    \end{restatable}

    Tiếp theo, ta sẽ  mở rộng định lý \ref{dl:Solely-Optimal-Covariance} cho DPMs với bước thời gian liên tục.
    Tương tự như các bài toán ở công thức \ref{eq:Arbitrary-Covariance-Optimize-Mean} và công thức \ref{eq:Arbitrary-Mean-Optimize-Covariance},
    ta xét hai bài toán tối ưu hóa sau với duy nhất trung bình và ma trận hiệp phương sai:

    \begin{equation} \label{eq:Continuous-Arbitrary-Covariance-Optimize-Mean}
        \text{Cho ma trận hiệp phương sai bất kỳ } \boldsymbol{\Sigma}_{s \vert t}, \min_{\boldsymbol{\mu}_{s \vert t}} \ell_{s, t}
    \end{equation}

    \begin{equation} \label{eq:Continuous-Arbitrary-Mean-Optimize-Covariance}
        \text{Cho trung bình bất kỳ } \boldsymbol{\mu}_{s \vert t}, \min_{\boldsymbol{\Sigma}_{s \vert t}} \ell_{s, t}
    \end{equation}

    Trung bình tối ưu của bài toán trong công thức \ref{eq:Continuous-Arbitrary-Covariance-Optimize-Mean} cũng là công thức \ref{eq:Continuous-Optimal-Mean}, trung bình tối ưu này không phù hợp với $\boldsymbol{\Sigma}_{s \vert t}$.
    Ma trận hiệp phương sai tối ưu của bài toán trong công thức \ref{eq:Continuous-Arbitrary-Mean-Optimize-Covariance} được trình bày trong mệnh đề \ref{md:Continuous-Corrected-Optimal-Covariance}.

    \begin{restatable}{md}{continuouscorrectedoptimalcovariance} \label{md:Continuous-Corrected-Optimal-Covariance}
        Ta giả định ma trận hiệp phương sai có dạng $\boldsymbol{\Sigma}_{s \vert t} (\boldsymbol{x}_t) = \mathrm{diag} \big( \boldsymbol{\sigma}_{s \vert t} (\boldsymbol{x}_t)^2 \big)$.
        Với trung bình bất kỳ $\boldsymbol{\mu}_{s \vert t}(\boldsymbol{x}_t)$ được tham số hóa bởi mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t)$ trong công thức \ref{eq:Estimated-Continuous-Optimal-Mean},
        ma trận hiệp phương sai tối ưu $\tilde{\boldsymbol{\sigma}}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$ của bài toán trong công thức \ref{eq:Continuous-Arbitrary-Mean-Optimize-Covariance} là:

        \begin{equation}
            \begin{aligned}
                \tilde{\boldsymbol{\sigma}}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2 &= \boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2 + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \underbrace{\big( \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \epsilon_t \rbrack \big)^2}_{\mathrm{error}} \\
                &= \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \big \lbrack \big( \boldsymbol{\epsilon}_t - \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) \big)^2 \big \rbrack
            \end{aligned}
        \end{equation}

        Với $\boldsymbol{\epsilon}_t = \dfrac{\boldsymbol{x}_t - \sqrt{\alpha_{t \vert 0}} \boldsymbol{x}_0}{\sqrt{\beta_{t \vert 0}}}$ là nhiễu được dùng để tạo ra $\boldsymbol{x}_t$ từ $\boldsymbol{x}_0$ và $\tilde{\beta}_{s \vert t} = \dfrac{\beta_{s \vert 0}}{\beta_{t \vert 0}} \beta_{t \vert s}$.
    \end{restatable}

    Tương tự như trong công thức \ref{eq:Sigma-SN-SPM} và công thức \ref{eq:Sigma-NPR-DPM},
    để ước lượng $\boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$ và $\tilde{\boldsymbol{\sigma}}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$,
    ta có thể học các kỳ vọng có điều kiện xuất hiện trong mệnh đề \ref{md:Continuous-Optimal-Covariance} và mệnh đề \ref{md:Continuous-Corrected-Optimal-Covariance} bằng cách cực tiểu hóa hàm mục tiêu MSE.
    Chi tiết được trình bày trong phụ lục \ref{Appen:Section:Extention-to-DPMs-with-Continuous-Timesteps}.

    \section{Thực nghiệm}

    Ta đánh giá SN-DPM và NPR-DPM trong DPMs với cả bước thời gian rời rạc và bước thời gian liên tục.

    Với DPMs bước thời gian rời rạc (mục \ref{Background}), ta xem xét quá trình khuếch tán thuận DDPM (Denoising Diffusion Probabilistic Models) (tương ứng với $\lambda_n^2 = \tilde{\beta}_n$ ở công thức \ref{eq:Groundtruth-Reverse-Process}),v
    và quá trình khuếch tán thuận DDIM (Denoising Diffusion Implicit Models) (tương ứng với $\lambda_n^2 = 0$ trong công thức \ref{eq:Groundtruth-Reverse-Process}).
    Một cách tường minh ta gọi các phương pháp NPR-DDPM và NPR-DDIM (hoặc SN-DDPM và SN-DDPM). Ta so sánh các phương pháp này với các phưng pháp:

    \begin{itemize}
        \item DDPM gốc \cite{ho2020denoising}, sử dụng ma trận hiệp phương sai được đặt trước $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n)=\tilde{\beta}_n \boldsymbol{I}$ hoặc $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n) = \beta_n \boldsymbol{I}$.
        \item DDIM gốc \cite{song2020denoising}, sử dụng ma trận hiệp phương sai được đặt trước $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n) = \lambda_n^2 \boldsymbol{I} = \boldsymbol{0}$.
        \item Analytic-DPM \cite{bao2021analytic} được trình bày ở mục \ref{Background}.
    \end{itemize}

    Với bước thời gian liên tục (ở mục \ref{Extension-to-DPMs-with-Continuous-Timesteps}), ta xét VP SDE \cite{song2020score} làm quá trình khuếch tán thuận.
    Ta so sánh phương pháp đề xuất với các phương pháp sau:

    \begin{itemize}
        \item Euler-Maruyama solver \cite{song2020score}, phương pháp này đầu tiên sẽ đảo ngược quá trình khuếch tán thuận VP SDE và sau đó sẽ rời rạc hóa quá trình khuếch tán ngược sử dụng Euler-Maruyama solver.
        \item Ancestral sampling \cite{song2020score}, phưng pháp này thiết kế một chuỗi Markov tương tự như công thức \ref{eq:Reverse-Process} và lấy mẫu từ chuỗi Markov.
        \item Probabity flow \cite{song2020score}, xấp xỉ một phương trình vi phân thường (ODE) tương đương với phương trình vi phân ngẫu nhiên (SDE) và sau đó rời rạc hóa phương trình vi phân thừng này.
        \item Analytic-DPM \cite{bao2021analytic} được trình bày ở mục \ref{Background}.
        \item "Gotta Go Fast" SDE solver \cite{jolicoeur2021gotta} sử dụng độ dài bước thích nghi.
    \end{itemize}

    Vì khả năng và chất lượng sinh dữ liệu của DPMs trên một tập con các bước là rất quan trọng nên ta so sánh các phương pháp đề xuất với các phương pháp nêu trên với ràng buộc trên một quỹ đạo
    $1 \leq \tau_1 < \dots < \tau_K = N$ với số lượng bước thời gian $K$ khác nhau \cite{song2020denoising}, \cite{bao2021analytic} (chi tiết áp dụng các phương pháp vào quỹ đạo được trình bày trong phụ lục \ref{Appen:Section:Inference-on-Trajectories}).
    Theo \cite{bao2021analytic}, ta xem xét hai kiểu quỹ đạo. Kiểu đầu tiên là quỹ đạo chẵn (ET) \cite{nichol2021improved}, các bước thời gian được cách đều nhau. Kiểu thứ hai là quỹ đạo tối ưu (OT) \cite{watson2021learning}, 
    các bước thời gian được xác định bằng quy hoạch động làm cực đại hóa ELBO.

    Ta đánh giá phương pháp đề xuất trên sáu mạng dự đoán nhiễu được tiền huấn luyện từ các công trình trước \cite{ho2020denoising}, \cite{song2020denoising}, \cite{nichol2021improved}, \cite{bao2021analytic}.
    Ba trong số các mạng trên được huấn luyện trên tập CIFAR10 \cite{krizhevsky2009learning} với lịch trình phưng sai tuyến tính (LS) của $\beta_n$ \cite{ho2020denoising},
    lịch trình phương sai cosine (CS) của $\beta_n$ \cite{nichol2021improved} và VP SDE \cite{song2020score} tương ứng.
    Hai cấu hình đầu tiên là CIFAR10 (LS) và CIFAR10 (CS) tương ứng có bước thời gina rời rạc, cấu hình cuối cùng là CIFAR10 (VP SDE) có bước thời gian liên tục.
    Các mạng tiền huấn luyện còn lại được huấn luyện với bước thời gian rời rạc trên tập CelebA 64x64 \cite{liu2015deep}, ImageNet 64x64 \cite{deng2009imagenet} và LSUN Bedroom \cite{yu2015lsun} tương ứng.
    Ta huấn luyện mạng dự đoán phần dư nhiễu NPR hoặc mạng dự đoán bình phương nhiễu SN với tất cả các mạng trên, theo cách thực thi đã được trình bày ở mục \ref{Implementation}.
    Chi tiết của thực nghiệm được trình bày ở phụ lục \ref{Experimental-Details}.

    \subsection{Chất lượng mẫu}

    Trong mục này, ta so sánh chất lượng mẫu dữ liệu được sinh ra theo phương pháp định lượng, được đo lường bởi khoảng cách FID \cite{heusel2017gans}.
    Ta đánh giá các DPMs với cả bước thời gian rời rạc và bước thời gian liên tục. Với DPMs bước thời gian rời rạc, ta sẽ đánh giá DPMs ở cả hai kiểu quá trình thuận tương ứng là DDPM và DDIM.
    \cite{watson2021learning}, \cite{bao2021analytic} kết luận rằng DPM với quỹ đạo tối ưu lại thường cho khoảng cách FID tệ hơn nên ta chỉ đánh giá ở quỹ đạo chẵn.


    \begin{table}[h!]
        %\small
        %\centering
        \caption{Bảng kết quả khoảng cách FID. Tất cả các kết quả đều với cấu hình quỹ đạo chẵn (ET). A-DPM ký hiệu của Analytic-DPM. 
        Ta cần chú ý rằng chi phí thời gian tăng thêm của mạng dự đoán phần dư nhiễu NPR hoặc mạng dự đoán bình phương nhiễu SN là không đáng kể trên tập CIFAR10, CelebA 64x64 và khoảng 4.5 \% trên tập ImageNet 64x64
        (chi tiết ở phụ lục \ref{Appen:Subsection:Details-of-Memory-and-Time-Cost}). Ta có thể sử dụng số bước để so sánh tính hiệu quả của các phương pháp}
        \resizebox{\columnwidth}{!}{
            \begin{tabular}{ lrrrrrrrrrrrrr  }
                \hline
                \multirow{2}{*}{\# Số bước $K$} & \multicolumn{6}{c}{CIFAR10 (LS)} & & \multicolumn{6}{c}{CIFAR10 (CS)} \\ \cline{2-7} \cline{9-14}
                & 10 & 25 & 50 & 100 & 200 & 1000 & & 10 & 25 & 50 & 100 & 200 & 1000 \\
                \hline
                DDPM, $\tilde{\beta}_n$ & 44.45 & 21.83 & 15.21 & 10.94 & 8.23 & 5.11 &  & 34.76 & 16.18 & 11.11 & 8.38 & 6.66 & 4.92 \\
                DDPM, $\beta_n$ & 233.41 & 125.05 & 66.28 & 31.36 & 12.96 & \textbf{3.04} & & 205.31 & 84.71 & 37.35 & 14.81 & 5.74 & \textbf{3.34} \\
                A-DDPM & 34.26 & 11.60 & 7.25 & 5.40 & 4.01 & 4.03 & & 22.94 & 8.50 & 5.50 & 4.45 & 4.04 & 4.31 \\
                NPR-DDPM & 32.35 & 10.55 & 6.18 & 4.52 & 3.57 & 4.10 & & 19.94 & 7.99 & 5.31 & 4.52 & 4.10 & 4.27 \\
                SN-DDPM & \textbf{24.06} & \textbf{6.91} & \textbf{4.63} & \textbf{3.67} & \textbf{3.31} & 3.65 & & \textbf{16.33} & \textbf{6.05} & \textbf{4.17} & \textbf{3.83} & \textbf{3.72} & 4.07 \\
                \hline
                DDIM & 21.31 & 10.70 & 7.74 & 6.08 & 5.07 & 4.13 & & 34.34 & 16.68 & 10.48 & 7.94 & 6.69 & 4.89 \\
                A-DDIM & 14.00 & 5.81 & 4.04 & 3.55 & 3.39 & 3.74 & & 26.43 & 9.96 & 6.02 & 4.88 & 4.92 & 4.66 \\
                NPR-DDIM & 13.34 & 5.38 & 3.95 & 3.53 & 3.42 & 3.72 & & 22.81 & 9.47 & 6.04 & 5.02 & 5.06 & 4.62 \\
                SN-DDIM & \textbf{12.19} & \textbf{4.28} & \textbf{3.39} & \textbf{3.23} & \textbf{3.22} & \textbf{3.65} & & \textbf{17.90} & \textbf{7.36} & \textbf{5.16} & \textbf{4.63} & \textbf{4.63} & \textbf{4.51} \\
                \hline
            \end{tabular}
        }
        \resizebox{\columnwidth}{!} {
            \begin{tabular}{ lrrrrrrrrrrrrr  }
                \hline
                \multirow{2}{*}{\# Số bước $K$} & \multicolumn{6}{c}{CelebA 64x64} & & \multicolumn{6}{c}{ImageNet 64x64} \\ \cline{2-7} \cline{9-14}
                & 10 & 25 & 50 & 100 & 200 & 1000 & & 25 & 50 & 100 & 200 & 400 & 4000 \\
                \hline
                DDPM, $\tilde{\beta}_n$ & 36.69 & 24.46 & 18.96 & 14.31 & 10.48 & 5.95 & & 29.21 & 21.71 & 19.12 & 17.81 & 17.48 & 16.55 \\
                DDPM, $\beta_n$ & 294.79 & 115.69 & 53.39 & 25.65 & 9.72 & \textbf{3.16} & & 170.28 & 83.86 & 45.04 & 28.39 & 21.38 & 16.38 \\
                A-DDPM & 28.99 & 16.01 & 11.23 & 8.08 & 6.51 & 5.21 & & 32.56 & 22.45 & 18.80 & 17.16 & 16.40 & 16.34 \\
                NPR-DDPM & 28.37 & 15.74 & 10.89 & 8.23 & 7.03 & 5.33 & & 28.27 & 20.89 & 18.06 & 16.96 & \textbf{16.32} & 16.38 \\
                SN-DDPM & \textbf{20.60} & \textbf{12.00} & \textbf{7.88} & \textbf{5.89} & \textbf{5.02} & 4.42 & & \textbf{27.58} & \textbf{20.74} & \textbf{18.04} & \textbf{16.61} & 16.37 & \textbf{16.22} \\
                \hline
                DDIM & 20.54 & 13.45 & 9.33 & 6.60 & 4.96 & 3.40 & & 26.06 & 20.10 & 18.09 & 17.84 & 17.74 & 19.00 \\
                A-DDIM & 15.62 & 9.22 & 6.13 & 4.29 & 3.46 & 3.13 & & \textbf{25.98} & \textbf{19.23} & 17.73 & 17.49 & 17.44 & 18.98 \\
                NPR-DDIM & 14.98 & 8.93 & 6.04 & 4.27 & 3.59 & 3.15 & & 28.84 & 19.62 & 17.63 & 17.42 & 17.30 & 18.91 \\
                SN-DDIM & \textbf{10.20} & \textbf{5.48} & \textbf{3.83} & \textbf{3.04} & \textbf{2.85} & \textbf{2.90} & & 28.07 & 19.38 & \textbf{17.53} & \textbf{17.23} & \textbf{17.23} & \textbf{18.89} \\
                \hline
            \end{tabular}
        }
        \begin{center}
            \resizebox{9.5cm}{!}{
                \begin{tabular}{ lrrrrrr  }
                    \hline
                    \multirow{2}{*}{\# Số bước $K$} & \multicolumn{6}{c}{CIFAR10 (VP SDE)} \\ \cline{2-7}
                    & 10 & 25 & 50 & 100 & 200 & 1000 \\
                    \hline
                    Euler-Maruyama & 292.20 & 170.17 & 90.79 & 47.46 & 21.92 & \textbf{2.55} \\
                    Ancestral-Sampling & 235.28 & 129.29 & 68.52 & 31.99 & 12.81 & 2.72 \\
                    Probabity Flow & 107.74 & 21.34 & 7.78 & 4.33 & 3.27 & 2.82 \\
                    A-DPM & 35.10 &  11.57 & 6.54 & 4.71 & 3.61 & 2.98 \\
                    NPR-DPM & 33.70 & 10.44 & 5.83 & 3.97 & 3.05 & 3.04 \\
                    SN-DPM & \textbf{25.30} & \textbf{7.34} & \textbf{4.46} & \textbf{3.27} & \textbf{2.83} & 2.71 \\
                    \hline
                \end{tabular}
            }
        \end{center}
        \label{table:FID-CIFAR10}
    \end{table}

    Ở trong bảng \ref{table:FID-CIFAR10}, cả NPR-DPM và SN-DPM vượt trội hơn hầu hết các phương pháp còn lại.
    Đặc biêt, SN-DPM cải thiện chất lượng ảnh một cách rõ rệt trên tập CIFAR10 và tập CelebA 64x64 khi số bước được sử dụng nhỏ.
    Hơn nữa, các phương pháp của ta tỏ ra rất tốt trong cả bước thời gian rời rạc và bước thời gian liên tục.

    Theo \cite{bao2021analytic}, ta cũng so sánh số bước nhỏ nhất cần thiết để đạt được khoảng cách FID đạt khoảng 6,
    kết quả được trình bày trong bảng \ref{table:Smallest-steps-to-achieved-FID-6}.
    Ta nhận thấy trên tập CelebA 64x64, SN-DPM chỉ cần số bước khoảng bằng một nửa so với các phương pháp khác.
    Trong phần phụ lục, ta sẽ so sánh khoảng cách FID sau khi tính đến chi phí tính toán tăng thêm,
    cũng như so sánh với "Gotta Go Fast" SDE solver.

    \subsection{Kết quả ước lượng hợp lý}

    Trong mục này, ta sẽ đánh giá cận trên $-L_{\mathrm{elbo}}$ (công thức \ref{eq:ELBO-Maximization}) trên log-likelihood âm của DPMs với bước thời gian rời rạc.
    \cite{bao2021analytic} đã phát biểu rằng $-L_{\mathrm{elbo}}=\infty$ trong quá trình khuếch tán thuận của DDIM, nên ta chỉ có kết quả với quá trình khuếch tán thuận của DDPM.

    Trong bảng \ref{table:Upper-Bound}, phương pháp NPR-DPM hầu hết vượt trội so với các phương pháp còn lại trên tất cả các tập dữ liệu, trên các số bước thời gian và trên các kiểu quỹ đạo.

    \begin{table}[h!]
        \caption{Số bước nhỏ nhất để đạt được khoảng cách FID khoảng bằng 6.
        Chi phí thời gian trong từng bước cho từng phương pháp xem như là như nhau.
        Phương pháp của ta có thêm mạng dự đoán phần dư nhiễu NPR hoặc mạng dự đoán bình phương nhiễu SN vì vậy sẽ tăng thêm chi phí thời gian.
        Ta nhân kết quả với tỷ lệ chi phí thời gian trên từng bước so với các phương pháp được so sánh}
        \begin{center}
            \resizebox{11cm}{!}{
                \begin{tabular}{ lrrr}
                    \hline
                    Phương pháp & CIFAR10 & CelebA 64x64 & LSUN Bedroom \\
                    \hline
                    DDPM \cite{ho2020denoising} & 90 (6.12) & > 200 & 130 (6.06) \\
                    DDIM \cite{song2020denoising} & 30 (5.85) & > 100 & BEST FID > 6 \\
                    Improved DDPM \cite{nichol2021improved} &  45 (5.96) & Không có mô hình & \textbf{90} (6.02) \\
                    Analytic-DPM \cite{bao2021analytic} &  25 (5.81) & 55 (5.98) & 100 (6.05) \\
                    NPR-DPM &  1.002 x 23 (5.76) & 1.011 x 50 (6.04) &  1.017 x \textbf{90} (6.01) \\
                    SN-DPM &  1.005 x \textbf{17} (5.81) & 1.012 x \textbf{22} (5.96) & 1.100 x 92 (6.02) \\
                    \hline
                \end{tabular}
            }
        \end{center}
        \label{table:Smallest-steps-to-achieved-FID-6}
    \end{table}

    Ban đầu ta nhận thấy SN-DPM không tỏ ra vượt trội so với các phương pháp khác trên kết quả về ước lượng hợp lý,
    lý do có thể ta chưa xem xét trung bình không hoàn hảo và sai số bị khuếch đại của $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2$ như đã được đề cập ở trong mục \ref{Optimal-Solution-Covariance-Beyond-Isotropic-Covariance}.
    Kết quả này không nhất quán với kết quả của FID trong bảng \ref{table:FID-CIFAR10} vì đặc tính khác nhau của hai cách đánh giá này.
    Sự khác biệt này đã được quan sát và bàn luận nhiều trong các công trình trước \cite{ho2020denoising}, \cite{nichol2021improved}, \cite{song2021maximum}, \cite{vahdat2021score}, \cite{watson2021learning}, \cite{kingma2021variational}, \cite{bao2021analytic}.
    Ta nhận thấy tuy NPR-DPM tỏ ra tốt hơn so với SN-DPM với ước lượng hợp lý nhưng lại không tốt hơn ở độ đo khoảng cách FID.

    Ta cũng so sánh Improved-DDPM \cite{nichol2021improved} theo cách đánh giá ước lượng hợp lý.
    Với một số lượng bước thời gian sử dụng ít, phương pháp của ta có kết quả ước lượng hợp lý tốt hơn khá nhiều so với phương pháp của \cite{nichol2021improved} trên tập ImageNet 64x64.
    Với số bước thời gian đầy đủ, hai phương pháp có kết quả ước lượng hợp lý tương đương nhau.
    Điều này thể hiện rằng một hàm mục tiêu gián tiếp như hàm mục tiêu MSE có thể thu được kết quả ước lượng hợp lý tương đương với tối ưu hóa trực tiếp $L_{\mathrm{elbo}}$.


    \begin{table}[h!]
        \caption{Cận trên ($-L_{\mathrm{elbo}}$) của log-likelihood âm.
        A-DPM là ký hiệu của Analytic-DPM. Cần chú ý rằng chi phí tính toán được thêm vào là không đáng kể trên các tập CIFAR10, CelebA 64x64 và khoảng 4.5 \% trên tập ImageNet 64x64.
        Vì vậy ta có thể sử dụng số bước thời gian để so sánh độ hiệu quả của các phương pháp. Để giảm ảnh hưởng của tính ngẫu nhiên, ta cũng lặp lại với cấu hình số bước thời gian nhiều nhất và phương sai sẽ được đề cập ở phần phụ lục \ref{Appen:Subsection:Details-of-Memory-and-Time-Cost}.}
        \begin{center}
            \resizebox{\columnwidth}{!}{
                \begin{tabular}{llrrrrrrrrrrrrr}
                    \hline
                    \multicolumn{2}{c}{\multirow{2}{*}{\# Số bước $K$}}&\multicolumn{6}{c}{CIFAR10 (LS)} & \multicolumn{6}{c}{CIFAR10 (CS)}\\ \cline{3-8} \cline{10-15}
                    \multicolumn{2}{c}{}& 10 & 25 & 50 & 100 & 200 & 1000 & & 10 & 25 & 50 & 100 & 200 & 1000 \\
                    \hline
                    \multirow{4}{*}{ET} & DDPM, $\tilde{\beta}_n$ & 74.95 & 24.98 & 12.01 & 7.08 & 5.03 & 3.73 & & 75.96 & 24.94 & 11.96 & 7.04 & 4.95 & 3.60 \\
                    & DDIM $\beta_n$ & 6.99 & 6.11 & 5.44 & 4.86 & 4.39 & 3.75 & & 6.51 & 5.55 & 4.92 & 4.41 & 4.03 & 3.54 \\
                    & A-DDPM & 5.47 & 4.79 & 4.38 & 4.07 & 3.84 & 3.59 & & 5.08 & 4.45 & 4.09 & 3.83 & 3.64 & 3.42 \\
                    & NPR-DDPM & 5.40 & 4.64 & 4.25 & 3.98 & 3.79 & 3.57 & & 5.03 & 4.33 & 3.99 & 3.76 & 3.59 & 3.41 \\
                    \hline
                    \multirow{3}{*}{OT} & DDPM, $\tilde{\beta}_n$ & 5.38 & 4.34 & 3.97 & 3.82 & 3.77 & 3.75 & & 5.51 & 4.30 & 3.86 & 3.65 & 3.57 & 3.54 \\
                    & A-DDPM & 4.11 & 3.68 & 3.61 & 3.59 & 3.59 & 3.59 & & 3.99 & 3.56 & 3.47 & 3.44 & 3.43 & 3.42 \\
                    & NPR-DDPM & 3.91 & 3.64 & 3.59 & 3.58 & 3.57 & 3.57 & & 3.88 & 3.52 & 3.45 & 3.42 & 3.41 & 3.41 \\
                    \hline
                \end{tabular}
            }
        \end{center}
        \begin{center}
            \resizebox{\columnwidth}{!}{
                \begin{tabular}{llrrrrrrrrrrrrr}
                    \hline
                    \multicolumn{2}{c}{\multirow{2}{*}{\# Số bước $K$}}&\multicolumn{6}{c}{CelebA 64x64} & \multicolumn{6}{c}{ImageNet 64x64}\\ \cline{3-8} \cline{10-15}
                    \multicolumn{2}{c}{}& 10 & 25 & 50 & 100 & 200 & 1000 & &  25 & 50 & 100 & 200 & 400 & 4000 \\
                    \hline
                    \multirow{4}{*}{ET} & DDPM, $\tilde{\beta}_n$ & 33.42 & 13.09 & 7.14 & 4.60 & 3.45 & 2.71 & & 105.87 & 46.25 & 22.02 & 12.10 & 7.59 & 3.89 \\
                    & DDIM $\beta_n$ & 6.67 & 5.72 & 4.98 & 4.31 & 3.74 & 2.93 & & 5.81 & 5.20 & 4.70 & 4.31 & 4.04 & 3.65 \\
                    & A-DDPM & 4.54 & 3.89 & 3.48 & 3.16 & 2.92 & 2.66 & & 4.78 & 4.42 & 4.15 & 3.95 & 3.81 & 3.61 \\
                    & NPR-DDPM & \textbf{4.46} & \textbf{3.78} & \textbf{3.40} & \textbf{3.11} & \textbf{2.89} & \textbf{2.65} & & \textbf{4.66} & \textbf{4.22} & \textbf{3.96} & \textbf{3.80} & \textbf{3.71} & \textbf{3.60} \\
                    \hline
                    \multirow{3}{*}{OT} & DDPM, $\tilde{\beta}_n$ & 4.76 & 3.58 & 3.16 & 2.99 & 2.94 & 2.93 & & 4.56 & 4.09 & 3.84 & 3.73 & 3.68 & 3.65 \\
                    & A-DDPM & 2.97 & 2.71 & 2.67 & 2.66 & 2.66 & 2.66 & & 3.83 & 3.70 & 3.64 & 3.62 & 3.62 & 3.61 \\
                    & NPR-DDPM & \textbf{2.88} & \textbf{2.69} & \textbf{2.66} & \textbf{2.66} & \textbf{2.65} & \textbf{2.65} & & \textbf{3.73} & \textbf{3.65} & \textbf{3.62} & \textbf{3.60} & \textbf{3.60} & \textbf{3.60} \\
                    \hline
                \end{tabular}
            }
        \end{center}
        \label{table:Upper-Bound}
    \end{table}

    \section{Các công trình liên quan}

    \textbf{DPMs và các biến thể:} Ý tưởng về quá trình sinh dữ liệu được xây dựng bởi một quá trình khuếch tán ngược lần đầu tiên được đề xuất bởi \cite{sohl2015deep}.
    Đặc biệt \cite{sohl2015deep} đảo ngược quá trình khuếch tán thuận sử dụng một chuỗi Markov với bước thời gian rời rạc, huấn luyện bằng cách cực đại hóa cận dưới ELBO.
    \cite{ho2020denoising} đề xuất tái tham số hóa trung bình của chuỗi Markov bằng mạng dự đoán nhiễu, mạng này chia sẻ tham số giữa các bước thời gian khác sau và được huấn luyện để cực tiểu hóa hàm mục tiêu MSE.
    \cite{song2020score} xem xét DPMs với bước thời gian rất nhỏ, có thể được biểu diễn bằng một phương trình vi phân ngẫu nhiên (SDEs).
    Gần đây, một số biến thể của DPMs đã được đề xuất. \cite{kingma2021variational} nghiên cứu thêm về quá trình khuếch tán thuận.
    \cite{vahdat2021score} nghiên cứu DPMs trong không gian ẩn và \cite{dockhorn2021score} đề xuất biến vận tốc phụ trợ vào quá trình khuếch tán.

    Dựa trên khả năng sinh dữ liệu mạnh mẽ, DPMs đã tạo ra rất nhiều hứa hẹn trong nhiều ứng dụng như sinh dữ liệu có điều khiển \cite{choi2021ilvr}, \cite{meng2021sdedit}, \cite{sinha2021d2c}, \cite{nichol2021glide},
    chuyển đổi giọng nói \cite{popov2021diffusion}, tăng độ phân giải ảnh \cite{saharia2021image}, \cite{li2022srdiff}, dịch ảnh \cite{sasaki2021unit}, tạo hình khối \cite{zhou20213d},
    tạo đám mây điểm 3D \cite{luo2021diffusion} và dữ đoán chuỗi thời gian \cite{rasul2021autoregressive}.

    \textbf{Thiết kế ma trận hiệp phương sai DPMs:} Như đã đề cập trong mục \ref{Introduction}, thiết kế của ma trận hiệp phương sai trong DPMs là rất quan trọng trong khả năng sinh dữ liệu với một tập con các bước thời gian,
    một số công trình trước \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic} sử dụng các ma trận hiệp phương sai đẳng hướng mà chỉ phụ thuộc vào bước thời gian mà không xem xét đến trạng thái.
    Bên cạnh đó, \cite{nichol2021improved} sử dụng ma trận hiệp phương sai đường chéo có phụ thuộc vào trạng thái.
    Điểm khác biệt giữa \cite{nichol2021improved} là trực tiếp huấn luyện mạng hiệp phương sai trên cận dưới $L_{\mathrm{elbo}}$,
    mạng dự đoán của chúng ta được huấn luyện dựa trên hàm mục tiêu MSE dựa trên dạng của ma trận hiệp phương sai tối ưu.
    Phương pháp của ta đạt được một kết quả ước lượng hợp lý tốt trên một số bước thời gian nhỏ, trí ngược với \cite{nichol2021improved}.

    \textbf{Faster DPMs:} Trong khi nghiên cứu thiết kế ma trận hiệp phương sai trong DPMs, đã có nhiều nỗ lực về việc lấy mẫu nhanh và hiệu quả hơn.
    Nhiều công trình nghiên cứu sử dụng quỹ đạo ngắn bằng cách áp dụng các thuật toán tìm kiếm, nhưu tìm kiếm trên lưới \cite{chen2020wavegrad},
    quy hoạch động \cite{watson2021learning} và tìm kiếm khả vi \cite{watson2021fastsampler}.
    Các thuật toán tìm kiếm này có thể được kết hợp với phương pháp của ta để đạt được kết quả tốt hơn.
    Ví dụ, sự kết hợp giữa quy hoạch động và phương pháp của ta dẫn đến ột kết quả tốt hơn trong ước lượng hợp lý, được trình bày ở kết quả OT trong bảng \ref{table:Upper-Bound}.
    Nhiều công trình thay đổi họ của mô hình trong quá trình khuếch tán ngược, thay thế mô hình Gaussian.
    \cite{luhman2021knowledge}, \cite{salimans2021progressive} chắt lọc quá trình khuếch tán ngược ban đầu thành một mô hình có thể thực hiện quá trình ngược với một vài hoặc chỉ một bước thời gian,
    và \cite{xiao2021tackling} mô hình hóa quá trình khuếch tán ngược là một hàm sinh có điều kiện và đề xuất để huấn luyện một hàm mục tiêu đối kháng.
    Tuy nhiên, hàm ước lược hợp lý là không dễ dàng tìm vì sự thay đổi của họ mô hình.
    Nhiều công trình thiết kế các bộ giải nhanh hơn \cite{jolicoeur2021gotta,popov2021diffusion} cho DPMs với bước thời gian liên tục.
    Tuy nhiên các bộ giải này chỉ xem xét các ma trận hiệp phương sai đầy đủ trong \cite{ho2020denoising}, \cite{bao2021analytic} không linh hoạt như phương pháp của ta.

    \section{Kết luận}

    Ta đã xem xét ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ để cải thiện khả năng sinh dữ liệu của DPMs.
    Ta thu được kết quả với trung bình tối ưu và ma trận hiệp phương sai tối ưu, và cách để hiệu chỉnh ma trận hiệp phương sai sử dụng phân tích thành các thành phần kỳ vọng có điều kiện trên một hàm của nhiễu,
    có thể ước lượng được bằng cực tiếu hóa hàm mục tiêu MSE. Ta xem xét ma trận hiệp phương sai đường chéo để giảm chi phí tính toán khi lấy mẫu.
    Bên cạnh đó, ta áp dụng chiến lược chia sẻ tham số cũng để làm giảm chi phí tính toán và quá trình huấn luyện hai giai đoạn.
    Phương pháp của ta áp dụng được cho cả DPMs với bước thời gian rời rạc và bước thời gian liên tục.
    Về mặt thực nghiệm, phương pháp của ta tỏ ra vượt trội hơn so với nhiều phương pháp khác về mặt ước lượng hợp lý và cỉa thiện chất lượng ảnh được sinh ra đặc biệt chỉ cần sử dụng một số ít bước.


    \newpage
    \printbibliography[title={TÀI LIỆU THAM KHẢO}]

    \newpage

    \appendix

    \section{Chứng minh} \label{Appen:Section:Proof}

    \subsection{Chứng minh định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}, \ref{dl:Solely-Optimal-Mean}, \ref{dl:Solely-Optimal-Covariance}}

    \begin{bd} \label{bd:Conditioned-Moment-Matching} (Kết nối moment có điều kiện) Giả sử $q(\boldsymbol{x})$ là một hàm mật độ xác suất với trung bình $\boldsymbol{\mu}_q$ và ma trận hiệp phương sai $\boldsymbol{\Sigma}_q$ và $p(\boldsymbol{x})=\mathcal{N}(\boldsymbol{x} \vert \boldsymbol{\mu}, \mathrm{diag}(\boldsymbol{\sigma}^2))$ là một phân phối Gaussian. Khi đó:

    \begin{enumerate}
        \item Với $\boldsymbol{\sigma}^2$ bất kỳ, bài toán tối ưu hóa $\displaystyle\min_{\mu} D_{\mathrm{DK}} (q \Vert p)$ có nghiệm tối ưu $\boldsymbol{\mu}^{\ast}=\boldsymbol{\mu}_q$
        \item Với $\mu$ bất kỳ, bài toán tối ưu hóa $\displaystyle\min_{\boldsymbol{\sigma}^2} D_{\mathrm{KL}}(q \Vert p)$ có nghiệm tối ưu $\hat{\boldsymbol{\sigma}}^{\ast 2}=\mathrm{diag}(\boldsymbol{\Sigma}_q) + (\boldsymbol{\mu} - \boldsymbol{\mu}_q)^2$, với $(.)^2$ là bình phương từng phần tử
        \item Bài toán tối ưu $\displaystyle\min_{\boldsymbol{\mu}, \boldsymbol{\sigma}^2}$ có nghiệm tối ưu $\boldsymbol{\mu}^{\ast}=\boldsymbol{\mu}_q$ và $\boldsymbol{\sigma}^{\ast 2} = \mathrm{diag} (\boldsymbol{\Sigma}_q)$.
    \end{enumerate}

    \end{bd}

    \textit{Chứng minh.} \cite{bao2021analytic} đã chứng minh rằng độ phân kỳ Kullback-Leibler giữa một hàm mật độ xác suất bất kỳ $q$ và một phân phối Gaussian $p$ có thể được viết $D_{\mathrm{KL}}(q \Vert p)=D_{\mathrm{KL}}\big(\mathcal{N}(\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q \big) \Vert p) + c$, với $c$ là hằng số chỉ phụ thuộc vào $q$ (bổ đề 2 trong \cite{bao2021analytic}).
    Vì vậy nghiệm tối ưu của $D_{\mathrm{DL}} (q \Vert p)$ và $D_{\mathrm{KL}} \big( \mathcal{N} (\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q) \big)$ theo $\boldsymbol{\mu}$ và $\boldsymbol{\Sigma}_q$ là bằng nhau.

    Ta khai triển $D_{\mathrm{KL}} \big( \mathcal{N} (\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q) \Vert p$ theo định nghĩa của độ phân kỳ Kullback-Leibler:

    \begin{equation} \label{eq:Kullback-Leibler-Expanded}
        \begin{aligned}
            2 D_{\mathrm{KL}} \big( \mathcal{N} (\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q) \Vert p \big) &= \mathrm{tr} \big( \mathrm{diag} (\boldsymbol{\sigma}^{-2}) \boldsymbol{\Sigma}_q \big) - d + \log \dfrac{\lvert \mathrm{diag}(\boldsymbol{\sigma}^2) \rvert}{\lvert \boldsymbol{\Sigma}_q \rvert} + (\boldsymbol{\mu} - \boldsymbol{\mu}_q)^T \mathrm{diag}(\boldsymbol{\sigma^{-2}}) (\boldsymbol{\mu} - \boldsymbol{\mu}_q) \\
            &=\sum_{i=1}^d \Big \lbrace \sigma_i^{-2} \big \lbrack (\boldsymbol{\Sigma}_q)_{i, i} + (\boldsymbol{\mu}_i - (\boldsymbol{\mu}_q)_i)^2 \big\rbrack + \log \sigma_i^2 \Big \rbrace - \log \lvert \boldsymbol{\Sigma}_q \rvert  - d
        \end{aligned}
    \end{equation}

    Từ đây ta rút ra:

    \begin{equation*}
        \min_{\boldsymbol{\mu}} D_{\mathrm{KL}} (q \Vert) \Leftrightarrow \min_{\boldsymbol{\mu}} (\boldsymbol{\mu} - \boldsymbol{\mu}_q)^T \mathrm{diag}(\boldsymbol{\sigma}^{-2}) (\boldsymbol{\mu} - \boldsymbol{\mu}_q)
    \end{equation*}

    công thức này cho ta thấy nghiệm tối ưu $\boldsymbol{\mu}^{\ast} = \boldsymbol{\mu}_q$.

    Cũng từ công thức \ref{eq:Kullback-Leibler-Expanded}, ta biết rằng:

    \begin{equation}
        \min_{\boldsymbol{\sigma}^2} D_{\mathrm{KL}} (q \Vert p) \Leftrightarrow \sum_{i=1}^d \Big \lbrace \sigma_i^{-2} \big \lbrack (\boldsymbol{\Sigma}_q)_{i, i} + (\boldsymbol{\mu}_i - (\boldsymbol{\mu}_q)_i)^2 \big \rbrack + \log \sigma_i^2  \Big \rbrace
    \end{equation}

    Ta lấy đạo hàm $\sigma_i^{-2} \big \lbrack (\boldsymbol{\Sigma}_q)_{i, i} + (\boldsymbol{\mu}_i - (\boldsymbol{\mu}_q)_i)^2 \big \rbrack + \log \sigma_i^2$ theo $\sigma_i^2$, ta thu được nghiệm tối ưu:
    
    \begin{equation}
        \tilde{\sigma}_i^{\ast 2} = (\boldsymbol{\Sigma}_q)_{i, i} + (\boldsymbol{\mu}_i - (\boldsymbol{\mu}_q)_i)^2
    \end{equation}

    Vì vậy bài toán tối ưu $\displaystyle\min_{\boldsymbol{\sigma}^2} D_{\mathrm{KL}}(q \Vert p)$ có nghiệm tối ưu là $\tilde{\boldsymbol{\sigma}}^{\ast 2}=\mathrm{diag}(\boldsymbol{\Sigma}_q) + (\boldsymbol{\mu} - \boldsymbol{\mu}_q)^2$

    Kết hợp $\boldsymbol{\mu}^{\ast}$ và $\tilde{\boldsymbol{\sigma}}^{\ast 2}$, ta có nghiệm tối ưu của bài toán $\displaystyle \min_{\boldsymbol{\mu}, \boldsymbol{\sigma}^2} D_{\mathrm{KL}} (q \Vert p)$ là:
    
    \begin{equation}
        \begin{cases}
            \boldsymbol{\mu}^{\ast} = \boldsymbol{\mu}_q \\
            \boldsymbol{\sigma}^{\ast 2} = \mathrm{diag} (\boldsymbol{\Sigma})_q + \big( \boldsymbol{\mu}^{\ast} - \boldsymbol{\mu}_q \big)^2
        \end{cases}     
    \end{equation}

    \begin{bd} \label{bd:Mean-Covariance}
        Giả sử $q(\boldsymbol{x}_{0:N})$ được định nghĩa trong công thức \ref{eq:Forward-Process}. Khi đó ta có:

        \begin{equation*}
            \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \tilde{\boldsymbol{\mu}}_n \Big( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \big( \boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \big) \Big)
        \end{equation*}

        \begin{equation*}
            \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T \rbrack \big) - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^T \big)
        \end{equation*}

        \begin{equation*}
            \mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big) = \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2 \big)
        \end{equation*}

        Với $\boldsymbol{\epsilon}_n = \dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}$ là nhiễu để tạo ra $\boldsymbol{x}_n$ từ $\boldsymbol{x}_0$ và $\gamma_n = \sqrt{\overline{\alpha}_{n-1}} - \sqrt{\overline{\beta}_{n-1} - \lambda_n^2} \sqrt{\dfrac{\overline{\alpha}_n}{\overline{\beta}_n}}$
    \end{bd}

    \textit{Chứng minh.}
    Vì $\tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \boldsymbol{x}_0)$ là một hàm tuyến tính với $\boldsymbol{x}_0$ nên:

    \begin{equation*}
        \begin{aligned}
            \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack &= \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0)} \lbrack \boldsymbol{x}_{n-1} \rbrack \\ 
            &= \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)}\tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \boldsymbol{x}_0) \\
            &= \tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \boldsymbol{x}_0) \\
            &= \tilde{\boldsymbol{\mu}}_n \Big( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \big( \boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \big) \Big)
        \end{aligned}
    \end{equation*}

    Với ma trận hiệp phương sai $\mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack$, \cite{bao2021analytic} đã chứng minh được rằng có thể khai triển $\mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_0 \rbrack$ với $\gamma_n = \sqrt{\overline{\alpha}_{n-1}} - \sqrt{\overline{\beta}_{n-1} - \lambda_n^2} \sqrt{\dfrac{\overline{\alpha}_n}{\overline{\beta}_n}}$ (bổ đề 13 của \cite{bao2021analytic})

    Bên cạnh đó, ta có $\mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack = \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \Big \lbrack \dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n}\boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}} \Big \rbrack = \dfrac{\overline{\alpha}_n}{\overline{\beta}_n} \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_0 \rbrack$. Vì vậy:

    \begin{equation}
        \begin{aligned}
            \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \\
            &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^T \big) \\
            \Rightarrow \mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big) &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2 \big)
        \end{aligned}
    \end{equation}

    \joint*

    \textit{Chứng minh.}
    \cite{bao2021analytic} chứng minh rằng độ phân kỳ Kullback-Leibler giữa một phân phối xác suất chung $q(\boldsymbol{x}_{0:N})$ và một chuối Markov $p(\boldsymbol{x}_{0:N})$ có thể được viết dưới dạng:

    \begin{equation}
        D_{\mathrm{KL}} (q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}))=\sum_{n=1}^N \mathbb{E}_{q} D_{\mathrm{KL}} (q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)) + c
    \end{equation}

    với $c$ là hằng số chỉ phụ thuộc vào $q$ (xem Bổ đề 8 trong \cite{bao2021analytic}). 
    Kết quả là bài toán tối ưu hóa của độ phân kỳ Kullback-Leibler được phân tích thành $n$ bài toan con độc lập:

    \begin{equation}
        \min_{\boldsymbol{\mu}_n (.), \boldsymbol{\sigma}_n (.)^2} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big), 1 \leq n \leq N
    \end{equation}

    Khi $q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)$ là một hàm mật độ xác suất với trung bình $\mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack$ và ma trận hiệp phương sai $\mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack$ và $p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) = \mathcal{N}\big( \boldsymbol{x}_{n-1} \vert \boldsymbol{\mu}_n (\boldsymbol{x}_n), \mathrm{diag} (\boldsymbol{\sigma}_n(\boldsymbol{x}_n)^2)\big)$ là một phân phối Gaussian, tương ứng với bổ đề \ref{bd:Conditioned-Moment-Matching} và bổ đề \ref{bd:Mean-Covariance}, ta có lời giải tối ưu là:

    \begin{equation}
        \begin{aligned}
            \boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n) &= \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \tilde{\boldsymbol{x}}_n \big(\boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} (\boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack )\big) \\
            \boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2 &= \mathrm{diag} (\mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack) = \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2 )
        \end{aligned}
    \end{equation}

    \mean*

    \textit{Chứng minh.}
    Tương tự như định lý \ref{dl:Solely-Optimal-Mean}, bài toán tối ưu hóa tương đương với:

    \begin{equation}
        \max_{\lbrace \boldsymbol{\mu}_n \rbrace_{n=1}^N} L_{\mathrm{elbo}} \Leftrightarrow \min_{\lbrace \boldsymbol{\mu}_n \rbrace_{n=1}^N} D_{\mathrm{KL}} \big(q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big) \Leftrightarrow \min_{\boldsymbol{\mu}_n} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big), 1 \leq n \leq N
    \end{equation}

    Theo bổ đề \ref{bd:Conditioned-Moment-Matching} và bổ đề \ref{bd:Mean-Covariance}, ta thu được trung bình tối ưu $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ là:

    \begin{equation}
        \boldsymbol{\mu}_n^{\ast}=\mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \tilde{\boldsymbol{\mu}}_n \Big( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \big( \boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \big) \Big)
    \end{equation}

    \covariance*

    \textit{Chứng minh.}
    Tương tự như định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}, bài toán tối ưu hóa tương đương với:

    \begin{equation*}
        \max_{\lbrace \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} L_{\mathrm{elbo}} \Leftrightarrow \min_{\lbrace \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} D_{\mathrm{KL}} \big(q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big) \Leftrightarrow \min_{\boldsymbol{\Sigma}_n} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big), 1 \leq n \leq N
    \end{equation*}

    Theo bổ đề \ref{bd:Conditioned-Moment-Matching}, ta biết hiệp phương sai tối ưu hiệu chỉnh $\tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2$ là:

    \begin{equation}
        \tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2 = \mathrm{diag} \big(\mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big) + \big( \boldsymbol{\mu}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack\big)^2
    \end{equation}

    Theo bổ đề \ref{bd:Conditioned-Moment-Matching}, $\mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big) = \boldsymbol{\sigma}_n^{\ast} (\boldsymbol{x}_n)^2$.
    Theo bổ đề \ref{bd:Mean-Covariance} và tham số hóa $\boldsymbol{\mu}_n (\boldsymbol{x}_n)$ trong công thức \ref{eq:Estimated-Optimal-Mean}, ta có:
    \begin{equation}
        \boldsymbol{\mu}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \gamma_n \sqrt{\dfrac{\overline{\beta}_n}{\overline{\alpha}_n}} \big( \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)
    \end{equation}

    Cuối cùng ta thu được,

    \begin{equation}
        \begin{aligned}
            \tilde{\boldsymbol{\sigma}}_n^{\ast} (\boldsymbol{x}_n)^2 &= \mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big) + \big( \boldsymbol{\mu}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big)^2 \\
            &= \boldsymbol{\sigma}_n^{\ast}(\boldsymbol{x}_n)^2 + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \underbrace{\big( \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \big)^2}_{\mathrm{error}} \\
            &= \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big \lbrace \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2 + \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2 - 2 \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) + \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2 \big \rbrace \\
            &= \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big \lbrace \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n^2 \rbrack - 2 \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) + \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2 \big \rbrace \\
            &= \lambda_n^2 \boldsymbol{1} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \lbrack (\boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n))^2 \rbrack
        \end{aligned}
    \end{equation}

    \subsection{Chứng minh mệnh đề \ref{md:Continuous-Optimal-Covariance} và mệnh đề \ref{md:Continuous-Corrected-Optimal-Covariance}}

    \begin{bd} \label{bd:Continous-Conditional-Distribution}
        Với $0 \leq s < t \leq T$ và $q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)$ là phân phối có điều kiện của $\boldsymbol{x}_s$ khi cho trước $\boldsymbol{x}_t$ được xác định bởi SDE $d \boldsymbol{x} = f(t) \boldsymbol{x} dt + g(t) d \boldsymbol{w}$. Khi đó ta có:

        \begin{equation}
            \begin{aligned}
                \mathbb{E}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack &= \dfrac{1}{\sqrt{\alpha_{t \vert s}}} \big( \boldsymbol{x}_t - \dfrac{\beta_{t \vert s}}{\sqrt{\beta_{t \vert 0}}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \big) \\
                \mathrm{Cov}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack &= \overline{\beta}_{s \vert t} \boldsymbol{I} + \dfrac{\beta_{s \vert t}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \boldsymbol{\epsilon}_t^T \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack^T \big) \\
                \mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack \big) &= \overline{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{s \vert t}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack^2 \big)
            \end{aligned}
        \end{equation}

        Với $\boldsymbol{\epsilon}_t = \dfrac{\boldsymbol{x}_t - \sqrt{\alpha_{t \vert 0}} \boldsymbol{x}_0}{\sqrt{\beta_{t \vert 0}}}$ là nhiễu được sử dụng để tạo ra $\boldsymbol{x}_t$ từ $\boldsymbol{x}_0$ và $\overline{\beta}_{s \vert t} = \dfrac{\beta_{s \vert 0}}{\beta_{t \vert 0}} \beta_{t \vert s}$ được xác định bởi SDE là:
    \end{bd}

    \textit{Chứng minh.}
    Phân phối có điều kiện của $\boldsymbol{x}_s$ khi cho trước $\boldsymbol{x}_t$ và $\boldsymbol{x}_0$ được xác định bởi SDE là:

    \begin{equation}
        q(\boldsymbol{x}_s \vert \boldsymbol{x}_t, \boldsymbol{x}_0) = \mathcal{N} \big( \boldsymbol{x}_s \vert \dfrac{\sqrt{\alpha_{t \vert s}} \beta_{s \vert 0}}{\beta_{t \vert 0}} \boldsymbol{x}_t + \dfrac{\sqrt{\alpha_{s \vert 0} \beta_{t \vert s}}}{\beta_{t \vert 0}} \boldsymbol{x}_0, \overline{\beta}_{s \vert t} \boldsymbol{I} \big)
    \end{equation}

    Với $\mathbb{E}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack$, ta có:

    \begin{equation}
        \begin{aligned}
            \mathbb{E}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack &= \dfrac{1}{\sqrt{\alpha_{t \vert s}}} \big( \boldsymbol{x}_t + \beta_{t \vert s} \nabla \log q_t(\boldsymbol{x}_t) \big) \\
            &= \dfrac{1}{\sqrt{\alpha_{t \vert s}}} \big( \boldsymbol{x}_t - \dfrac{\beta_{t \vert s}}{\sqrt{\beta_{t \vert 0}}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \big)
        \end{aligned}    
    \end{equation}

    Với $\mathrm{Cov}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)}$, ta có thể khai triển sử dụng quy tắc cộng tổng phương sai:

    \begin{equation}
        \begin{aligned}
            \mathrm{Cov}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack &= \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \mathrm{Cov}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t, \boldsymbol{x}_0)} \lbrack \boldsymbol{x}_s \rbrack + \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \mathbb{E}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t, \boldsymbol{x}_0)} \lbrack \boldsymbol{x}_s \rbrack \\
            &= \overline{\beta}_{s \vert t} \boldsymbol{I} + \dfrac{\alpha_{s \vert 0} \beta_{t \vert s}^2}{\beta_{t \vert 0}^2} \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_0 \rbrack \\
            &= \overline{\beta}_{s \vert t} \boldsymbol{I} + \dfrac{\alpha_{s \vert 0} \beta_{t \vert s}^2}{\beta_{t \vert 0}^2} \dfrac{\beta_{t \vert 0}}{\alpha_{t \vert 0}} \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \\
            &= \overline{\beta}_{s \vert t} \boldsymbol{I} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \boldsymbol{\epsilon}_t^T \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \epsilon_t \rbrack^T \big)
        \end{aligned}
    \end{equation}

    Ma trận thu được đường chéo của ma trận hiệp phương sai là:

    \begin{equation}
        \mathrm{diag}\big( \mathrm{Cov}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack \big) = \overline{\beta}_{s \vert t} \boldsymbol{1} + \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack^2 \big)
    \end{equation}

    \continuousoptimalcovariance*

    \textit{Chứng minh.}
    Tương ứng với bổ đề \ref{bd:Mean-Covariance} và bổ đề \ref{bd:Continous-Conditional-Distribution}, lời giải tối ưu là:

    \begin{equation}
        \begin{aligned}
            \boldsymbol{\mu}_{s \vert t}^{\ast} &= \mathbb{E}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack = \dfrac{1}{\sqrt{\alpha_{t \vert s}}} \big( \boldsymbol{x}_t - \dfrac{\beta_{t \vert s}}{\sqrt{\beta_{t \vert 0}}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \big) \\
            \boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2 &= \mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x}_s) \vert \boldsymbol{x}_t} \lbrack \boldsymbol{x}_s \rbrack \big) = \overline{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t) \lbrack \boldsymbol{\epsilon}_t^2 \rbrack} - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t) \lbrack \boldsymbol{\epsilon}_t \rbrack^2} \big)
        \end{aligned}
    \end{equation}

    \continuouscorrectedoptimalcovariance*

    \textit{Chứng minh.}

    Tương ứng với bổ đề \ref{bd:Conditioned-Moment-Matching} và mệnh đề \ref{md:Continuous-Optimal-Covariance}, ma trận hiệp phương sai tối ưu $\tilde{\boldsymbol{\sigma}}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$ là:

    \begin{equation}
        \begin{aligned}
            \tilde{\boldsymbol{\sigma}}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2 &= \mathrm{diag} (\mathrm{Cov}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack) + \big(\boldsymbol{\mu}_{s \vert t} (\boldsymbol{x}_t) - \mathbb{E}_{q(\boldsymbol{x}_s \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{x}_s \rbrack \big)^2 \\
            &= \boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2 + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \underbrace{\big( \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \big)^2}_{\mathrm{error}} \\
            &= \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big \lbrace  \big \lbrace \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack^2 + \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack^2 - 2 \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \rbrack \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) + \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t)^2 \big \rbrace \\
            &= \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big \lbrace \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t^2 \rbrack - 2 \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t \rbrack \rbrack \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) + \hat{\boldsymbol{\epsilon}}_t(\boldsymbol{x}_t)^2 \big \rbrace \\
            &= \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \big \lbrack \big( \boldsymbol{\epsilon}_t - \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) \big)^2 \big \rbrack
        \end{aligned}
    \end{equation}

    \subsection{Sức mạnh sinh dữ liệu của DPMs được cải thiện trong trường hợp phân phối dữ liệu là trộn của các phân phối Gaussian}

    \begin{bd} \label{bd:Mixture-Gaussian-Data-Distribution}
        Ta giả sử $q(\boldsymbol{x}, \boldsymbol{y})$ là một hàm mật độ xác suất ví dụ $q(\boldsymbol{x})=\sum_{j=1}^J \gamma_j \mathcal{N} (\boldsymbol{\mu}_j, c \boldsymbol{I})$ với $J \leq 2$ và trung bình $\lbrace \boldsymbol{\mu}_j \rbrace_{j=1}^J$ đôi một khác nhau và $q(\boldsymbol{y} \vert \boldsymbol{x})=\mathcal{N}(\boldsymbol{y} \vert \sqrt{\alpha} \boldsymbol{x}, \beta \boldsymbol{I})$ với $\alpha, \beta > 0$. Ta giả sử $p(\boldsymbol{x} \vert \boldsymbol{y}) = \mathcal{N} (\boldsymbol{x} \vert \boldsymbol{\mu}(\boldsymbol{y}), \boldsymbol{\Sigma}(\boldsymbol{y}))$ là một phân phối Gaussian có điều kiện trên $\boldsymbol{y}$.
        Khi đó ta có:

        \begin{equation}
            \min_{\boldsymbol{\mu}, \boldsymbol{\Sigma}:\boldsymbol{\Sigma}(\boldsymbol{y})=\mathrm{diag}(\boldsymbol{\sigma} (\boldsymbol{y})^2)} \mathbb{E}_{q(\boldsymbol{y})} D_{\mathrm{KL}} \big( q(\boldsymbol{x} \vert \boldsymbol{y}) \Vert p(\boldsymbol{x} \vert \boldsymbol{y}) \big) < \min_{\boldsymbol{\mu}, \boldsymbol{\Sigma}:\boldsymbol{\Sigma}(\boldsymbol{y})=\sigma^2 \boldsymbol{I}} \mathbb{E}_{q(\boldsymbol{y})} D_{\mathrm{KL}} \big( q(\boldsymbol{x} \vert \boldsymbol{y}) \Vert p(\boldsymbol{x} \vert \boldsymbol{y}) \big)
        \end{equation}
    \end{bd}

    \textit{Chứng minh.}
    Như đã được đề cập trong chứng minh của bổ đề \ref{bd:Conditioned-Moment-Matching}, độ phân kỳ Kullback-Leibler giữa hàm mật độ xác suất $q$ và một phân phối Gaussian $p$ có thể được viết dưới dạng $D_{\mathrm{KL}} (q \Vert p) = D_{\mathrm{KL}} \big( \mathcal{N}(\boldsymbol{x} \vert \mathbb{E}_{q(\boldsymbol{x}, \boldsymbol{y})} \lbrack \boldsymbol{x} \rbrack) \Vert p \big) + \mathrm{const}$, với $\boldsymbol{\mu}_q$ là trung bình của phân phối $q$, $\boldsymbol{\Sigma}_q$ là ma trận hiệp phương sai của phân phối $q$ và $\mathrm{const}$ chỉ phụ thuộc vào phân phối $q$.
    Vì vậy, ta chỉ cần chứng minh:

    \begin{equation}
        \begin{aligned}
            &\min_{\boldsymbol{\mu}, \boldsymbol{\Sigma}:\boldsymbol{\Sigma}(\boldsymbol{y})=\mathrm{diag}(\boldsymbol{\sigma} (\boldsymbol{y})^2)} \mathbb{E}_{q(\boldsymbol{y})} D_{\mathrm{KL}} \big( \mathcal{N} (x \vert \mathbb{E}_{q(\boldsymbol{x} \vert \boldsymbol{y})}, \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack x \rbrack) \Vert p(\boldsymbol{x} \vert \boldsymbol{y}) \big) \\
            &< \\
            &\min_{\boldsymbol{\mu}, \boldsymbol{\Sigma}:\boldsymbol{\Sigma}(\boldsymbol{y})=\sigma^2 \boldsymbol{I}} \mathbb{E}_{q(\boldsymbol{y})} D_{\mathrm{KL}} \big( \mathcal{N} (x \vert \mathbb{E}_{q(\boldsymbol{x} \vert \boldsymbol{y})}, \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack x \rbrack) \Vert p(\boldsymbol{x} \vert \boldsymbol{y}) \big)
        \end{aligned}
    \end{equation}

    Trung bình tối ưu $\boldsymbol{\mu}^{\ast} (\boldsymbol{y})=\mathbb{E}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack \boldsymbol{x} \rbrack$ cho cả hai bài toán.
    Ta đặt $\boldsymbol{M} (\boldsymbol{y})=\mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack \boldsymbol{x} \rbrack$.
    Ta khai triển độ phân kỳ Kullback-Leibler và thế $\boldsymbol{\mu}^{\ast}$ vào $\boldsymbol{\mu}$:

    \begin{equation}
        2 D_{\mathrm{KL}} \big( \mathcal{N} (\boldsymbol{x} \vert \mathbb{E}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack x \rbrack), \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \Vert p(\boldsymbol{x} \vert \boldsymbol{y}) \big) = \mathrm{tr} \big( \boldsymbol{\Sigma} (\boldsymbol{y})^{-1} \boldsymbol{M} (\boldsymbol{y}) \big) - d + \log \dfrac{\lvert \boldsymbol{\Sigma} (\boldsymbol{y}) \rvert}{\lvert \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack x \rbrack \rvert}
    \end{equation}

    Vì vậy ta chỉ cần chứng minh:

    \begin{equation}
        \min_{\boldsymbol{\Sigma}:\boldsymbol{\Sigma}(\boldsymbol{y})=\mathrm{diag}(\boldsymbol{\sigma}(\boldsymbol{y})^2)} \mathbb{E}_{q(\boldsymbol{y})} \Big \lbrack \mathrm{tr} \big( \boldsymbol{\Sigma} (\boldsymbol{y})^{-1} \boldsymbol{M} (\boldsymbol{y}) \big) + \log \lvert \boldsymbol{\Sigma} (\boldsymbol{y}) \rvert \Big \rbrack < \min_{\boldsymbol{\Sigma}:\boldsymbol{\Sigma}(\boldsymbol{y})=\sigma^2 \boldsymbol{I}} \mathbb{E}_{q(\boldsymbol{y})} \Big \lbrack \mathrm{tr} \big( \boldsymbol{\Sigma} (\boldsymbol{y})^{-1} \boldsymbol{M} (\boldsymbol{y}) \big) + \log \lvert \boldsymbol{\Sigma} (\boldsymbol{y}) \rvert \Big \rbrack
    \end{equation}

    tương đương với:

    \begin{equation}
        \min_{\boldsymbol{\sigma}(.)^2} \mathbb{E}_{q(\boldsymbol{y})} \Bigg \lbrack \sum_{i=1}^d \big( \boldsymbol{\sigma} (\boldsymbol{y})_i^{-2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \boldsymbol{\sigma} (\boldsymbol{y})_i^2 \big) \Bigg \rbrack < \min_{\sigma^2} \mathbb{E}_{q(\boldsymbol{y})} \Bigg \lbrack \sum_{i=1}^d \big( \sigma^{-2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \sigma^2 \big) \Bigg \rbrack
    \end{equation}

    Bài toán ở vế bên trái cho ta biết lời giải tối ưu $\boldsymbol{\sigma}^{\ast}(\boldsymbol{y})_i^2=\boldsymbol{M} (\boldsymbol{y})_{ii}$ và bài toán ở vế bên phải có lời giải tối ưu $\sigma^{\ast 2}=\mathbb{E}_{q(\boldsymbol{y})} \dfrac{\mathrm{tr}\big( \boldsymbol{M} (\boldsymbol{y}) \big)}{d}$.
    Ta chỉ cần chứng mình:

    \begin{equation} \label{eq:Inequality-Mixture-Of-Gaussian}
        \mathbb{E}_{q(\boldsymbol{y})} \Bigg \lbrack \sum_{i=1}^d \big( \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^{-2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^2 \big) \Bigg \rbrack < \mathbb{E}_{q(\boldsymbol{y})} \Bigg \lbrack \sum_{i=1}^d \big( \sigma^{\ast -2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \sigma^{\ast 2} \big) \Bigg \rbrack
    \end{equation}
    Ta chứng minh bằng phản chứng. Ta giả sử:

    \begin{equation}
        \mathbb{E}_{q(\boldsymbol{y})} \Bigg \lbrack \sum_{i=1}^d \big( \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^{-2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^2 \big) \Bigg \rbrack = \mathbb{E}_{q(\boldsymbol{y})} \Bigg \lbrack \sum_{i=1}^d \big( \sigma^{\ast -2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \sigma^{\ast 2} \big) \Bigg \rbrack
    \end{equation}

    Vì vậy:

    \begin{equation}
        \forall \boldsymbol{y}, \sum_{i=1}^d \big( \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^{-2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^2 \big) = \sum_{i=1}^d \big( \sigma^{\ast -2} \boldsymbol{M} (\boldsymbol{y})_{ii} + \log \sigma^{\ast 2} \big)
    \end{equation}

    phải đúng khi và chỉ khi $\forall y, \forall i, \boldsymbol{\sigma}^{\ast} (\boldsymbol{y})_i^2=\sigma^{\ast 2}$. Điều này nghĩa là $\forall y, \forall y, \boldsymbol{M} (\boldsymbol{y})_{ii}=\mathbb{E}_{q(\boldsymbol{y})} \dfrac{\mathrm{tr}\big( \boldsymbol{M} (\boldsymbol{y}) \big)}{d}$, ẩn ý rằng tồn tại $m \in \mathbb{R}$ phù hợp với $\boldsymbol{y}$ ví dụ $\mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack \boldsymbol{x} \rbrack \big) = m \boldsymbol{I}$.

    Từ đây ta thu được $q(\boldsymbol{x} \vert \boldsymbol{y})$:

    \begin{equation}
        \begin{aligned}
            q(\boldsymbol{x} \vert \boldsymbol{y}) &\propto q(\boldsymbol{x}) q(\boldsymbol{y} \vert \boldsymbol{x}) \propto \sum_{j=1}^J \gamma_j \exp \Bigg ( - \dfrac{\lVert \boldsymbol{x} - \boldsymbol{\mu}_j \rVert_2^2}{2c} \Bigg ) \exp \Bigg ( - \dfrac{\lVert \boldsymbol{y} - \sqrt{\alpha} \boldsymbol{x} \rVert_2^2}{2\beta} \Bigg ) \\
            &\propto \sum_{j=1}^J \exp \Bigg ( - \dfrac{\lVert \boldsymbol{\mu}_j \rVert_2^2}{2c} \Bigg ) \exp \Bigg( - \dfrac{(c \alpha + \beta) \lVert \boldsymbol{x} \rVert_2^2 - 2 \langle \boldsymbol{x}, \beta \boldsymbol{\mu}_j + c \sqrt{\alpha} \boldsymbol{y} \rangle}{2 c \beta} \Bigg ) \\
            &= \sum_{j=1}^J \exp \Bigg ( \dfrac{\lVert \beta \boldsymbol{\mu}_j + c \sqrt{\alpha} \boldsymbol{y} \rVert_2^2}{2 c \beta (c \alpha + \beta)} - \dfrac{\lVert \boldsymbol{\mu}_j \rVert_2^2}{2c} \Bigg ) \exp \Bigg ( - \dfrac{\lVert \boldsymbol{x} - (\beta \boldsymbol{\mu}_j + c \sqrt{\alpha} \boldsymbol{y}) / (c \alpha + \beta) \rVert}{2c \beta / (c \alpha + \beta)} \Bigg ) \\
            &\propto \sum_{j=1}^J \exp \Bigg ( \log \gamma_j - \dfrac{\alpha}{c \alpha + \beta} \dfrac{\lVert \boldsymbol{\mu}_j \rVert_2^2}{2} + \dfrac{\sqrt{\alpha}}{c \alpha + \beta} \boldsymbol{\mu}_j^T \boldsymbol{y} \Bigg) \mathcal{N} \Big ( (\beta \boldsymbol{\mu}_j + c \sqrt{\alpha} \boldsymbol{y})/(c \alpha + \beta), c \beta /(c \alpha + \beta) \boldsymbol{I} \Big )
        \end{aligned}
    \end{equation}

    Ta đặt $\xi_j = \log \gamma_j - \dfrac{\alpha}{c \alpha + \beta}\dfrac{\lVert \boldsymbol{\mu}_j \rVert_2^2}{2}$, $\boldsymbol{\phi} (\boldsymbol{y})=\big ( \phi_1 (\boldsymbol{y}), \dots, \phi_J (\boldsymbol{y}) \big )$ với $\boldsymbol{\phi}_j = \xi_j + \dfrac{\sqrt{\alpha}}{c \alpha + \beta} \boldsymbol{\mu}_j^T \boldsymbol{y}$ và $\boldsymbol{\eta} (\boldsymbol{y})=\mathrm{softmax} \big ( \boldsymbol{\phi} (\boldsymbol{y}) \big )$.
    Đặt $\boldsymbol{\nu}_j (\boldsymbol{y})=(\beta \boldsymbol{\mu}_j + c \sqrt{\alpha} \boldsymbol{y})/(c \alpha + \beta), \overline{\boldsymbol{\mu}}(\boldsymbol{y})=\sum_{j=1}^J \eta_j (\boldsymbol{y}) \boldsymbol{\mu}_j$ và $\overline{\boldsymbol{\nu}} (\boldsymbol{y})=\sum_{j=1}^J \eta_j (\boldsymbol{y}) \boldsymbol{\nu}_j (\boldsymbol{y})=(\beta \overline{\boldsymbol{\mu}} (\boldsymbol{y}) + c \sqrt{\alpha} \boldsymbol{y})/(c \alpha + \beta)$.
    Khi đó ta có:

    \begin{equation}
        q(\boldsymbol{x} \vert \boldsymbol{y}) = \sum_{j=1}^J \eta_j (\boldsymbol{y}) \mathcal{N} \big ( \boldsymbol{\nu}_j (\boldsymbol{y}), c \beta / (c \alpha + \beta) \boldsymbol{I} \big )
    \end{equation}

    cũng là một phân phối trộn của các phân phối Gaussian.
    Theo tính chất của phân phối trộn của các phân phối Gaussian, đường chéo của ma trận hiệp phương sai là:

    \begin{equation}
        \mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack \boldsymbol{x} \rbrack \big) = c \beta / (c \alpha + \beta) \boldsymbol{1} + \sum_{j=1}^J \eta_j (\boldsymbol{y}) \boldsymbol{\nu}_j (\boldsymbol{y})^2 - \overline{\boldsymbol{\nu}} (\boldsymbol{y})^2
    \end{equation}

    Mặt khác $\mathrm{diag} \big( \mathrm{Cov}_{q(\boldsymbol{x} \vert \boldsymbol{y})} \lbrack \boldsymbol{x} \rbrack \big)=m \boldsymbol{I}$.
    Vì vậy:

    \begin{equation}
        c \beta / (c \alpha + \beta)d + \sum_{j=1}^J \eta_j(\boldsymbol{y}) \lVert \boldsymbol{\nu}_j (\boldsymbol{y}) \rVert_2^2 - \lVert \rVert_2^2 = d m
    \end{equation}

    phù hợp với $\boldsymbol{y}$:

    \begin{equation}
        \sum_{j=1}^J \eta_j (\boldsymbol{y}) \lVert \boldsymbol{\nu}_j (\boldsymbol{y}) \rVert_2^2 - \lVert \overline{\nu} (\boldsymbol{y}) \rVert_2^2 = \beta^2 / (c \alpha + \beta)^2 \Bigg \lbrack \sum_{j=1}^J \eta_j (\boldsymbol{y}) \lVert \boldsymbol{\mu}_j \rVert_2^2 - \lVert \overline{\boldsymbol{\mu}} \rVert_2^2 \Bigg \rbrack
    \end{equation}

    $\sum_{j=1}^J \eta_j (\boldsymbol{y}) \lVert \boldsymbol{\mu}_j \rVert_2^2 - \lVert \overline{\boldsymbol{\mu}} \rVert_2^2$ cũng phù hợp với $\boldsymbol{y}$.
    Đặt $\boldsymbol{y} = t\boldsymbol{y}_0, j_0 = \underset{j}{\mathrm{argmax}} \thickspace \boldsymbol{\mu}_j^T \boldsymbol{y}_0$. Khi đó $\lim_{t \rightarrow \infty} \eta_{j_0} (t \boldsymbol{y}_0)=1$ và:

    \begin{equation}
        \lim_{t \rightarrow \infty} \sum_{j=1}^J \eta_j (t \boldsymbol{y}_0) \lVert \boldsymbol{\mu}_j \rVert_2^2 - \lVert \overline{\boldsymbol{\mu}} (t \boldsymbol{y}_0) \rVert_2^2 =0
    \end{equation}

    Vì vậy, $\sum_{j=1}^J \eta_j (\boldsymbol{y}) \lVert \boldsymbol{\mu}_j \rVert_2^2 - \lVert \overline{\boldsymbol{\mu}} (\boldsymbol{y})  \rVert_2^2 = 0$. Điều này nghĩa là:

    \begin{equation}
        \sum_{j=1}^J \eta_j (\boldsymbol{y}) \lVert \boldsymbol{\mu}_j \rVert_2^2 - \lVert \overline{\boldsymbol{\mu}} (\boldsymbol{y}) \rVert_2^2 = \sum_{j=1}^J \eta_j (\boldsymbol{y}) \lVert \boldsymbol{\mu}_j - \overline{\boldsymbol{\mu}} (\boldsymbol{y}) \rVert_2^2 = 0
    \end{equation}

    Vì vậy $\boldsymbol{\mu}_1 = \boldsymbol{\mu}_2 = \dots = \boldsymbol{\mu}_J = \overline{\boldsymbol{\mu}} (\boldsymbol{y})$.
    Điều này mâu thuẫn với giả thuyết $\lbrace \boldsymbol{\mu}_j \rbrace_{j=1}^J$ đôi một khác nhau.
    Vì vậy bất đẳng thức \ref{eq:Inequality-Mixture-Of-Gaussian} đúng.

    \begin{md} \label{md:Mixture-Data-Distribution}
        Nếu hàm phân phối dữ liệu $q(\boldsymbol{x}_0)=\sum_{j=1}^J \mathcal{N} (\boldsymbol{\mu}_j, c \boldsymbol{I})$ là một phân phối trộn với $J \geq 2$ của phân phối Gaussian và $\lbrace \boldsymbol{\mu}_j \rbrace_{j=1}^J$ đôi một khác nhau, khi đó ta có:

        \begin{equation}
            \max_{\boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n:\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)=\mathrm{diag}\big( \boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2 \big)} L_{\mathrm{elbo}} > \max_{\boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n:\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)=\sigma_n^2 \boldsymbol{I}} L_{\mathrm{elbo}}
        \end{equation}
    \end{md}

    \textit{Chứng minh.}
    Ta chỉ cần chứng minh:

    \begin{equation}
        \min_{\boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n:\boldsymbol{\Sigma}_n=\mathrm{diag}\big( \boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2 \big)} D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big) < \max_{\boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n:\boldsymbol{\Sigma}_n=\sigma_n^2 \boldsymbol{I}} D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N})
    \end{equation}

    Như đã được đề cập trong chứng minh của định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}, $D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{0:N} \Vert p(\boldsymbol{x}_{0:N}) \big)$ có thể được phân tích thành:

    \begin{equation}
        D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big) = \sum_{n=1}^N \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big) + c
    \end{equation}

    với $c$ là một hằng số chỉ phụ thuộc vào phân phối $q$. Vì vậy ta chỉ cần chứng minh:\

    \begin{equation}
        \begin{aligned}
            &\sum_{n=1}^N \min_{\boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n:\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)=\mathrm{diag}\big( \boldsymbol{\sigma}_n (\boldsymbol{x}_n)^2 \big)} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big) \\
            < &\sum_{n=1}^N \min_{\boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n:\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)=\sigma_n^2 \boldsymbol{I}} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big)
        \end{aligned}
    \end{equation}

    Ta chỉ cần chứng minh bất đẳng thức trên đúng khi $n=1$:

    \begin{equation}
        \begin{aligned}
            & \min_{\boldsymbol{\mu}_1, \boldsymbol{\Sigma}_1:\boldsymbol{\Sigma}_1(\boldsymbol{x}_1)=\mathrm{diag}\big( \boldsymbol{\sigma}_1 (\boldsymbol{x}_1)^2 \big)} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_0 \vert \boldsymbol{x}_1) \Vert p(\boldsymbol{x}_0 \vert \boldsymbol{x}_1) \big) \\
            < & \min_{\boldsymbol{\mu}_1, \boldsymbol{\Sigma}_1:\boldsymbol{\Sigma}_1(\boldsymbol{x}_1)=\sigma_1^2 \boldsymbol{I}} \mathbb{E}_q D_{\mathrm{KL}} \big( q(\boldsymbol{x}_0\vert \boldsymbol{x}_1) \Vert p(\boldsymbol{x}_0 \vert \boldsymbol{x}_1) \big)
        \end{aligned}
    \end{equation}

    Bất đẳng thức trên đúng theo \ref{bd:Mixture-Gaussian-Data-Distribution}.

    \section{Các kết quả cho ma trận hiệp phương sai đầy đủ} \label{Appen:Section:Results-for-Full-Covariances}

    Trong mục này, ta sẽ diễn giải các kết quả cho ma trận hiệp phương sai đầy đủ. 
    Trong mệnh đề , ta sẽ thu được lời giải tối ưu của bài toán tối ưu trong công thức \ref{eq:ELBO-Maximization}.
    Trong mệnh đề , ta sẽ thu được ma trận hiệp phương sai tối ưu cho bài toán tối ưu trong công thức \ref{eq:Arbitrary-Mean-Optimize-Covariance} khi tối ưu duy nhất ma trận hiệp phương sai.
    Các chứng minh trong bổ đề , tương tự như bổ đề \ref{bd:Conditioned-Moment-Matching}

    \begin{bd} \label{bd:Joint-Optimal-Solution-Full-Covariance}
        Giả sử $q(\boldsymbol{x})$ là một hàm mật độ xác suất với trung bình $\boldsymbol{\mu}_q$ và ma trận hiệp phương sai $\boldsymbol{\Sigma}_q$ và $ơ(\boldsymbol{x})=\mathcal{N}(\boldsymbol{x} \vert \boldsymbol{\mu}, \boldsymbol{\Sigma})$ là một phân phối Gaussian. Khi đó:

        \begin{enumerate}
            \item Với ma trận hiệp phương sai bất kỳ $\boldsymbol{\Sigma}$, bài toán tối ưu hóa $\displaystyle\min_{\boldsymbol{\mu}} D_{\mathrm{KL}} (q \Vert p)$ có nghiệm trung bình tối ưu $\boldsymbol{\mu}^{\ast}=\boldsymbol{\mu}_q$
            \item Với trung bình bất kỳ $\boldsymbol{\mu}$, bài toán tối ưu hóa $\displaystyle\min_{\boldsymbol{\Sigma}} D_{\mathrm{KL}} (q \Vert p)$ có nghiệm tối ưu $\tilde{\boldsymbol{\Sigma}}^{\ast}=\boldsymbol{\Sigma}_q + (\boldsymbol{\mu} - \boldsymbol{\mu}_q)(\boldsymbol{\mu} - \boldsymbol{\mu}_q)^T$
            \item Bài toán tối ưu hóa $\displaystyle\min_{\boldsymbol{\mu}, \boldsymbol{\Sigma}} D_{\mathrm{KL}} (q \Vert p)$ có nghiệm tối ưu $\boldsymbol{\mu}^{\ast}=\boldsymbol{\mu}_q$ và $\boldsymbol{\Sigma}^{\ast} = \boldsymbol{\Sigma}_q$
        \end{enumerate}
    \end{bd}

    \textit{Chứng minh.}
    Tương tự như chứng minh của bổ đề \ref{bd:Conditioned-Moment-Matching}, nghiệm tối ưu của $D_{\mathrm{KL}}(q \Vert p)$ và $D_{\mathrm{KL}}\big( \mathcal{N} (\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q) \Vert p \big)$ tương ứng với $\boldsymbol{\mu}$ và $\boldsymbol{\Sigma}$ là như nhau.
    Ta khai triển $D_{\mathrm{KL}} \big( \mathrm{N}(\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q ) \Vert p \big)$ theo định nghĩa của độ phân kỳ Kullback-Leibler:

    \begin{equation}
        \begin{aligned}
            2 D_{\mathrm{KL}} \big( \mathcal{N}(\boldsymbol{x} \vert \boldsymbol{\mu}_q, \boldsymbol{\Sigma}_q) \Vert p \big) &= \mathrm{tr} \big( \boldsymbol{\Sigma}^{-1} \boldsymbol{\Sigma}_q \big) - d + \log \dfrac{\lvert \boldsymbol{\Sigma} \rvert}{\lvert \boldsymbol{\Sigma}_q \rvert} + \big( \boldsymbol{\mu} - \boldsymbol{\mu}_q \big)^T \boldsymbol{\Sigma}^{-1} \big( \boldsymbol{\mu} - \boldsymbol{\mu}_q \big) \\
            &= \mathrm{tr} \Big( \boldsymbol{\Sigma}^{-1} \big( \boldsymbol{\Sigma}_q + (\boldsymbol{\mu} - \boldsymbol{\mu}_q) (\boldsymbol{\mu} - \boldsymbol{\mu}_q)^T \big) \Big) + \log \dfrac{\boldsymbol{\Sigma}}{\lvert \boldsymbol{\Sigma}_q \rvert} - d
        \end{aligned}
    \end{equation}

    Vì vậy, $\displaystyle\min_{\boldsymbol{\mu}} D_{\mathrm{KL}} (q \Vert p) \Leftrightarrow \displaystyle\min_{\boldsymbol{\mu}} \big (\boldsymbol{\mu} - \boldsymbol{\mu}_q \big )^T \boldsymbol{\Sigma}^{-1} \big (\boldsymbol{\mu} - \boldsymbol{\mu}_q \big )$ có nghiệm tối ưu $\boldsymbol{\mu}^{\ast} = \boldsymbol{\mu}_q$, và $\displaystyle \min_{\boldsymbol{\Sigma}} D_{\mathrm{KL}} (q \Vert p) \Leftrightarrow \displaystyle \min_{\boldsymbol{\Sigma}} \mathrm{tr} \Big( \boldsymbol{\Sigma}^{-1} \big( \boldsymbol{\Sigma}_q + (\boldsymbol{\mu} - \boldsymbol{\mu}_q) (\boldsymbol{\mu} - \boldsymbol{\mu}_q)^T \big) \Big) + \log \lvert \boldsymbol{\Sigma} \rvert$ có nghiệm tối ưu $\tilde{\boldsymbol{\Sigma}}^{\ast}=\boldsymbol{\Sigma}_q + (\boldsymbol{\mu} - \boldsymbol{\mu}_q)(\boldsymbol{\mu} - \boldsymbol{\mu}_q)^T$.
    Kết hợp $\boldsymbol{\mu}^{\ast}$ và $\tilde{\boldsymbol{\Sigma}}^{\ast}$, ta biết rằng $\displaystyle\min_{\boldsymbol{\mu}, \boldsymbol{\Sigma}} D_{\mathrm{KL}} (q \Vert p)$ có nghiệm tối ưu $\boldsymbol{\mu}^{ast}=\boldsymbol{\mu}_q$ và $\boldsymbol{\Sigma}^{\ast}=\boldsymbol{\Sigma}_q$

    \begin{md} \label{md:Optimal-Covariance-Solely-Full-Covariance}
        Giả sử $\boldsymbol{\Sigma}_n (\boldsymbol{x}_n)$ là một ma trận hiệp phương sai đầy đủ. 
        Khi đó trung bình tối ưu của bài toán tối ưu trong công thức \ref{eq:ELBO-Maximization} là $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ trong công thức \ref{eq:Optimal-Mean} và ma trận hiệp phương sai tối ưu của bài toán tối ưu trong công thức \ref{eq:ELBO-Maximization} là:

        \begin{equation}
            \boldsymbol{\Sigma}_n^{\ast} (\boldsymbol{x}_n) = \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^T \big)
        \end{equation}
    \end{md}

    \textit{Chứng minh.}
    \cite{bao2021analytic} chứng minh rằng độ phân kỳ Kullback - Leibler giữa một hàm mật độ xác suất chung và một chuỗi Markov $p(\boldsymbol{x}_{0:N})$ được viết dưới dạng:

    \begin{equation}
        D_{\mathrm{KL}} \big ( q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big ) = \sum_{n=1}^N \mathbb{E}_{q} D_{\mathrm{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big) + c
    \end{equation}

    với $c$ là hằng số chỉ phụ thuộc vào phân phối $q$ (xem bổ đề 8 trong \cite{bao2021analytic}).
    Kết quả là quá trình tối ưu của độ phân kỳ Kullback-Leibler được phân tích thành $n$ bài toán tối ưu hóa con độc lập:

    \begin{equation}
        \min_{\boldsymbol{\mu}_n (.), \boldsymbol{\Sigma}_n (.)} \mathbb{E}_q D_{\mathbb{KL}} \big( q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \Vert p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) \big), 1 \leq n \leq N
    \end{equation}

    $q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)$ là hàm mật độ xác suất với trung bình $\mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack$ và ma trận hiệp phương sai $\mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack$ và $p(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n) = \mathcal{N} \big( \boldsymbol{x}_{n-1} \vert \boldsymbol{\mu}_n (\boldsymbol{x}_n), \boldsymbol{\Sigma}_n (\boldsymbol{x}_n) \big)$ là phân phối Gaussian,
    theo bổ đề \ref{bd:Joint-Optimal-Solution-Full-Covariance} và bổ đề \ref{bd:Mean-Covariance}, ta biết nghiệm tối ưu là:

    \begin{equation}
        \begin{aligned}
            \boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n) &= \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \tilde{\boldsymbol{\mu}}_n \big( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_m}} (\boldsymbol{x}_n - \sqrt{\overline{\beta}_n}\mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack) \big) \\
            \boldsymbol{\Sigma}_n^{\ast} (\boldsymbol{x}_n) &= \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^T \big)
        \end{aligned}
    \end{equation}

    \begin{md} \label{md:Corrected-Optimal-Covariance-Solely-Full-Covariance}
        Giả sử $\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)$ là ma trận hiệp phương sai đầy đủ.
        Với trung bình bất kỳ $\boldsymbol{\mu}_n (\boldsymbol{x}_n)$ được tham số hóa bởi một mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ như trong công thức \ref{eq:Estimated-Optimal-Mean}, ma trận hiệp phương sai tối ưu $\tilde{\boldsymbol{\Sigma}}_n^{\ast} (\boldsymbol{x}_n)$ của bài toán tối ưu trong công thức \ref{eq:Arbitrary-Mean-Optimize-Covariance} là:

        \begin{equation}
            \begin{aligned}
                \tilde{\boldsymbol{\Sigma}}_n^{\ast} (\boldsymbol{x}_n) &= \boldsymbol{\Sigma}_n^{\ast} (\boldsymbol{x}_n) + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \underbrace{\big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)\big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^T}_{\mathrm{error}} \\
                &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \big \lbrack \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big) \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^T \big \rbrack
            \end{aligned}
        \end{equation}
    \end{md}

    \textit{Chứng minh.}

    Theo bổ đề \ref{bd:Joint-Optimal-Solution-Full-Covariance}, ta biết hiệp phương sai tối ưu $\tilde{\boldsymbol{\Sigma}}_n^{\ast}$ là:

    \begin{equation}
        \tilde{\boldsymbol{\Sigma}}_n^{\ast} (\boldsymbol{x}_n) = \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack + \big( \boldsymbol{\mu}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big)\big( \boldsymbol{\mu}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big)^T
    \end{equation}

    Theo mệnh đề \ref{md:Optimal-Covariance-Solely-Full-Covariance}, $\mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \boldsymbol{\Sigma}_n^{\ast} (\boldsymbol{x}_n)$.

    Theo bỏ đề \ref{bd:Mean-Covariance} và tham số hóa $\boldsymbol{\mu}_n (\boldsymbol{x})$ trong công thức \ref{eq:Estimated-Optimal-Mean}, ta có:

    \begin{equation}
        \boldsymbol{\mu}_n (\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack = \gamma_n \sqrt{\dfrac{\overline{\beta}_n}{\overline{\alpha}_n}} \big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)
    \end{equation}

    Ta thu được:

    \begin{equation*}
        \begin{aligned}
            \tilde{\boldsymbol{\Sigma}}_n^{\ast} (\boldsymbol{x}_n) &= \mathrm{Cov}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack + \big( \boldsymbol{\mu}_n(\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big)\big( \boldsymbol{\mu}_n(\boldsymbol{x}_n) - \mathbb{E}_{q(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{x}_{n-1} \rbrack \big)^T \\
            &= \boldsymbol{\Sigma}_n^{\ast} (\boldsymbol{x}_n) + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \underbrace{\big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)\big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^T}_{\mathrm{error}} \\
            &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \big \lbrace \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^T - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^T + \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^T  \big \rbrace \\
            &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \big \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T - \boldsymbol{\epsilon}_n \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^T - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \boldsymbol{\epsilon}_n^T + \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n) \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)^T \big \rbrack \\
            &= \lambda_n^2 \boldsymbol{I} + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \big \lbrack \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big) \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^T \big \rbrack
        \end{aligned}
    \end{equation*}

    Ta cần chú ý rằng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \boldsymbol{\epsilon}_n^T \rbrack$ trong mệnh đề \ref{md:Optimal-Covariance-Solely-Full-Covariance} và $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \big \lbrack \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big) \big( \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \big)^T \big \rbrack$ trong mệnh đề \ref{md:Corrected-Optimal-Covariance-Solely-Full-Covariance} là các ma trận có kích thước $d\times d$.
    Ta cũng có thể học các ước lượng có điều kiện bằng cách huấn luyện một mạng và đầu ra là ma trận có kích thước $d \times d$ bằng hàm mục tiêu MSE, sau đó ta ước lượng $\boldsymbol{\Sigma}_n^{\ast} (\boldsymbol{x}_n)$ và $\tilde{\boldsymbol{\Sigma}}_n^{\ast} (\boldsymbol{x}_n)$ sử dụng mạng.

    Tuy nhiên, thu được mẫu từ các bước chuyển tiếp là phân phối Gaussian với ma trận hiệp phương sai đầy đủ cần sử dụng một phép phân tích của ma trận hiệp phương sai, ví dụ phân tích Cholesky có độ phức tạp thời gian $\mathcal{O}(d^3)$.
    Trong thực tế, $d$ có thể rất lớn (ảnh có độ phân giải cao), một phép phân tích tốn rất nhiều thời gian.
    Vì vậy, trong thực tế việc sử dụng ma trận đường chéo là phù hợp để không phải sử dụng các phép phân tích với chi phí lớn về mặt thời gian.

    \section{Mở rộng DPMs sang bước thời gian liên tục} \label{Appen:Section:Extention-to-DPMs-with-Continuous-Timesteps}

    Để thu được ước lượng của $\boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$ xuất hiện trong mệnh đề \ref{md:Continuous-Optimal-Covariance}, ta sử dụng mạng $\boldsymbol{h}_t (\boldsymbol{x}_t) \in \mathbb{R}^d$ để học $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lbrack \boldsymbol{\epsilon}_t^2 \rbrack$ bằng cực tiểu hóa hàm MSE:

    \begin{equation}
        \min_{\boldsymbol{h}_t} \mathbb{E}_t \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lVert \boldsymbol{\epsilon}_t^2 - \boldsymbol{h}_t (\boldsymbol{x}_t) \rVert_2^2
    \end{equation}

    với $t$ được lấy mẫu theo phân phối đều từ $\lbrack 0, T, \rbrack$. Sau đó ta thu được $\boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$:

    \begin{equation}
        \hat{\boldsymbol{\sigma}}_{s \vert t} (\boldsymbol{x}_t)^2 = \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \big( \boldsymbol{h}_t (\boldsymbol{x}_t) - \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t)^2 \big)
    \end{equation}

    Để thu được ước lượng của $\boldsymbol{\sigma}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$ được đề cập trong mệnh đề \ref{md:Continuous-Corrected-Optimal-Covariance}, ta sử dụng mạng $\boldsymbol{g}_t(\boldsymbol{x}_t) \in \mathbb{R}^d$ để học $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \big \lbrack \big( \boldsymbol{\epsilon}_t - \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) \big)^2 \big \rbrack$ bằng cách cực tiểu hóa hàm MSE:

    \begin{equation}
        \min_{\boldsymbol{g}_t} \mathbb{E}_t \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_t)} \lVert \big( \boldsymbol{\epsilon}_t - \hat{\boldsymbol{\epsilon}}_t (\boldsymbol{x}_t) \big)^2 - \boldsymbol{g}_t (\boldsymbol{x}_t) \rVert_2^2
    \end{equation}

    Với $t$ được lấy mẫu theo phân phối đều từ $\lbrack 0, T \rbrack$. Khi đó ta thu được ước lượng của $\tilde{\boldsymbol{\sigma}}_{s \vert t}^{\ast} (\boldsymbol{x}_t)^2$:

    \begin{equation}
        \hat{\tilde{\boldsymbol{\sigma}}}_{s \vert t} (\boldsymbol{x}_t)^2 = \tilde{\beta}_{s \vert t} \boldsymbol{1} + \dfrac{\beta_{t \vert s}^2}{\beta_{t \vert 0} \alpha_{t \vert s}} \boldsymbol{g}_t (\boldsymbol{x}_t)
    \end{equation}

    \section{Sinh dữ liệu trên quỹ đạo con} \label{Appen:Section:Inference-on-Trajectories}

    Để tăng tốc quá trình sinh dữ liệu, ta có thể đảo ngược một quá trình khuếch tán thuận ngắn hơn $q(\boldsymbol{x}_{\tau_0}, \dots, \boldsymbol{x}_{\tau_k} \vert \boldsymbol{x}_0)$ ràng buộc trên một quỹ đạo $1 \leq \tau_1 < \dots < \tau_K = N$ gồm $K$ bước thời gian \cite{song2020denoising}, \cite{bao2021analytic}.
    Theo như ký hiệu trong \cite{bao2021analytic}, quá trình khuếch tán thuận rút gọn được định nghĩa là:

    \begin{equation*}
        \begin{aligned}
            & q(\boldsymbol{x}_{\tau_1}, \boldsymbol{x}_{\tau_2}, \dots, \boldsymbol{x}_{\tau_K} \vert \boldsymbol{x}_0) = q(\boldsymbol{x}_{\tau_K} \vert \boldsymbol{x}_0) \prod_{k=2}^K q(\boldsymbol{x}_{\tau_{k-1}} \vert \boldsymbol{x}_{\tau_k}, \boldsymbol{x}_0) \\
            & q(\boldsymbol{x}_{\tau_{k-1}} \vert \boldsymbol{x}_{\tau_k}, \boldsymbol{x}_0) = \mathcal{N} \big( \boldsymbol{x}_{\tau_{k-1}} \vert \tilde{\boldsymbol{\mu}}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k}, \boldsymbol{x}_0), \lambda_{\tau_{k-1} \vert \tau_k}^2 \boldsymbol{I} \big) \\
            & \tilde{\boldsymbol{\mu}}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k}, \boldsymbol{x}_0) = \sqrt{\overline{\alpha}_{\tau_{k-1}}} \boldsymbol{x}_0 + \sqrt{\overline{\beta}_{\tau_{k-1}} - \lambda_{\tau_{k-1} \vert \tau_k}^2} \dfrac{\boldsymbol{x}_{\tau_k} - \sqrt{\overline{\alpha}_{\tau_k}}\boldsymbol{x}_0}{\sqrt{\overline{\beta}_{\tau_k}}}
        \end{aligned}
    \end{equation*}

    Tương tự như công thức \ref{eq:Reverse-Process}, mô hình Markov rút gọn để đảo ngược quá trình khuếch tán thuận được định nghĩa là:

    \begin{equation*}
        \begin{aligned}
            & p(\boldsymbol{x}_0, \boldsymbol{x}_{\tau_1}, \dots, \boldsymbol{x}_{\tau_K}) = p(\boldsymbol{x}_{\tau_K}) \prod_{k=1}^K p(\boldsymbol{x}_{\tau_{k-1} \vert \tau_k}) \\
            & p(\boldsymbol{x}_{\tau_{k-1} \vert \tau_k}) = \mathcal{N} \big( \boldsymbol{x}_{\tau_{k-1}} \vert \boldsymbol{\mu}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k}), \boldsymbol{\Sigma}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k}) \boldsymbol{I} \big)
        \end{aligned}
    \end{equation*}

    Theo định lý \ref{dl:Optimal-Solution-To-Joint-Optimization}, khi $\boldsymbol{\Sigma}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k})=\mathrm{diag} \big( \boldsymbol{\sigma}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k})^2 \big)$, hiệp phương sai tối ưu $\boldsymbol{\sigma}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k})^2$ là:

    \begin{equation}
        \boldsymbol{\sigma}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k})^2 = \lambda_{\tau_{k-1} \vert \tau_k}^2 \boldsymbol{1} + \gamma_{\tau_{k-1} \vert \tau_k}^2 \dfrac{\overline{\beta}_{\tau_k}}{\overline{\alpha}_{\tau_k}} \Big( \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_{\tau_k})} \lbrack \boldsymbol{\epsilon}_{\tau_k}^2 \rbrack - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_{\tau_k})} \lbrack \boldsymbol{\epsilon}_{\tau_k} \rbrack^2 \Big)
    \end{equation}

    với $\boldsymbol{\epsilon}_{\tau_k}=\dfrac{\boldsymbol{x}_{\tau_k} - \sqrt{\overline{\alpha}_{\tau_k}} \boldsymbol{x}_0}{\sqrt{\overline{\beta}_{\tau_k}}}$ là nhiễu để tạo ra $\boldsymbol{x}_{\tau_k}$ từ $\boldsymbol{x}_0$ và $\gamma_{\tau_{k-1} \vert \tau_k}=\sqrt{\overline{\alpha}_{\tau_{k-1}}} - \sqrt{\overline{\beta}_{\tau_{k-1}} - \lambda_{\tau_{k-1} \vert \tau_k}^2} \sqrt{\dfrac{\overline{\alpha}_{\tau_k}}{\overline{\beta}_{\tau_k}}}$.
    Vì vậy ta có thể sử dụng mạng dự đoán nhiễu bình phương $\boldsymbol{h}_n(\boldsymbol{x}_n)$ được luấn luyện trên hàm mục tiêu ở công thức \ref{eq:Square-Noise-Prediction-Network-MSE-Loss} và ước lượng của $\boldsymbol{\sigma}_{\tau_{k-1} \vert \tau_k}^{\ast} (\boldsymbol{x}_{\tau_k})^2$ bằng công thức:

    \begin{equation}        
        \hat{\boldsymbol{\sigma}}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k})^2 = \lambda_{\tau_{k-1} \vert \tau_k}^2 \boldsymbol{1} + \gamma_{\tau_{k-1} \vert \tau_k}^2 \dfrac{\overline{\beta}_{\tau_k}}{\overline{\alpha}_{\tau_k}} \big( \boldsymbol{h}_{\tau_k} (\boldsymbol{x}_{\tau_k}) - \hat{\boldsymbol{\epsilon}}_{\tau_k} (\boldsymbol{x}_{\tau_k})^2 \big)
    \end{equation}

    Khi xét tới trung bình không hoàn hảo (khi xét sai lệch của $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$), tương ứng với định lý \ref{dl:Solely-Optimal-Covariance}, hiệp phương sai tối ưu hiệu chỉnh là $\tilde{\boldsymbol{\sigma}}_{\tau_{k-1} \vert \tau_k}^{\ast} (\boldsymbol{x}_{\tau_k})^2$ là:

    \begin{equation}
        \tilde{\boldsymbol{\sigma}}_{\tau_{k-1} \vert \tau_k}^{\ast} (\boldsymbol{x}_{\tau_k})^2 = \lambda_{\tau_{k-1} \vert \tau_k}^2 \boldsymbol{1} + \gamma_{\tau_{k-1} \vert \tau_k}^2 \dfrac{\overline{\beta}_{\tau_k}}{\overline{\alpha}_{\tau_k}} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_{\tau_k})} \big \lbrack \big(\boldsymbol{\epsilon}_{\tau_k} - \hat{\boldsymbol{\epsilon}}_{\tau_k} (\boldsymbol{x}_{\tau_k}) \big)^2 \rbrack
    \end{equation}

    Vì vậy ta sử dụng mạng dự đoán phần dư nhiễu bình phương $\boldsymbol{g}_n (\boldsymbol{x}_n)$ được huấn luyện trên hàm mục tiêu ở công thức \ref{eq:Square-Noise-Prediction-Network-MSE-Loss} và ước lượng của $\tilde{\boldsymbol{\sigma}}_{\tau_{k-1} \vert \tau_k}^{\ast} (\boldsymbol{x}_{\tau_k})^2$ là:

    \begin{equation}
        \hat{\tilde{\boldsymbol{\sigma}}}_{\tau_{k-1} \vert \tau_k} (\boldsymbol{x}_{\tau_k})^2 = \lambda_{\tau_{k-1} \vert \tau_k}^2 \boldsymbol{1} + \gamma_{\tau_{k-1} \vert \tau_k}^2 \boldsymbol{g}_{\tau_k} (\boldsymbol{x}_{\tau_k})
    \end{equation}

    Ta cần nhấn mạnh rằng quá trình sinh dữ liệu trên quỹ đạo rút gọn không cần huấn luyện một mạng dự đoán phần dư nhiễu bình phương hoặc một mạng dự đoán nhiễu bình phương, quá trình rút gọn và quá trình đầy đủ sử dụng chung phân phối cận biên vì vậy ta có thể sử dụng các mạng dự đoạn được huấn luyện với số bước thời gian đầy đủ.

    \section{Một số bàn luận}

    \subsection{Khuếch đại sai lệch} \label{Appen:Subsection:Error-Amplification}

    Ta cần chú ý rằng trong SN-DPM, sai lệch của $\hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)^2$ hay bị khuếch đại so với $\hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)$.
    $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2$ sử dụng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)^2$ là bình phương của đầu ra của mô hình.
    Tuy nhiên hàm mục tiêu cho $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ trong công thức \ref{eq:Noise-Prediction} là hàm mục tiêu MSE giữa $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ và $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack$ thay vì bình phương của nhiễu.
    Vì vậy, sai lệch giữa $\hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)^2$ và $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2$ có xu hướng bị khuếch đại.
    Đặc biệt sai lệch của $\hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)^2$ và $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack^2$ tại thành phần thứ $i$ là $\big \lbrack \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)_i^2 - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack_i^2 \big \rbrack=A_i \big \lbrack \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)_i - \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack_i \big \rbrack$ với $A_i = \big \lbrack \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)_i + \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack_i \big \rbrack$.
    Vì vậy, sai lệch của $\hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n)^2$ tại thành phần thứ $i$ bị nhân với một hệ số $A_i$.
    Trong thực tế, giá trị của $A_i$ không đảm bảo bị chặn và sai lệch có thể khuếch đại bởi một hệ số lớn.

    Ngược lại, NPR-DPM không gặp phải vấn đề về khuếch đại sai số, khi mà mô hình này sử dụng mô hình mạng $\boldsymbol{g}_n (\boldsymbol{x}_n)$ để ước lượng $\mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)}$ và trực tiếp cực tiểu hóa hàm mục tiêu MSE giữa giá trị đầu ra của mạng và giá trị thực tế thu được.

    \subsection{NPR-DPM không phải lúc nào cũng tốt hơn SN-DPM}

    Ta chú ý rằng SN-DPM tốt hơn về độ đô FID và NPR-DPM tốt hơn về ước lượng hợp lý.
    Khả năng sinh dữ liệu của NPR-DPM trên độ đo ước lượng hợp lý được đảm bảo vì mô hình này tối ưu hóa hàm $\log$ của ước lượng hợp lý với trung bình không hoàn hảo.
    Nhưng chất lượng ảnh được sinh ra và ước lượng hợp lý không nhất thiết phải nhất quán với nhau (mục 3.2 trong \cite{theis2016note}) và NPR-DPM không trực tiếp tối ưu hóa chất lượng ảnh được sinh ra.
    Vì vậy NPR-DPM trên độ đo FID không được đảm bảo.

    Trong thực tế, NPR-DPM rất hữu ích trong các ứng dụng như nén không tổn hao (mục 7.3 trong \cite{kingma2021variational}),
    nơi mà ước lượng hợp lý và độ hiệu quả tính toán đóng một vai trò quan trọng.

    \section{Chi tiết thực nghiệm} \label{Experimental-Details}

    \subsection{Chi tiết của các mô hình dự đoán nhiễu được tiền huấn luyện}

    Trong bảng \ref{table:Details-of-Pretrained-Noise-Prediction-Network}, ta sẽ liệt kê chi tiết về các mạng dự đoán nhiễu được tiền huấn luyện.
    Mô hình được tiền huấn luyện trên ImageNet 64x64 bao gồm mạng dự đoán nhiễu và một mạng hiệp phương sai.
    Ta chỉ sử dụng mạng dự đoán nhiễu.

    \begin{table}[h!] 
        \caption{Chi tiết của các mạng dự đoán nhiễu được sử dụng trong thử nghiệm.
        LS nghĩa là lịch trình tuyến tính của $\beta_n$ trong quá trình khuếch tán thuận của bước thời gian rời rạc (công thức \ref{eq:Forward-Process}).
        CS nghĩa là lịch trình cosine của $\beta_n$ \cite{nichol2021improved} trong quá trình khuếch toán thuận của bước thời gian rời rạc (công thức \ref{eq:Forward-Process}).
        VP SDE được định nghĩa bằng $d \boldsymbol{x}=- \dfrac{1}{2} \beta(t) \boldsymbol{x} dt + \sqrt{\beta(t)} d \boldsymbol{w}$, với $\beta (t)$ là một hàm tuyến tính theo $t$ với $\beta(0)=1$ và $\beta(1)=20$ \cite{song2020score}}
        \begin{tabular}{l c c c c}
            \hline
            & Loại bước thời gian & Số bước thời gian $N$ & Quá trình thuận & Công trình \\
            \hline
            CIFAR10 (LS) & Rời rạc & 1000 & LS & \cite{bao2021analytic} \\
            CIFAR10 (CS) & Rời rạc & 1000 & CS & \cite{bao2021analytic} \\
            CIFAR10 (VP SDE) & Liên tục & \_ & VP SDE & \cite{song2020score} \\
            CelebA 64x64 & Rời rạc & 1000 & LS & \cite{song2020denoising} \\
            ImageNet 64x64 & Rời rạc & 4000 & CS & \cite{nichol2021improved} \\
            LSUN Bedroom & Rời rạc & 1000 & LS & \cite{ho2020denoising} \\
            \hline
        \end{tabular}
        \label{table:Details-of-Pretrained-Noise-Prediction-Network}
    \end{table}

    \subsection{Cấu trúc chi tiết của mạng dự đoán nhiễu}

    Trong bảng \ref{table:Structures-Details-of-Prediction-Network}, ta liệt kê cấu trúc chi tiết của $N_1$ và $NN_2$ của mạng dự đoán nhiễu được sử dụng trong thực nghiệm.

    \begin{table}[h!] 
        \caption{$NN_1$ là mạng dự đoán nhiễu được tiền huấn luyện và $NN_2$ là SN hoặc NPR sử dụng trong thực nghiệm.
        CONV là viết tắ của mạng tích chập. RES là các khối phần dư}
        \begin{center}
            \begin{tabular}{l c c c }
                \hline
                & $NN_1$ & $NN_2$ (SN) & $NN_2$ (NPR) \\
                \hline
                CIFAR10 (LS) & CONV & CONV & CONV \\
                CIFAR10 (CS) & CONV & CONV & CONV \\
                CIFAR10 (VP SDE) & CONV & CONV & CONV \\
                CelebA 64X64 & CONV & CONV & CONV \\
                ImageNet 64x64 & CONV & RES + CONV & CONV \\
                LSUN Bedroom & CONV & RES + CONV & CONV \\
                \hline
            \end{tabular}
        \end{center}
        \label{table:Structures-Details-of-Prediction-Network}
    \end{table}

    \subsection{Chi tiết về chi phí bộ nhớ và chi phí thời gian} \label{Appen:Subsection:Details-of-Memory-and-Time-Cost}

    Trong bảng \ref{table:Model-size}, ta liệt kê chi phí bộ nhớ và chi phí thời gian của các mô hình (tương ứng với các phương pháp) được sử dụng trong thực nghiệm.
    Chi phí bộ nhớ của SN hoặc NPR là không đáng kể. Thời gian tăng thêm của SN hoặc NPR là không đáng kể trên CIFAR10, CelebA 64x64, và khoảng 4.5\% trên tập ImageNet 64x64, và khoảng 10 \% trên tập LSUN Bedroom.

    \begin{table}[h!]
        \caption{Kích thước của mô hình (MB) và thời gian chạy trung bình (ms) để chạy một bước qua mạng (thời gian để tính toán nhiễu và thời gian để tính toán qua SN và NPR).
        Ta cũng sẽ liệt kê thời gian tăng thêm của SN và NPR tương đối so với mạng dự đoán nhiễu.
        Tất cả được thực hiện với batch size là 10 và trên một GeForce RTX 2080 Ti.}
        \begin{center}
            \resizebox{\columnwidth}{!}{
                \begin{tabular}{l c c c}
                    \hline
                    & Mạng dự đoán nhiễu & SN-DPM & NPR-DPM \\
                    \hline
                    CIFAR10 (LS) & 200.44 MB / 25.65 MS & 200.45 MB / 25.77 MS (+0.5\%) & 200.45 MB / 25.71 MS (+0.2\%) \\
                    CIFAR10 (CS) & 200.44 MB / 25.26 MS & 200.45 MB / 25.62 MS (+1.4\%) & 200.45 MB / 25.64 MS (+1.5\%) \\
                    CIFAR10 (VP SDE) & 235.77 MB / 26.98 MS 235.78 MB / 27.17 MS (+0.7\%) & 235.78 MB / 27.17 MS (+0.7\%) \\
                    CelebA 64X64 & 300.22 MB / 48.64 MS & 300.23 MB / 49.20 MS (+1.2\%) & 300.23 MB / 49.18 MS (+1.1\%) \\
                    ImageNet 64X64 & 461.82 MB / 72.32 MS & 463.47 MB / 75.56 MS (+4.5\%) & 461.84 MB / 72.80 MS (+0.7\%) \\
                    LSUN Bedroom & 433.63 MB / 441.41 MS & 435.02 MB / 485.54 MS (+10.0\%) & 433.64 MB / 448.74 MS (+1.7\%) \\
                    \hline
                \end{tabular}
            }
        \end{center}
        \label{table:Model-size}
    \end{table}

    \subsection{Chi tiết huấn luyện}
    
    Ta sử dụng cấu hình huấn luyện tương tự như mạng dự đoán nhiễu trong \cite{bao2021analytic}.
    Trên tất cả các tập dự liệu, ta sử dụng thuật toán AdamW \cite{loshchilov2018decoupled} với tốc độ học 0.0001.
    Ta huấn luyện trên 500000 bước và trung bình dịch chuyển hàm mũ (EMA) với hệ số 0.9999.
    Ta sử dụng batch size là 64 trên tập LSUN Bedroom và 128 trên các tập khác.
    Ta sẽ lưu lại một checkpoint sau mỗi 10000 bước và lựa chọn mô hình với tham số tốt nhất trên độ đo FID trên 1000 ảnh được sinh ra.
    Mặc định, các ảnh được sinh với số bước đầy đủ, ngoại trừ tập LSUN Bedroom.
    Trên tập LSUN Bedroom, các ảnh được sinh ra được với 100 bước với chi phí thời gian chấp nhận được (chi phí thời gian trên tập LSUN Bedroom lớn hơn rất nhiều so với các tập khác).

    Huấn luyện một mạng SN hoặc NPR trên tập CIFAR10 mất khoảng 32 giờ trên một GeForce RTX 2080Ti.
    Huấn luyện trên tập CelebA 64x64 mất khoảng 72 giờ trên hai GeForce RTX 2080Ti.
    Huấn luyện trên tập ImageNet 64x64 mất khoảng 83 giờ trên hai GeForece RTX 2080ti. 
    Huấn luyện trên tập LSUN Bedroom mất khoảng 171 giờ trên bốn GeFore RTX 2080 Ti.

    \subsection{Log của ước lượng hợp lý và lấy mẫu}

    Dữ liệu ảnh là một vector của các số thực trong $\lbrace 0, 1, \dots, 255 \rbrace$ và ta sẽ đưa các giá trị này về khoảng $\lbrack -1, 1 \rbrack$ theo \cite{ho2020denoising}, \cite{bao2021analytic}.

    \textbf{Log của ước lượng hợp lý.} Theo \cite{ho2020denoising}, \cite{bao2021analytic}, ta rời rạc hóa bước chuyển tiếp Markov cuối cùng $p(\boldsymbol{x}_0 \vert \boldsymbol{x}_1)$ để thu được NLL rời rạc và cận trên.
    Ước lượng hợp lý được đánh giá trên toàn tập test.

    \textbf{Lấy mẫu.} Theo \cite{ho2020denoising}, \cite{bao2021analytic}, ta chỉ hiển thị trung bình của $p(\boldsymbol{x}_0 \vert \boldsymbol{x}_1)$ mà không phải là lấy mẫu ở bước cuối cùng của quá trình lấy mẫu.
    Theo \cite{bao2021analytic}, ta sẽ chặn hiệp phương sai $\boldsymbol{\sigma}_2 (\boldsymbol{x}_2)^2$ của $p(\boldsymbol{x}_1 \vert \boldsymbol{x}_2)$ bởi chuẩn vô cùng là $\lVert \boldsymbol{\sigma}_2 (\boldsymbol{x}_2) \rVert_{\infty} \mathbb{E} \lvert \epsilon \rvert \leq \dfrac{2}{255}y$ với $\lVert \boldsymbol{\sigma}_2 (\boldsymbol{x}_2) \rVert_{\infty}$ ký hiệu là chuẩn vô cùng,
    $\epsilon$ là phân phối Gaussian chuẩn tắc và $y$ là độ thay đổi lớn nhất có thể chịu được trên từng kênh màu.
    Theo \cite{bao2021analytic} ta sử dụng $y = 2$ trên CIFAR10 (LS) và trên CelebA 64x64 với quá trình khuếch tán thuận DDPM.
    Các cấu hình khác sử dụng $y=1$.
    Theo \cite{bao2021analytic}, ta tính độ đo FID trên 50000 ảnh được sinh ra, sử dụng code chính thức của FID được viết trên PyTorch (\url{(https://github.com/mseitzer/pytorch-fid}).
    Theo \cite{nichol2021improved}, \cite{bao2021analytic}, thống kê tham chiếu của FID được tính dựa trên toàn bộ tập huấn luyện của CIFAR10 và tập ImageNet 64x64, tập 50 nghìn ảnh huấn luyện trên CelebA 64x64 và tập LSUN Bedroom.

    \subsection{Số mẫu Monte Carlo để tính toán quỹ đạo tối ưu}

    Để tính toán quỹ đạo tối ưu cần ước lượng các thành phần được phân tích xuất hiện trong $L_{\mathrm{elbo}}$, liên quan đến ước lượng Monte Carlo được tính trên tập huấn luyện \cite{watson2021learning}, \cite{bao2021analytic}.
    Theo \cite{bao2021analytic}, ta sử dụng 50000 mẫu trên tập CIFAR10, 10000 mẫu trên tập CelebA 64x64 và ImageNet 64x64.

    \subsection{Thử nghiệm chi tiết trên các bảng \ref{table:FID-CIFAR10}, \ref{table:Smallest-steps-to-achieved-FID-6}, \ref{table:Upper-Bound}}

    Trong bảng \ref{table:FID-CIFAR10} và bảng \ref{table:Upper-Bound}, kết quả của các mô hình cơ bản và phương pháp của ta dựa trên cùng một mạng dự đoán nhiễu (các mô hình được liệt kê ở bảng \ref{table:Details-of-Pretrained-Noise-Prediction-Network}).
    Các kết quả về các mô hình này trong DPMs với bước thời gian rời rạc được cung cấp bởi \cite{bao2021analytic}.
    Cho DPMs với bước thời gian liên tục, ta thu được kết quả của Euler-Maruyama solver và dòng xác suất bằng cách chạy code \url{https://github.com/yang-song/score_sde_pytorch} của \cite{song2020score} và thu được kết quả của Ancestral Sampling và Analytic-DPM \cite{bao2021analytic}.

    Trong bảng \ref{table:Smallest-steps-to-achieved-FID-6}, kết quả của DDPM, DDIM, Analytic-DPM và phương pháp của ta dựa trên cùng một mạng dự đoán nhiễu (các mô hình được liệt kê ở bảng \ref{table:Details-of-Pretrained-Noise-Prediction-Network}).
    Chi phí thời gian trên một bước thời gian riêng biệt là như nhau trên tất cả các mô hình (DDPM, DDIM, Improved DDPM và Analytic DPM) dựa trên thống kê báo cáo trong bảng 4 trong \cite{bao2021analytic}).
    Tỷ số giữa chi phí thời gian trong một bước thời gian riêng biệt trong NPR-DPM và SN-DPM dựa trên quá trình khuếch tán thuận của DDPM dựa trên các tập dữ liệu.
    Hai lựa chọn SN-DPM và NPR-DPM yêu cầu số bước thời gian nhỏ hơn các lựa chọn khác.

    \section{Thực nghiệm bổ sung}

    \subsection{So sánh ước lượng hợp lý}

    Ta so sánh NPR-DPM và Improved DDPM \cite{nichol2021improved} dựa trên tập ImageNet 64x64.
    Improved-DDPM tham số hóa ma trận hiệp phương sai đường chéo sử dụng nội suy giữa $\beta_n$ và $\tilde{\beta}_n$ và học ma trận hiệp sai trực tiếp bằng cách tối ưu hóa $L_{\mathrm{elbo}}$.
    Trong bảng \ref{table:Likelihood-comparison}, NPR-DDPM có thể thu được một kết quả ước lượng hợp lý phù hợp chỉ với một số bước thời gian nhỏ, trái ngược với Improved DDPM.
    Với số bước thời gian đầy đủ, hai phương pháp cho cùng một kết quả trên ước lượng hợp lý.
    Điều này cho thấy rằng sử dụng một hàm mục tiêu thay thế ví dụ như hàm mục tiêu MSE có thể thu được cùng kết quả ước lượng hợp ly so với trực tiếp tối ưu hóa $L_{\mathrm{elbo}}$.

    \begin{table}[h!]
        \caption{Cận trên ($-L_{\mathrm{elbo}}$) là số âm của log của ước lượng hợp lý với quá trình khuếch tán thuận của DDPM trên tập ImageNet và số bước đầy đủ}
        \begin{center}
            \begin{tabular}{lrrrrrrr}
                \hline
                Mô hình \textbackslash \# Số bước K & 25 & 50 & 100 & 200 & 400 & 1000 & 4000 \\
                \hline
                Improved DDPM &  18.91 & 8.46 & 5.27 & 4.24 & 3.86 & 3.68 & \textbf{3.57} \\
                NPR-DDPM & \textbf{4.66} & \textbf{4.22} & \textbf{3.96} & \textbf{3.80} & \textbf{3.71} & \textbf{3.64} & \textbf{3.60} \\
                \hline
            \end{tabular}
        \end{center}
        \label{table:Likelihood-comparison}
    \end{table}

    \subsection{Phương sai của ước lượng hợp lý}

    Ta chú ý rằng với số bước thời gian đầy đủ, kết quả ước lượng hợp lý của Analytic-DPM và NPR-DDPM trong bảng \ref{table:Smallest-steps-to-achieved-FID-6} là rất gần nhau.
    Để làm giảm hiệu ứng của ngẫu nhiên, ta báo cáo độ lệch tiêu chuẩn của kết quả ước lượng hợp lý dưới cấu hình số bước thời gian đầy đủ trong bảng \ref{table:Likelihood-Variance}.

    \begin{table}
        \caption{Cận trên ($-L_{\mathrm{elbo}}$) là số âm của log của ước lượng hợp lý.
        Ta lặp lại 5 lần với seeds khác nhau và báo cáo trung bình và độ lệch chuẩn.
        Từng lần chạy ta chọn ngẫu nhiên 10000 ảnh}
        \begin{center}
            \begin{tabular}{lcccc}
                \hline
                & CIFAR10 (LS) & CIFAR10 (CS) & CelebA 64x64 & ImageNet 64x64 \\
                \hline
                Analytic-DPM \cite{bao2021analytic} & 3.58593 $\pm$ 0.00028 & 3.42229$\pm$0.00019 & 2.65657$\pm$0.00126 & 3.61749$\pm$0.00745 \\
                NPR-DDPM & 3.57204$\pm$0.00039 & 3.41013$\pm$0.00031 & 2.65257$\pm$0.00113 & 3.59660$\pm$0.00793 \\
                \hline
            \end{tabular}
        \end{center}
        \label{table:Likelihood-Variance}
    \end{table}

    \subsection{So sánh sau khi chuẩn hóa chi phí tăng thêm}
    
    Ta biểu diễn các kết quả sau khi chuẩn hóa các chi phí tăng thêm. Trong bảng \ref{table:FID-Comparision-Normalization}, phương pháp của ta vẫn tỏ ra vượt trội so với các mô hình còn lại.
    Ta cũng so sánh với "Gotta Go Fast" SDE solver \cite{jolicoeur2021gotta} và phương pháp của ta cũng tỏ ra tốt hơn khi NFE nhỏ ($\leq 49$).
    Khi NFE lớn ($\geq 147$), các phương pháp khác có kết quả tương tự nhau.

    Ta cũng liệt kê các kết quả sau khi chuẩn hóa chi phi huấn luyện tăng thêm.
    Trên CIFAR10 (LS), ta huấn luyện một mạng dự đoán nhiễu với số bước là 300000 bước và huấn luyện mạng SN hoặc NPR với 200000 bước.
    Điều này đảm bảo tổng chi phí huấn luyện luôn nhỏ hơn mô hình CIFAR10 (LS) được cung cấp trong \cite{bao2021analytic} được huấn luyện với 500000 bước.
    Với số bước thời gian lần lượt là 24 và 49 bước, NPR-DPM thu được FID lần lượt là 10.56 và 6.24, SN-DDPM thu được FID lần lượt là là 7.51 và 4.64.
    Các kết quả này không bị ảnh hưởng nhiều bởi chuẩn hóa chi phí huấn luyện tăng thêm và phương pháp của ta vẫn tốt hơn nhiều các mô hình trong Analytic-DPM \cite{bao2021analytic}.

    \begin{table}[h!]
        \caption{So sánh khoảng cách FID sau khi chuẩn hóa chi phí tăng thêm của quá trình sinh dữ liệu.
        Số bước thời gian chuẩn hóa và hàm đánh giá mô hình (NFE) được hiển thị trong dấu ngoặc tròn.
        Chuẩn hóa đảm bảo chi phí thời gian của các mô hình của ta nhỏ hơn so với các mô hình khác}
        \begin{center}
            \resizebox{\columnwidth}{!}{
                \begin{tabular}{lrrrrrrrrrrrrrr}
                    \hline
                    \multirow{2}{*}{\# Số bước } & \multicolumn{2}{c}{CIFAR10 (LS)} & & \multicolumn{2}{c}{CIFAR10 (CS)} & & \multicolumn{2}{c}{CelebA 64x64} & & \multicolumn{2}{c}{ImageNet 64x64} & & \multicolumn{2}{c}{VP SDE} \\ \cline{2-3} \cline{5-6} \cline{8-9} \cline{11-12} \cline{14-15}
                    & 25 (24) & 50 (49) & & 25 (24) & 50 (49) & & 25 (24) & 50 (49) & & 25 (23) & 50 (47) & & 25 (24) & 50 (49) \\
                    \hline
                    Analytic-DPM \cite{bao2021analytic} &  11.60 & 7.25 & & 8.50 & 5.50 & & 16.01 & 11.23 & & 32.56 & 22.45 & & 11.57 & 6.54 \\
                    NPR-DDPM & 10.82 & 6.28 & & 7.98 & 5.33 & & 16.00 & 11.06 & & 29.72 & 21.52 & & 10.88 & 5.80 \\
                    SN-DDPM & \textbf{7.42} & \textbf{4.60} & & \textbf{6.15} & \textbf{4.20} & & \textbf{12.11} & \textbf{8.08} & & \textbf{29.05} & \textbf{20.80} & & \textbf{7.94} & \textbf{4.47} \\
                    \hline
                \end{tabular}
            }
            \resizebox{\columnwidth}{!}{
                \begin{tabular}{lrrrrrrr}
                    \hline
                    NFE trên CIFAR10 (VP SDE) & 29 (28) & 39 (38) & 49 (48) & 147 (145) & 179 (177) & 274 (272) & 329 (326) \\
                    \hline
                    Gotta Go Fast & 247.79 & 116.91 & 72.29 & \textbf{2.95} & \textbf{2.59} & 2.74 & 2.70 \\
                    NPR-DDPM & 9.22 & 6.97 & 5.88 & 3.44 & 3.19 & 2.91 & 2.94 \\
                    SN-DDPM & \textbf{6.62} & \textbf{5.21} & \textbf{4.55} & 2.96 & 2.85 & \textbf{2.67} & \textbf{2.64} \\
                    \hline
                \end{tabular}
            }
        \end{center}
        \label{table:FID-Comparision-Normalization}
    \end{table}
\end{document}