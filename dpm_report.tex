\documentclass[14pt, a4paper]{article}
\usepackage{minitoc}
\usepackage[left=3.00cm, right=2.5cm, top=2.00cm, bottom=2.00cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{graphicx}
%\usepackage{algpseudocode}
%\usepackage{algorithm}
\usepackage[ruled,vlined,linesnumbered,algosection]{algorithm2e}
\usepackage{blindtext}
\usepackage{setspace}
\usepackage[utf8]{inputenc}
\usepackage[utf8]{vietnam}
\usepackage[center]{caption}
\usepackage[shortlabels]{enumitem}
\usepackage{fancyhdr} % header, footer
\usepackage{hyperref} % loại bỏ border với mục lục và công thức
\usepackage[nonumberlist, nopostdot, nogroupskip]{glossaries}
\usepackage{glossary-superragged}
\usepackage{tikz,tkz-tab}
\setglossarystyle{superraggedheaderborder}
\pagestyle{fancy}
%\usepackage[style=numeric,sortcites]{biblatex}
%\addbibresource{ref.bib}
%\usepackage[numbers]{natbib}
\usepackage{indentfirst}
\usepackage[natbib,backend=biber,style=ieee, sorting=ynt]{biblatex}
\bibliography{ref.bib}

\graphicspath{{./figures/}}


\makenoidxglossaries

% Danh mục thuật ngữ
\newglossaryentry{DPM}
{
	name={DPMs},
	description={Diffusion Probabilistic Models}
}
\newglossaryentry{DGM}
{
	name={DGMs},
	description={Deep Generative Models}
}
\newglossaryentry{GANs}
{
	name={GANs},
	description={Generative Adversarial Networks}
}
\newglossaryentry{ELBO}
{
	name={ELBO},
	description={Evidence Lower Bound}
}
\newglossaryentry{DDPM}
{
	name={DDPM},
	description={Denoising Diffusion Probabilistic Models}
}
\newglossaryentry{DDIM}
{
	name={DDIM},
	description={Denoising Diffusion Implicit Models}
}
\newglossaryentry{MSE}
{
	name={MSE},
	description={Mean Square Error}
}

\hypersetup{
    colorlinks=false,
    pdfborder={0 0 0},
}


\fancyhf{}
\rhead{\textbf{Môn học: Học máy và khai phá dữ liệu}}
\lhead{\textbf{GVHD: PGS. TS. Trần Trọng Hiếu}}
\rfoot{\thepage}
\lfoot{\textbf{Học viên thực hiện: Nguyễn Chí Thanh}}
\renewcommand{\headrulewidth}{0.4pt}
\renewcommand{\footrulewidth}{0.4pt}


\numberwithin{equation}{section}
\numberwithin{figure}{section}

\setlength{\parindent}{0.5cm}

\setcounter{secnumdepth}{3} % Cho phép subsubsection trong report
\setcounter{tocdepth}{3} % Chèn subsubsection vào bảng mục lục

\newtheorem{dl}{Định lý}
\newtheorem{md}{Mệnh đề}
\newtheorem{bd}{Bổ đề}
\newtheorem{dn}{Định nghĩa}
\newtheorem{hq}{Hệ quả}

\numberwithin{dl}{section}
\numberwithin{md}{section}
\numberwithin{bd}{section}
\numberwithin{dn}{section}
\numberwithin{hq}{section}

\doublespacing

\begin{document}

    \begin{titlepage}

        \newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

        \center % Center everything on the page

        %----------------------------------------------------------------------------------------
        %	HEADING SECTIONS
        %----------------------------------------------------------------------------------------
        \textsc{\LARGE Đại học Quốc Gia Hà Nội}\\[0.5cm]
        \textsc{\LARGE Trường đại học Khoa học tự nhiên}\\[0.5cm] % Name of your university/college
        \textsc{\LARGE Khoa Toán - Cơ - Tin học}\\[0.5cm]

        \includegraphics[scale=0.2]{HUS-logo.jpg}\\[0.5cm]

        \textsc{\Large Chuyên ngành: Khoa học dữ liệu}\\[0.5cm] % Major heading such as course name


        %----------------------------------------------------------------------------------------
        %	TITLE SECTION
        %----------------------------------------------------------------------------------------

        \HRule \\[0.4cm]
        { \huge \bfseries BÀI TẬP MÔN HỌC}\\[0.4cm] % Title of your document
        \HRule \\[1.5cm]

        \textsc{\Large Môn học: Học máy và khai phá dữ liệu}\\[1cm] % Minor heading such as course title


        \textsc{\Large Đề tài: Ước lượng ma trận hiệp phương sai tối ưu với \\ trung bình không hoàn hảo \\ trong mô hình khuếch toán xác suất}\\[2cm]


        %----------------------------------------------------------------------------------------
        %	AUTHOR SECTION
        %----------------------------------------------------------------------------------------
        \begin{minipage}{0.4\textwidth}
            \begin{flushleft} \large
            \emph{Giảng viên hướng dẫn:} \\
            PGS. TS. Trần Trọng Hiếu % Supervisor's Name
            \end{flushleft}
        \end{minipage}\\[0.5cm]

        \begin{minipage}{0.4\textwidth}
        \begin{flushleft} \large
        \emph{Học viên thực hiện:}\\
        Nguyễn Chí Thanh \\
        MSHV: 21007925 \\ % Your name
        Lớp: Khoa học dữ liệu - K4
        \end{flushleft}
        \end{minipage}


        % If you don't want a supervisor, uncomment the two lines below and remove the section above
        %\Large \emph{Author:}\\
        %John \textsc{Smith}\\[3cm] % Your name

        %----------------------------------------------------------------------------------------
        %	DATE SECTION
        %----------------------------------------------------------------------------------------

        % I don't want day because it is English
        % {\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise

        %----------------------------------------------------------------------------------------
        %	LOGO SECTION
        %----------------------------------------------------------------------------------------

        %\includegraphics{logo/rsz_3logo-khtn.png}\\[1cm] % Include a department/university logo - this will require the graphicx package

        %----------------------------------------------------------------------------------------

        \vfill % Fill the rest of the page with whitespace

    \end{titlepage}

    \cleardoublepage
    \pagenumbering{gobble}
    \tableofcontents
    \newpage
    \listoffigures
    \newpage
    \glsaddall 
    \renewcommand*{\glossaryname}{Danh mục các từ viết tắt}
    \renewcommand*{\acronymname}{Danh sách từ viết tắt}
    \renewcommand*{\entryname}{Viết tắt}
    \renewcommand*{\descriptionname}{Viết đầy đủ}
    \printnoidxglossary
    \cleardoublepage
    \pagenumbering{arabic}

    %\maketitle

    \newpage

    \nocite{*}

    \begin{center}
    \section*{LỜI MỞ ĐẦU}
    \end{center}
    \addcontentsline{toc}{section}{{\bf LỜI MỞ ĐẦU}\rm}

    Các mô hình khuếch tán xác suất (DPMs) là một lớp các mô hình sinh (DGMs) rất mạnh.
    Mặc dù rất được các nhà khoa học quan tâm nhưng quá trình sinh dữ liệu sử dụng phép lặp tốn tài nguyên và ít hiệu quả về mặt tính toán hơn nhiều các mô hình sinh khác ví dụ là mô hình sinh đối kháng (GANs).
    Vậy nên hiệu năng của quá trình sinh trên một tập con của các bước thời gian là rất quan trọng,
    điều này bị ảnh hưởng rất lớn bởi ma trận hiệp phương sai được thiết kế trong DPMs.
    Trong đề tài này, ta xem xét và so sánh sự ảnh hưởng của ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ để khải thiện đáng kể sức mạnh của DPMs.
    Ta sẽ nhận được các kết quả tối ưu cho ma trận hiệp phương sai và hiệu chỉnh khi mà các trung bình của DPMs không hoàn hảo.
    Ma trận hiệp phương sai tối ưu và ma trận hiệp phương sai tối ưu đã được hiệu chỉnh đều có thể được phân tích thành các thành phần kỳ vọng có điều kiện của các hàm của nhiễu.
    Dựa trên điều này ta sẽ đề xuất ước lượng ma trận hiệp phương sao tối ưu và ma trận hiệp phương sai tối ưu được hiệu chỉnh khi biết trung bình không hoàn hảo bằng cách học các kỳ vọng có điều kiện.
    Phương pháp này có thể được áp dụng cho cả trường hợp bước thời gian rời rạc và bước thời gian liên tục.
    Ta sẽ chỉ xem xét ma trận hiệp phương sai đường chéo để làm giảm chi phí tính toán.
    Để tiến hành thực nghiệm hiệu quả, ta sử dụng chiến lược chia sẻ tham số giữa các mô hình và quá trình huấn luyện gồm hai giai đoạn.
    Kết quả thực nghiệm cho thấy phương pháp này vượt trội hơn một lượng lớn và đa dạng các phương pháp thiết kế ma trận hiệp phương sai dựa trên ước lượng hợp lý,
    và cải thiện chất lượng các ảnh được tạo ra đặc biệt dù chỉ trên một số lượng nhỏ bước.
    

        
    \newpage

    \section{Tổng quan về mô hình khuếch tán}

    Gần đây, các mô hình khuếch tán xác suất (DPMs) \cite{sohl2015deep}, \cite{ho2020denoising}, \cite{song2020score} đã tạo ra rất nhiều hứa hẹn trong lĩnh vực các mô hình sinh.
    Những mô hình này lần lượt đưa nhiễu vào theo từng bước thời gian vào phân phối dữ liệu gốc tạo nên một quá trình khuếch tán.
    Bằng cách học để đảo ngược quá trình khuếch tán sử dụng mô hình Markov, DPMs có khả năng tạo ra các ảnh chất lượng cao \cite{ho2020denoising}, \cite{song2020score}, \cite{dhariwal2021diffusion},
    các âm thanh chất lượng cao \cite{chen2020wavegrad}, \cite{kong2020diffwave}. 
    Các mô hình này hoàn toàn có khả năng cạnh tranh với các mô hình sinh tân tiến nhất hiện tại \cite{brock2018large}, \cite{wu2019logan}, \cite{karras2020analyzing}, \cite{binkowski2019high}, \cite{kalchbrenner2018efficient}.

    Tuy nhiên, quá trình sinh phải sử dụng một vòng lặp với số bước lớn và trên toàn bộ số bước của DPMs làm cho DPMs yêu cầu chi phí tính toán lớn hơn nhiều và kém hiệu quả hơn so với mô hình sinh đối kháng (GANs) \cite{goodfellow2014generative}.
    Vì vậy khả năng và chất lượng sinh dữ liệu của DPMs trên một tập con các bước là rất quan trọng.
    Trong trường hợp này thì quá trình khuếch tán ngược trở nên rất phức tạp \cite{xiao2021tackling} và thiết kế về ma trận hiệp phương sai trong DPMs trở thành một việc rất quan trọng \cite{nichol2021glide}, \cite{bao2021analytic}.
    Hầu hết các công trình trước đây \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic} sử dụng ma trận hiệp phương sai đẳng hướng mà chỉ phụ thuộc vào bước thời gian mà không phụ thuộc vào trạng thái.
    Một bước phát triển gần đây đáng chú ý là Analytic-DPM \cite{bao2021analytic},
    công trình này ước lượng ma trận hiệp phương sai tối ưu (theo khía cạnh ước lượng hợp lý cực đại) thay vì sử dụng giá trị đặt trước \cite{ho2020denoising}, \cite{song2020denoising} và cho thấy một bước cải thiện đáng kể trên ước lượng hợp lý và hiệu quả lấy mẫu.
    Tuy nhiên ma trận hiệp phương sai đẳng hướng hy sinh sức mạnh của DPMs để mô hình đơn giản hơn.
    Hơn nữa, tính tối ưu của ước lượng ma trận hiệp phương sai trong \cite{bao2021analytic} được duy trì bởi giả định là trung bình tối ưu đã biết trước,
    nhưng điều này không phù hợp trong thực tế.

    Để khắc phục những hạn chế đã được nêu ở trên đồng thời cải thiện thêm khả năng của DPMs dựa trên ước lượng hợp lý và lấy mẫu hiệu quả,
    ta xem xét ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ để cải thiện sức mạnh sinh dữ liệu của DPMs.
    Ta thu được trung bình và ma trận hiệp phương sai tối ưu được xác định từ ước lượng hợp lý cực đại.
    Ta cũng sẽ hiệu chỉnh ma trận hiệp phương sai khi cho trước một trung bình không hoàn hảo (khi trung bình tối ưu được xấp xỉ và có sai lệch với giá trị lý tưởng) theo khía cạnh ước lượng hợp lý.
    Cả ma trận hiệp phương sai tối ưu và ma trận hiệp phương sai tối ưu được hiệu chỉnh có thể được phân tích thành các thành phần là các kỳ vọng có điều kiện là hàm của nhiễu,
    các kỳ vọng này có thể được ước lượng bằng cách hàm mục tiêu sai lệch bình phương trung bình (MSE).
    Mặc dù lý thuyết này có thể được áp dụng cho trường hợp ma trận hiệp phương sai đầy đủ, nhưng trong các thử nghiệm thì ta chỉ xem xét ma trận hiệp phương sai đường chéo để làm giảm chi phí tính toán.
    Bên cạnh đó ta sử dụng chiến lược chia sẻ tham số tạo sự hiệu quả khi chạy suy luận các mô hình và quá trình huấn luyện gồm hai giai đoạn được áp dụng từ các kết quả lý thuyết.

    Phương pháp của chúng ta được áp dụng cho cả bước thời gian rời rạc \cite{ho2020denoising} và bước thời gian liên tục \cite{song2020score}.
    Trong các thí nghiệm, ta sẽ so sánh phương pháp của chúng ta với nhiều phương pháp khác \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic}, \cite{song2020score} về chất lượng dữ liệu được tạo ra và ước lượng hợp lý trong DPMs với cả trường hợp bước thời gian rời rạc và bước thời gian liên tục.
    Với gần như cùng một chi phí tính toán, phương pháp của ta gần như luôn luôn vượt trội hơn so với các phương pháp khác trên ước lượng hợp lý.
    Bên cạnh đó phương pháp của chúng ta cũng tạo ra các dữ liệu có chất lượng tốt hơn trong hầu hết trường hợp đặc biệt là khi số bước dùng để sinh ra dữ liệu nhỏ.

    \section{Mô hình toán học của mô hình khuếch tán}

    Các mô hình khuếch tán xác suất (DPMs) là một quá trình Markov đặc biệt với các bước chuyển tiếp là phân phối Gaussian:

    \begin{equation}
        p\big(\boldsymbol{x}_{0:N}\big)=p\big(\boldsymbol{x}_N\big)\prod_{n=1}^N p\big(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n\big)
    \end{equation}
    với
    \begin{equation}
        p\big(\boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n \big)=\mathcal{N} \big( \boldsymbol{x}_{n-1} \vert \boldsymbol{\mu}_n \big( \boldsymbol{x}_n \big), \boldsymbol{\Sigma}_n \big( \boldsymbol{x}_n \big) \big)
    \end{equation}

    Mục tiêu của ta là đảo ngược quá trình khuếch tán thuận $q\big(\boldsymbol{x}_{1:N} \vert \boldsymbol{x}_0\big)$. 
    Quá trình khuếch tán thuận đưa nhiễu vào phân phối dữ liệu $q(\boldsymbol{x}_0)$ một cách từ từ qua từng bước.
    \cite{song2020denoising} xem xét một họ các quá trình khuếch tán thuật mà từng bước được đánh dấu bởi một vector không âm $\lambda = \big( \lambda_1, \dots, \lambda_N \big) \in \mathbb{R}_{\geq 0}^{N}$:

    \begin{equation}
        q\big(\boldsymbol{x}_{1:N} \vert \boldsymbol{x}_0 \big)=q\big( \boldsymbol{x}_N \vert \boldsymbol{x}_0 \big) \prod_{n=2}^{N} q\big( \boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0 \big)
    \end{equation}

    \begin{equation}
        q\big( \boldsymbol{x}_N \vert \boldsymbol{x}_0 \big)=\mathcal{N} \big( \boldsymbol{x}_N \vert \sqrt{\overline{\alpha}_N} \boldsymbol{x}_0, \overline{\beta}_N \boldsymbol{I} \big)
    \end{equation}

    \begin{equation}
        q\big( \boldsymbol{x}_{n-1} \vert \boldsymbol{x}_n, \boldsymbol{x}_0 \big)=\mathcal{N} \big( \boldsymbol{x}_{n-1} \vert \tilde{\boldsymbol{\mu}}_n (\boldsymbol{x}_n, \boldsymbol{x}_0), \lambda_n^2 \boldsymbol{I} \big)
    \end{equation}

    \begin{equation}
        \tilde{\boldsymbol{\mu}}_n \big( \boldsymbol{x}_n, \boldsymbol{x}_0 \big)=\sqrt{\overline{\alpha}_{n-1}}\boldsymbol{x}_0 + \sqrt{\overline{\beta}_{n-1} - \lambda_n^2}.\dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n}\boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}
    \end{equation}

    với $\overline{\alpha}_1, \overline{\alpha}_2, \dots, \overline{\alpha}_N \in (0, 1)$ là một dãy giảm ngặt,
    $\overline{\beta}_n := 1 - \overline{\alpha}_n$ và $\boldsymbol{I}$ là ma trận đơn vị.
    Ta nhận thấy $q\big( \boldsymbol{x}_n \vert \boldsymbol{x}_0 \big)=\mathcal{N} \big( \boldsymbol{x}_n \vert \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0, \overline{\beta}_n \boldsymbol{I} \big)$,
    ta có thể lấy mẫu $\boldsymbol{x}_n$ một cách nhanh chóng khi biết trước $\boldsymbol{x}_0$ bằng cách:

    \begin{equation}
        \boldsymbol{x}_n = \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0 + \sqrt{\overline{\beta}_n} \boldsymbol{\epsilon}_n \text{ với } \boldsymbol{\epsilon}_n \sim \mathcal{N}(\boldsymbol{0}, \boldsymbol{I})
    \end{equation}

    Đặt $\alpha_n := \overline{\alpha}_n / \overline{\alpha}_{n-1}, \beta_n := 1 - \alpha_n$ và $\tilde{\beta}_n := \dfrac{\overline{\beta}_{n-1}}{\overline{\beta}_n}\beta_n$.
    Hai quá trình khuếch tán thuật hay được sử dụng là DDPM (tương ứng với $\lambda_n^2=\tilde{\beta}_n$) \cite{ho2020denoising} và DDIM (tương ứng với $\lambda_n^2 = 0$) \cite{song2020denoising}.
    Cụ thể quá trình khuếch tán thuận của DDPM là một quá trình Markov với chuyển tiếp Gaussian tuyến tính:

    \begin{equation}
        q\big( \boldsymbol{x}_n \vert \boldsymbol{x}_{n-1} \big)=\mathcal{N} \big( \bold{x}_n \vert \sqrt{\alpha}_n \boldsymbol{x}_{n-1}, \beta_n \boldsymbol{I} \big)
    \end{equation}

    Quá trình khuếch tán ngược được học bằng cách cực đại hóa cận dưới (ELBO): $L_{\mathrm{elbo}}=\mathbb{E}_q \log \dfrac{p(\bold{x}_{0:N})}{q(\bold{x}_{1:N}\vert \bold{x}_0)}$ hay tương đương với cực tiểu hóa độ phân kỳ Kullback-Leibler giữa quá trình khuếch tán thuận và quá trình khuếch tán ngược:

    \begin{equation} \label{eq:ELBO-Maximization}
        \max_{\lbrace \boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} L_{\mathrm{elbo}} \Leftrightarrow \min_{\lbrace \boldsymbol{\mu}_n, \boldsymbol{\Sigma}_n \rbrace_{n=1}^N} D_{KL} \big( q(\boldsymbol{x}_{0:N}) \Vert p(\boldsymbol{x}_{0:N}) \big)
    \end{equation}

    Bài toán ở công thức \ref{eq:ELBO-Maximization} tối ưu hóa cả trung bình và ma trận hiệp phương sai cùng lúc. 
    Ta gọi là bài toán tối ưu hóa chung.

    Để mô hình đơn giản, các công trình trước \cite{ho2020denoising}, \cite{song2020denoising}, \cite{bao2021analytic} sử dụng ma trận hiệp phương sai đẳng hướng là $\boldsymbol{\Sigma}_n(\boldsymbol{x}_n)=\sigma_n^2 \boldsymbol{I}$ chỉ phụ thuộc vào bước thời gian thứ $n$, $\sigma_n^2$ là phương sai cho từng bước.
    Với giả định này, \cite{bao2021analytic} đã chỉ ra cả trung bình tối ưu $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ và phương sai tối ưu có dạng giải tích tương ứng với kỳ vọng có điều kiện của nhiễu $\mathbb{E}_{q\big( \boldsymbol{x}_0 \vert \bold{x}_n \big)} \lbrack \boldsymbol{\epsilon}_n \rbrack$:

    \begin{equation}
        \boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)=\tilde{\boldsymbol{\mu}}_n \Bigg( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \Big( \boldsymbol{x}_n - \sqrt{\overline{\beta}_n} \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack \Big) \Bigg)
    \end{equation}

    \begin{equation} \label{eq:Optimal-Isotropic-Variance}
        \sigma_n^{\ast 2}=\lambda_n^2 + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \Bigg( 1 - \mathbb{E}_{q(\boldsymbol{x}_n)} \dfrac{\lVert \mathbb{E}_{q(\boldsymbol{x}_0 \vert \boldsymbol{x}_n)} \lbrack \boldsymbol{\epsilon}_n \rbrack\rVert_2^2}{d} \Bigg)
    \end{equation}

    Với $\boldsymbol{\epsilon}_n = \dfrac{\boldsymbol{x}_n - \sqrt{\overline{\alpha}_n} \boldsymbol{x}_0}{\sqrt{\overline{\beta}_n}}$ là nhiễu được dùng để tạo ra $\boldsymbol{x}_n$ từ $\boldsymbol{x}_0$, $d$ là số chiều của dữ liệu $\boldsymbol{x}_0$ và $\gamma_n = \sqrt{\overline{\alpha}_{n-1}} - \sqrt{\overline{\beta}_{n-1} - \lambda_n^2}\sqrt{\dfrac{\overline{\alpha}_n}{\overline{\beta}_n}}$.
    \cite{ho2020denoising} ước lượng $\boldsymbol{\mu}_n^{\ast} (\boldsymbol{x}_n)$ sử dụng một mạng dự đoán nhiễu $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$:

    \begin{equation}
        \hat{\boldsymbol{\mu}}_n(\boldsymbol{x}_n)=\tilde{\boldsymbol{\mu}}_n \Bigg( \boldsymbol{x}_n, \dfrac{1}{\sqrt{\overline{\alpha}_n}} \Big( \bold{x}_n - \sqrt{\overline{\beta}_n} \hat{\boldsymbol{\epsilon}}_n(\boldsymbol{x}_n) \Big) \Bigg)
    \end{equation}

    Mạng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ cần phải học được kỳ vọng $\mathbb{E}_{q\big( \boldsymbol{x}_0 \vert \bold{x}_n \big)} \lbrack \boldsymbol{\epsilon}_n \rbrack$ bằng cách cực tiểu hóa hàm mục tiêu MSE:

    \begin{equation} \label{eq:Noise-Prediction}
        \min_{\lbrace \hat{\boldsymbol{\epsilon}}_n  \rbrace_{n=1}^N} \mathbb{E}_n  \mathbb{E}_{q(\boldsymbol{x}_0, \boldsymbol{x}_n)} \lVert \boldsymbol{\epsilon}_n - \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n) \rVert_2^2
    \end{equation}

    với $n$ được lấy mẫu theo phân phối đều từ $\lbrace 1, 2, \dots, N \rbrace$.
    Công thức \ref{eq:Noise-Prediction} chỉ ra rằng nghiệm tối ưu khi $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ cần phải học được kỳ vọng $\mathbb{E}_{q\big( \boldsymbol{x}_0 \vert \bold{x}_n \big)} \lbrack \boldsymbol{\epsilon}_n \rbrack = \mathbb{E}_{q\big( \boldsymbol{x}_0 \vert \bold{x}_n \big)} \lbrack \boldsymbol{\epsilon}_n \rbrack$ với mọi $n \in \lbrace 1, 2, \dots, N \rbrace$.

    Phương sai tối ưu ở công thức \ref{eq:Optimal-Isotropic-Variance} có thể được ước lượng sử dụng mạng $\hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)$ cần phải học được kỳ vọng $\mathbb{E}_{q\big( \boldsymbol{x}_0 \vert \bold{x}_n \big)} \lbrack \boldsymbol{\epsilon}_n \rbrack$ theo \cite{bao2021analytic}:

    \begin{equation}
        \hat{\sigma}_n^{2}=\lambda_n^2 + \gamma_n^2 \dfrac{\overline{\beta}_n}{\overline{\alpha}_n} \Bigg( 1 - \mathbb{E}_{q(\boldsymbol{x}_n)} \dfrac{\lVert \hat{\boldsymbol{\epsilon}}_n (\boldsymbol{x}_n)\rVert_2^2}{d} \Bigg)
    \end{equation}

    \section{Phương pháp đề xuất}

    Ta có thể cải thiện ước lượng của ma trận hiệp phương sai của DPMs dựa trên công trình gần đây \cite{bao2021analytic}.
    Đầu tiên ta sẽ xem xét ma trận hiệp phương sai đường chéo và ma trận hiệp phương sai đầy đủ thay vì ma trận hiệp phương sai đẳng hướng để cải thiện khả năng sinh dữ liệu của DPMs và thu được biểu thức của nghiệm tối ưu,
    sẽ được trình bày ở mục \ref{Optimal-Solution-Covariance-Beyond-Isotropic-Covariance}. Tiếp theo ta sẽ hiệu chỉnh ma trận hiệp phương sai tối ưu khi cho một trung bình không hoàn hảo (có xét đến sai số xấp xỉ và tối ưu hóa), sẽ được trình bày ở mục .
    Các chứng minh sẽ được trình bày ở phụ lục .

    Mặc dù các kết quả lý thuyết có thể được áp dụng cho trường ma trận hiệp phương sai đầy đủ (phụ lục ), 
    nhưng thường tốn nhiều thời gian để thu được các mẫu dữ liệu từ các bước chuyển tiếp Gaussian với ma trận hiệp phương sai đầy đủ (ví dụ phân tích Cholesky).
    Để cân bằng sự linh hoạt giữa thời gian và chi phí tính toán, ta tập trung vào ma trận hiệp phương sai đường chéo trong xuyên suốt các thực nghiệm.

    \subsection{Lời giải tối ưu cho ma trận hiệp phương sai thay vì sử dụng ma trận hiệp phương sai đẳng hướng} \label{Optimal-Solution-Covariance-Beyond-Isotropic-Covariance}




    \newpage
    \printbibliography[title={TÀI LIỆU THAM KHẢO}]

\end{document}